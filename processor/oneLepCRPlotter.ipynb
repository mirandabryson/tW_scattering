{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import glob\n",
    "import re\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "import uproot\n",
    "import uproot_methods\n",
    "import awkward\n",
    "import pandas as pd\n",
    "from klepto.archives import dir_archive\n",
    "\n",
    "\n",
    "import coffea.processor as processor\n",
    "from coffea.processor.accumulator import AccumulatorABC\n",
    "from coffea import hist\n",
    "from coffea.analysis_objects import JaggedCandidateArray\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this cell for plotting NN score\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "from klepto.archives import dir_archive\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import coffea.processor as processor\n",
    "from coffea.processor.accumulator import AccumulatorABC\n",
    "from coffea.analysis_objects import JaggedCandidateArray\n",
    "from coffea.btag_tools import BTagScaleFactor\n",
    "from coffea import hist\n",
    "import pandas as pd\n",
    "import uproot_methods\n",
    "import uproot\n",
    "import awkward\n",
    "import copy\n",
    "\n",
    "from memory_profiler import profile\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "from Tools.config_helpers import *\n",
    "from Tools.helpers import mergeArray, mt\n",
    "\n",
    "from Tools.objects import Collections\n",
    "from Tools.cutflow import Cutflow\n",
    "\n",
    "# This just tells matplotlib not to open any\n",
    "# interactive windows.\n",
    "matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "def pad_and_flatten(val): \n",
    "    try:\n",
    "        return val.pad(1, clip=True).fillna(0.).flatten()#.reshape(-1, 1)\n",
    "    except AttributeError:\n",
    "        return val.flatten()\n",
    "\n",
    "#model = tf.keras.models.load_model('../ML/data/training.h5')#, custom_objects=None, compile=False)\n",
    "\n",
    "#model._make_predict_function()\n",
    "#graph = tf.get_default_graph()\n",
    "\n",
    "#def run_model(inputs):\n",
    "#    global graph\n",
    "#    with graph.as_default():\n",
    "#        outputs = model.predict(inputs)\n",
    "#    return outputs\n",
    "\n",
    "os.environ['KERAS_BACKEND'] = 'theano'\n",
    "from keras.models import load_model\n",
    "\n",
    "#model = load_model('../ML/data/training.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.setrecursionlimit(10000)\n",
    "print(sys.getrecursionlimit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's define our processor first. \n",
    "\n",
    "class WHhadProcessor(processor.ProcessorABC):\n",
    "    def __init__(self):\n",
    "        \n",
    "        ## load the NN\n",
    "        self.model = load_model('../ML/data/lostLep_Z_backgrounds/training.h5')\n",
    "        self.stds  = pd.read_json('../ML/data/lostLep_Z_backgrounds/stds.json').squeeze()\n",
    "        self.means = pd.read_json('../ML/data/lostLep_Z_backgrounds/means.json').squeeze()\n",
    "        \n",
    "        #Great, now let's define some bins for our histograms.\n",
    "        \n",
    "        dataset_axis         = hist.Cat(\"dataset\", \"Primary dataset\")\n",
    "        pt_axis              = hist.Bin(\"pt\", r\"$p_{T}$ (GeV)\", 500, 0, 2000)\n",
    "        #pt_axis              = hist.Bin(\"pt\", r\"$p_{T}$ (GeV)\", 15, 0, 300)\n",
    "        multiplicity_axis    = hist.Bin(\"multiplicity\", r\"N\", 30, -0.5, 29.5)\n",
    "        phi_axis             = hist.Bin(\"phi\", r\"$\\Delta \\phi$\", 80, 0, 8)\n",
    "        mass_axis            = hist.Bin(\"mass\", r\"mass (GeV)\", 500, 0, 2000)\n",
    "        r_axis               = hist.Bin(\"r\", r\"$\\Delta R$\", 80, 0, 4)\n",
    "        score_axis           = hist.Bin(\"score\", r\"NN Score\", 10, 0, 1)\n",
    "\n",
    "        #In order to create proper histograms, we always need to include a dataset axis!\n",
    "        #For different types of histograms with different scales, I create axis to fit \n",
    "        #those dimensions!\n",
    "        \n",
    "        #Now, let's move to actually telling our processor what histograms we want to make.\n",
    "        #Let's start out simple. \n",
    "        self._accumulator = processor.dict_accumulator({\n",
    "            \"h_pt_met200_CR\":                       hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "            \"h_pt_met400_CR\":                       hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "            \"h_pt_met600_CR\":                       hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "            \n",
    "            \"fj_pt_met200_CR\":                      hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "            \"fj_pt_met400_CR\":                      hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "            \"fj_pt_met600_CR\":                      hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "\n",
    "            \"h_mass_met200_CR\":                     hist.Hist(\"Counts\", dataset_axis, mass_axis),\n",
    "            \"h_mass_met400_CR\":                     hist.Hist(\"Counts\", dataset_axis, mass_axis),\n",
    "            \"h_mass_met600_CR\":                     hist.Hist(\"Counts\", dataset_axis, mass_axis),\n",
    "            \n",
    "            \"met_noHiggs\":                          hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "            \"met_oneHiggs\":                         hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "            \"met_oneW\":                             hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "            \"met_inHiggs\":                          hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "            \"met_outHiggs\":                         hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "            \n",
    "            \"met_CR\":                               hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "            \"met_SR\":                               hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "            \"met_Higgs_CR\":                         hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "            \"met_Higgs_SR\":                         hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "            \"met_W_CR\":                             hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "            \"met_W_SR\":                             hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "            \"met_Higgs_W_CR\":                       hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "            \"met_Higgs_W_SR\":                       hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "\n",
    "        })\n",
    "\n",
    "    \n",
    "    @property\n",
    "    \n",
    "    def accumulator(self):\n",
    "        return self._accumulator\n",
    "\n",
    "    def process(self, df):\n",
    "     \n",
    "        \"\"\"\n",
    "        Processing function. This is where the actual analysis happens.\n",
    "        \"\"\"\n",
    "        output = self.accumulator.identity()\n",
    "        dataset = df[\"dataset\"]\n",
    "        cfg = loadConfig()\n",
    "        \n",
    "        ## MET -> can switch to puppi MET\n",
    "        met_pt  = df[\"MET_pt\"]\n",
    "        met_phi = df[\"MET_phi\"]\n",
    "        \n",
    "        ## Muons\n",
    "        muon = JaggedCandidateArray.candidatesfromcounts(\n",
    "            df['nMuon'],\n",
    "            pt = df['Muon_pt'].content,\n",
    "            eta = df['Muon_eta'].content,\n",
    "            phi = df['Muon_phi'].content,\n",
    "            mass = df['Muon_mass'].content,\n",
    "            miniPFRelIso_all=df['Muon_miniPFRelIso_all'].content,\n",
    "            looseId =df['Muon_looseId'].content\n",
    "            )\n",
    "        muon = muon[(muon.pt > 10) & (abs(muon.eta) < 2.4) & (muon.looseId) & (muon.miniPFRelIso_all < 0.2)]\n",
    "        #muon = Collections(df, \"Muon\", \"tightTTH\").get() # this needs a fix for DASK\n",
    "        \n",
    "        electrons = JaggedCandidateArray.candidatesfromcounts(\n",
    "            df['nElectron'],\n",
    "            pt=df['Electron_pt'].content, \n",
    "            eta=df['Electron_eta'].content, \n",
    "            phi=df['Electron_phi'].content,\n",
    "            mass=df['Electron_mass'].content,\n",
    "            pdgid=df['Electron_pdgId'].content,\n",
    "            mini_iso=df['Electron_miniPFRelIso_all'].content\n",
    "        )\n",
    "        \n",
    "        ## Electrons\n",
    "        electron = JaggedCandidateArray.candidatesfromcounts(\n",
    "            df['nElectron'],\n",
    "            pt = df['Electron_pt'].content,\n",
    "            eta = df['Electron_eta'].content,\n",
    "            phi = df['Electron_phi'].content,\n",
    "            mass = df['Electron_mass'].content,\n",
    "            miniPFRelIso_all=df['Electron_miniPFRelIso_all'].content,\n",
    "            cutBased=df['Electron_cutBased'].content\n",
    "            )\n",
    "        electron = electron[(electron.pt>10) & (abs(electron.eta) < 2.4) & (electron.miniPFRelIso_all < 0.1) &  (electron.cutBased >= 1)]\n",
    "        #electron = Collections(df, \"Electron\", \"tightTTH\").get() # this needs a fix for DASK\n",
    "        \n",
    "        tau = JaggedCandidateArray.candidatesfromcounts(\n",
    "            df['nTau'],\n",
    "            pt=df['Tau_pt'].content, \n",
    "            eta=df['Tau_eta'].content, \n",
    "            phi=df['Tau_phi'].content,\n",
    "            mass=df['Tau_mass'].content,\n",
    "            decaymode=df['Tau_idDecayMode'].content,\n",
    "            newid=df['Tau_idMVAnewDM2017v2'].content,\n",
    "        )\n",
    "        tau = tau[(tau.pt > 20) & (abs(tau.eta) < 2.4) & (tau.decaymode) & (tau.newid >= 8)]\n",
    "        \n",
    "        isotrack = awkward.JaggedArray.zip(\n",
    "            pt=df['IsoTrack_pt'], \n",
    "            eta=df['IsoTrack_eta'], \n",
    "            phi=df['IsoTrack_phi'], \n",
    "            rel_iso=df['IsoTrack_pfRelIso03_all'], \n",
    "        )\n",
    "        isotrack = isotrack[(isotrack.pt > 10) & (abs(isotrack.eta) < 2.4) & ((isotrack.rel_iso < 0.1) | ((isotrack.rel_iso*isotrack.pt) < 6))]\n",
    "        \n",
    "        ## FatJets\n",
    "        fatjet = JaggedCandidateArray.candidatesfromcounts(\n",
    "            df['nFatJet'],\n",
    "            pt = df['FatJet_pt'].content,\n",
    "            eta = df['FatJet_eta'].content,\n",
    "            phi = df['FatJet_phi'].content,\n",
    "            mass = df['FatJet_mass'].content,\n",
    "            msoftdrop = df[\"FatJet_msoftdrop\"].content,  \n",
    "            deepTagMD_HbbvsQCD = df['FatJet_deepTagMD_HbbvsQCD'].content, \n",
    "            deepTagMD_WvsQCD = df['FatJet_deepTagMD_WvsQCD'].content, \n",
    "            deepTag_WvsQCD = df['FatJet_deepTag_WvsQCD'].content\n",
    "            \n",
    "        )\n",
    "        \n",
    "        leadFatJet = fatjet[:,:1]\n",
    "        leadingFatJets = fatjet[:,:2]\n",
    "        difatjet = leadingFatJets.choose(2)\n",
    "        dphiDiFatJet = np.arccos(np.cos(difatjet.i0.phi-difatjet.i1.phi))\n",
    "        \n",
    "        htag = fatjet[((fatjet.pt > 200) & (fatjet.deepTagMD_HbbvsQCD > 0.8365))]\n",
    "        htag_hard = fatjet[((fatjet.pt > 300) & (fatjet.deepTagMD_HbbvsQCD > 0.8365))]\n",
    "        \n",
    "        lead_htag = htag[htag.pt.argmax()]\n",
    "        \n",
    "        wtag = fatjet[((fatjet.pt > 200) & (fatjet.deepTagMD_HbbvsQCD < 0.8365) & (fatjet.deepTag_WvsQCD > 0.918))]\n",
    "        wtag_hard = fatjet[((fatjet.pt > 300) & (fatjet.deepTagMD_HbbvsQCD < 0.8365) & (fatjet.deepTag_WvsQCD > 0.918))]\n",
    "        \n",
    "        lead_wtag = wtag[wtag.pt.argmax()]\n",
    "        \n",
    "        wh = lead_htag.cross(lead_wtag)\n",
    "        wh_deltaPhi = np.arccos(wh.i0.phi - wh.i1.phi)\n",
    "        wh_deltaR = wh.i0.p4.delta_r(wh.i1.p4)\n",
    "        \n",
    "        ## Jets\n",
    "        jet = JaggedCandidateArray.candidatesfromcounts(\n",
    "            df['nJet'],\n",
    "            pt = df['Jet_pt'].content,\n",
    "            eta = df['Jet_eta'].content,\n",
    "            phi = df['Jet_phi'].content,\n",
    "            mass = df['Jet_mass'].content,\n",
    "            jetId = df['Jet_jetId'].content, # https://twiki.cern.ch/twiki/bin/view/CMS/JetID\n",
    "            #puId = df['Jet_puId'].content, # https://twiki.cern.ch/twiki/bin/viewauth/CMS/PileupJetID\n",
    "            btagDeepB = df['Jet_btagDeepB'].content, # https://twiki.cern.ch/twiki/bin/viewauth/CMS/BtagRecommendation102X\n",
    "            #deepJet = df['Jet_'].content # not there yet?\n",
    "        )\n",
    "        \n",
    "        skimjet   = jet[(jet.pt>30) & (abs(jet.eta)<2.4)]\n",
    "        jet       = jet[(jet.pt>30) & (jet.jetId>1) & (abs(jet.eta)<2.4)]\n",
    "        jet       = jet[~jet.match(muon, deltaRCut=0.4)] # remove jets that overlap with muons\n",
    "        jet       = jet[~jet.match(electron, deltaRCut=0.4)] # remove jets that overlap with electrons\n",
    "        jet       = jet[jet.pt.argsort(ascending=False)] # sort the jets\n",
    "        btag      = jet[(jet.btagDeepB>0.4184)]\n",
    "        light     = jet[(jet.btagDeepB<0.4184)]\n",
    "        \n",
    "        ## Get the leading b-jets\n",
    "        high_score_btag = jet[jet.btagDeepB.argsort(ascending=False)][:,:2]\n",
    "        \n",
    "        leading_jet    = jet[jet.pt.argmax()]\n",
    "        leading_b      = btag[btag.pt.argmax()]\n",
    "        \n",
    "        bb = high_score_btag.choose(2)\n",
    "        bb_deltaPhi = np.arccos(np.cos(bb.i0.phi-bb.i1.phi))\n",
    "        bb_deltaR = bb.i0.p4.delta_r(bb.i1.p4)\n",
    "        \n",
    "        mtb = mt(btag.pt, btag.phi, met_pt, met_phi)\n",
    "        min_mtb = mtb.min()\n",
    "        mth = mt(htag.pt, htag.phi, met_pt, met_phi)\n",
    "        \n",
    "        ## other variables\n",
    "        ht = jet.pt.sum()\n",
    "        \n",
    "        min_dphiJetMet4 = np.arccos(np.cos(jet[:,:4].phi-met_phi)).min()\n",
    "        \n",
    "        leadingJets = jet[:,:2]\n",
    "        dijet = leadingJets.choose(2)\n",
    "        dphiDiJet = np.arccos(np.cos(dijet.i0.phi-dijet.i1.phi))\n",
    "        \n",
    "        min_dphiFatJetMet4 = np.arccos(np.cos(fatjet[:,:4].phi-met_phi)).min()\n",
    "\n",
    "        ## evaluate NN\n",
    "        # first, prepare the inputs.\n",
    "        # A .max() can ensure that the flattened array has the full length, but we rather use our pad_and_flatten function        \n",
    "        # sorting in training: ['mll', 'njet', 'nbtag', 'st', 'ht', 'met', 'mjj_max', 'mlb_min', 'mlb_max', 'l0_pt', 'l1_pt', 'deltaR_lj_min', 'j0_pt']\n",
    "        \n",
    "        '''NN_inputs = np.stack([\n",
    "            # normalize\n",
    "            pad_and_flatten( (metpt - self.means['met'])/self.stds['met'] ),\n",
    "            pad_and_flatten( (ht - self.means['ht'])/self.stds['ht'] ),\n",
    "            pad_and_flatten( (lead_jet_pt - self.means['lead_jet_pt'])/self.stds['lead_jet_pt'] ),\n",
    "            pad_and_flatten( (sublead_jet_pt - self.means['sublead_jet_pt'])/self.stds['sublead_jet_pt'] ),\n",
    "            pad_and_flatten( (njets - self.means['njets'])/self.stds['njets'] ),\n",
    "            pad_and_flatten( (nbjets - self.means['bjets'])/self.stds['bjets'] ),\n",
    "            pad_and_flatten( (wtagged_mc.counts - self.means['nWs'])/self.stds['nWs'] ),\n",
    "            pad_and_flatten( (htagged.counts - self.means['nHs'])/self.stds['nHs'] ),\n",
    "            pad_and_flatten( (nfatjets - self.means['nFatJets'])/self.stds['nFatJets'] ),\n",
    "            pad_and_flatten( (met_sig - self.means['met_significance'])/self.stds['met_significance'] ),\n",
    "            pad_and_flatten( (abs_min_dphi_met_leadjs4 - self.means['min_dphi_met_j4'])/self.stds['min_dphi_met_j4'] ),\n",
    "        ])\n",
    "        \n",
    "        NN_inputs = np.moveaxis(NN_inputs, 0, 1)\n",
    "        NN_score = self.model.predict(NN_inputs)'''\n",
    "        \n",
    "        #filters\n",
    "        good_vertices = df[\"Flag_goodVertices\"]\n",
    "        tighthalo = df[\"Flag_globalSuperTightHalo2016Filter\"]\n",
    "        noise_filter = df[\"Flag_HBHENoiseFilter\"]\n",
    "        noise_isofilter = df[\"Flag_HBHENoiseIsoFilter\"]\n",
    "        ecal_deadcell = df[\"Flag_EcalDeadCellTriggerPrimitiveFilter\"]\n",
    "        bad_pfmuon = df[\"Flag_BadPFMuonFilter\"]\n",
    "        ee_badsc = df[\"Flag_eeBadScFilter\"]\n",
    "       \n",
    "        #trigger\n",
    "        hlt_pfmet_250 = df[\"HLT_PFMET250_HBHECleaned\"]\n",
    "        hlt_pfmet_300 = df[\"HLT_PFMET300_HBHECleaned\"]\n",
    "        hlt_pfmet1_200 = df[\"HLT_PFMETTypeOne200_HBHE_BeamHaloCleaned\"]\n",
    "        hlt_pfmet_mht = df[\"HLT_PFMET120_PFMHT120_IDTight_PFHT60\"]\n",
    "        hlt_pfmetNoMu_mhtNoMu = df[\"HLT_PFMETNoMu120_PFMHTNoMu120_IDTight_PFHT60\"]\n",
    "        \n",
    "        #variable to remove overlap in met extensions\n",
    "        #stitchVar = df['stitch']\n",
    "        \n",
    "       \n",
    "        #Now it's time to make some selections.\n",
    "\n",
    "        ht_ps = (ht > 300)\n",
    "        met_g250 = (met_pt>250)\n",
    "        met_l400 = (met_pt<400)\n",
    "        met_bin1 = met_g250 & met_l400\n",
    "        met_g400 = (met_pt>400)\n",
    "        met_l600 = (met_pt<600)\n",
    "        met_bin2 = met_g400 & met_l600\n",
    "        met_bin3 = (met_pt>600)\n",
    "        njet_cut = (jet.counts>=2)\n",
    "        njet_veto = (jet.counts<=5)\n",
    "        njet_ps = njet_cut & njet_veto\n",
    "        bjet_ps = (btag.counts>=1)\n",
    "        fatjet_sel = (fatjet.counts >=1)\n",
    "        inc_fatjet_sel = (fatjet.counts >=2)\n",
    "        #mt_sel = (min_mt_b_met > 200).any()\n",
    "        \n",
    "        #stitch_base = (stitchVar == 1)\n",
    "        \n",
    "        min_dphi_sel = (min_dphiJetMet4>0.5)\n",
    "        dphi_sel = (dphiDiJet.min()<2.5)\n",
    "        fatjet_dphi_sel = (dphiDiFatJet<2.5).all()\n",
    "\n",
    "        lowerHiggs = ((lead_htag.msoftdrop>90).any())\n",
    "        upperHiggs = ((lead_htag.msoftdrop<150).any())\n",
    "        \n",
    "        lowerHiggsInv = ((lead_htag.msoftdrop<90).any())\n",
    "        upperHiggsInv = ((lead_htag.msoftdrop>150).any())\n",
    "        \n",
    "        higgsWindow = lowerHiggs & upperHiggs\n",
    "        invertedHiggsWindow = lowerHiggsInv | upperHiggsInv\n",
    "        \n",
    "        e_sel = (electron.counts == 0)\n",
    "        m_sel = (muon.counts == 0)\n",
    "        it_sel = (isotrack.counts == 0)\n",
    "        t_sel = (tau.counts == 0)\n",
    "        #l_sel = e_sel & m_sel & it_sel & t_sel\n",
    "        l_sel = ((electron.counts + muon.counts) == 1)\n",
    "        l_veto = (e_sel & m_sel & t_sel & it_sel)\n",
    "        \n",
    "        #h_sel =(htag.counts>0) \n",
    "        wmc_sel = (wtag.counts>0) \n",
    "\n",
    "        met_fsel = (good_vertices == 1) & (tighthalo == 1) & (noise_filter == 1) & (noise_isofilter == 1) & (ecal_deadcell == 1) & (bad_pfmuon == 1) & (ee_badsc == 1) \n",
    "        met_tsel = (hlt_pfmet_250 == 1).any() | (hlt_pfmet_300 == 1).any() | (hlt_pfmet1_200 == 1).any() | (hlt_pfmet_mht == 1).any() | (hlt_pfmetNoMu_mhtNoMu == 1).any()\n",
    "        \n",
    "        met_skim = (met_pt>200)\n",
    "        jet_skim = (skimjet.counts>1)\n",
    "        skim = met_skim & jet_skim & met_fsel & met_tsel #& stitch_base\n",
    "        \n",
    "        base_met = (met_pt>250)\n",
    "        base_fatjet = (fatjet.counts>1)\n",
    "        base_jet = (jet.counts<2)\n",
    "        base_sel = base_met & base_fatjet & base_jet\n",
    "        \n",
    "        kin_minFJM = (min_dphiFatJetMet4>0.5)\n",
    "        kin_dphiFJ = ((dphiDiFatJet<2.5).all())\n",
    "        kin_mth = (mth.min()>200)\n",
    "        kin_sel = kin_minFJM & kin_dphiFJ & kin_mth\n",
    "        \n",
    "        h_tag = (htag.counts>0)\n",
    "        h_mass = (abs(htag.msoftdrop-125)<25).any()\n",
    "        h_sel = h_tag & h_mass\n",
    "        \n",
    "        w_tag = (wtag.counts>0)\n",
    "        w_mass = (abs(wtag.msoftdrop-80)<30).any()\n",
    "        w_sel = w_tag & w_mass\n",
    "        \n",
    "        #sel = ht_ps & met_ps & njet_ps & bjet_ps & l_sel & h_sel & wmc_sel\n",
    "        #sel = ht_ps & met_ps & njet_ps & bjet_ps & fatjet_sel & l_sel & h_sel & min_dphi_sel & dphi_sel & fatjet_dphi_sel\n",
    "        sel1_CR = met_fsel & met_tsel & l_sel & njet_ps & bjet_ps & min_dphi_sel & dphi_sel & fatjet_dphi_sel & ht_ps & inc_fatjet_sel & h_sel & wmc_sel & met_bin1\n",
    "        sel2_CR = met_fsel & met_tsel & l_sel & njet_ps & bjet_ps & min_dphi_sel & dphi_sel & fatjet_dphi_sel & ht_ps & inc_fatjet_sel & h_sel & wmc_sel & met_bin2\n",
    "        sel3_CR = met_fsel & met_tsel & l_sel & njet_ps & bjet_ps & min_dphi_sel & dphi_sel & fatjet_dphi_sel & ht_ps & inc_fatjet_sel & h_sel & wmc_sel & met_bin3\n",
    "        \n",
    "        #selCR = met_fsel & met_tsel & l_sel & njet_ps & bjet_ps & min_dphi_sel & dphi_sel & fatjet_dphi_sel & ht_ps & inc_fatjet_sel & h_sel & wmc_sel & met_g250 #& higgsWindow\n",
    "        selCRNoHCut = met_fsel & met_tsel & l_sel & njet_ps & bjet_ps & min_dphi_sel & dphi_sel & fatjet_dphi_sel & ht_ps & inc_fatjet_sel & met_g250 #& h_sel & wmc_sel \n",
    "        selCROneHCut = met_fsel & met_tsel & l_sel & njet_ps & bjet_ps & min_dphi_sel & dphi_sel & fatjet_dphi_sel & ht_ps & inc_fatjet_sel & met_g250 & h_sel #& wmc_sel \n",
    "        selCROneWCut = met_fsel & met_tsel & l_sel & njet_ps & bjet_ps & min_dphi_sel & dphi_sel & fatjet_dphi_sel & ht_ps & inc_fatjet_sel & met_g250 & wmc_sel #& h_sel \n",
    "        selCRInverted = met_fsel & met_tsel & l_sel & njet_ps & bjet_ps & min_dphi_sel & dphi_sel & fatjet_dphi_sel & ht_ps & inc_fatjet_sel & h_sel & wmc_sel & met_g250 & invertedHiggsWindow \n",
    "    \n",
    "        selCR       = l_sel  & skim & base_sel & kin_sel\n",
    "        selSR       = l_veto & skim & base_sel & kin_sel\n",
    "        selHiggsCR  = l_sel  & skim & base_sel & kin_sel & h_sel\n",
    "        selHiggsSR  = l_veto & skim & base_sel & kin_sel & h_sel\n",
    "        selWCR      = l_sel  & skim & base_sel & kin_sel & w_sel\n",
    "        selWSR      = l_veto & skim & base_sel & kin_sel & w_sel\n",
    "        selHiggsWCR = l_sel  & skim & base_sel & kin_sel & h_sel & w_sel\n",
    "        selHiggsWSR = l_veto & skim & base_sel & kin_sel & h_sel & w_sel\n",
    "        \n",
    "        #Let's make sure we weight our events properly.\n",
    "        #wght = df['weight'][sel] * 137\n",
    "        weight = np.ones(len(df['weight'])) if dataset=='Data' else df['weight']\n",
    "        lumi = 1 if dataset=='Data' else 60\n",
    "        dataNorm = 1 if dataset=='Data' else 0.99\n",
    "\n",
    "        wght1_CR = weight[sel1_CR] * lumi\n",
    "        wght2_CR = weight[sel2_CR] * lumi\n",
    "        wght3_CR = weight[sel3_CR] * lumi\n",
    "        \n",
    "        wghtCR      = weight[selCR] * lumi\n",
    "        wghtSR      = weight[selSR] * lumi\n",
    "        wghtHiggsCR = weight[selHiggsCR] * lumi\n",
    "        wghtHiggsSR = weight[selHiggsSR] * lumi\n",
    "        wghtWCR     = weight[selWCR] * lumi\n",
    "        wghtWSR     = weight[selWSR] * lumi\n",
    "        wghtHiggsWCR     = weight[selHiggsWCR] * lumi\n",
    "        wghtHiggsWSR     = weight[selHiggsWSR] * lumi\n",
    "        \n",
    "        dataNormNoHCut = 1 if dataset=='Data' else 0.812\n",
    "        wghtCRNoHCut = weight[selCRNoHCut] * lumi * dataNormNoHCut\n",
    "        dataNormOneHCut = 1 if dataset=='Data' else 0.708\n",
    "        wghtCROneHCut = weight[selCROneHCut] * lumi * dataNormOneHCut\n",
    "        dataNormOneWCut = 1 if dataset=='Data' else 0.579\n",
    "        wghtCROneWCut = weight[selCROneWCut] * lumi * dataNormOneWCut\n",
    "        wghtCRInv = weight[selCRInverted] * lumi\n",
    "        \n",
    "        \n",
    "        #Let's fill some histograms. \n",
    "        output['h_pt_met200_CR'].fill(dataset=dataset, pt=lead_htag[sel1_CR].pt.flatten(), weight=wght1_CR)\n",
    "        output['h_pt_met400_CR'].fill(dataset=dataset, pt=lead_htag[sel2_CR].pt.flatten(), weight=wght2_CR)\n",
    "        output['h_pt_met600_CR'].fill(dataset=dataset, pt=lead_htag[sel3_CR].pt.flatten(), weight=wght3_CR)\n",
    "\n",
    "        output['fj_pt_met200_CR'].fill(dataset=dataset, pt=leadFatJet[sel1_CR].pt.flatten(), weight=wght1_CR)\n",
    "        output['fj_pt_met400_CR'].fill(dataset=dataset, pt=leadFatJet[sel2_CR].pt.flatten(), weight=wght2_CR)\n",
    "        output['fj_pt_met600_CR'].fill(dataset=dataset, pt=leadFatJet[sel3_CR].pt.flatten(), weight=wght3_CR)\n",
    "\n",
    "        output['h_mass_met200_CR'].fill(dataset=dataset, mass=lead_htag[sel1_CR].mass.flatten(), weight=wght1_CR)\n",
    "        output['h_mass_met400_CR'].fill(dataset=dataset, mass=lead_htag[sel2_CR].mass.flatten(), weight=wght2_CR)\n",
    "        output['h_mass_met600_CR'].fill(dataset=dataset, mass=lead_htag[sel3_CR].mass.flatten(), weight=wght3_CR)\n",
    "\n",
    "        output['met_noHiggs'].fill(dataset=dataset, pt=met_pt[selCRNoHCut].flatten(), weight=wghtCRNoHCut)\n",
    "        output['met_oneHiggs'].fill(dataset=dataset, pt=met_pt[selCROneHCut].flatten(), weight=wghtCROneHCut)\n",
    "        output['met_oneW'].fill(dataset=dataset, pt=met_pt[selCROneWCut].flatten(), weight=wghtCROneWCut)\n",
    "        output['met_inHiggs'].fill(dataset=dataset, pt=met_pt[selCR].flatten(), weight=wghtCR)\n",
    "        output['met_outHiggs'].fill(dataset=dataset, pt=met_pt[selCRInverted].flatten(), weight=wghtCRInv)\n",
    "        \n",
    "        output['met_CR'].fill(dataset=dataset, pt=met_pt[selCR].flatten(), weight=wghtCR)\n",
    "        output['met_SR'].fill(dataset=dataset, pt=met_pt[selSR].flatten(), weight=wghtSR)\n",
    "        output['met_Higgs_CR'].fill(dataset=dataset, pt=met_pt[selHiggsCR].flatten(), weight=wghtHiggsCR)\n",
    "        output['met_Higgs_SR'].fill(dataset=dataset, pt=met_pt[selHiggsSR].flatten(), weight=wghtHiggsSR)\n",
    "        output['met_W_CR'].fill(dataset=dataset, pt=met_pt[selWCR].flatten(), weight=wghtWCR)\n",
    "        output['met_W_SR'].fill(dataset=dataset, pt=met_pt[selWSR].flatten(), weight=wghtWSR)\n",
    "        output['met_Higgs_W_CR'].fill(dataset=dataset, pt=met_pt[selHiggsWCR].flatten(), weight=wghtHiggsWCR)\n",
    "        output['met_Higgs_W_SR'].fill(dataset=dataset, pt=met_pt[selHiggsWSR].flatten(), weight=wghtHiggsWSR)\n",
    "        \n",
    "        return output\n",
    "\n",
    "    \n",
    "    def postprocess(self, accumulator):\n",
    "        return accumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "859ad6204a6249e28385cfd903adc91b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(HTML(value='Processing'), FloatProgress(value=0.0, max=434.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tag = '0p1p27'\n",
    "\n",
    "fileset_WH  = {'mC750_l1': glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/WH_had_750_1_nanoAOD/*.root'),\n",
    "                'WJets': glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/W*JetsToLNu_Tune*Autumn18*/*.root'),\n",
    "                      #+glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'W*JetsToLNu_NuPt*Autumn18*/*.root'),\n",
    "                'QCD': glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/QCD_HT*Autumn18*/*.root'),\n",
    "                'TTJets': glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/TTJets*Autumn18*/*.root'),\n",
    "                'ZNuNu': glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/ZJetsToNuNu*Autumn18*/*.root'),\n",
    "                'ST': glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/ST*Autumn18*/*.root'),\n",
    "                #'ST_tW': glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/ST_tW*/*.root'),\n",
    "                #'ST_tChannel': glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/ST_t-channel*/*.root'),\n",
    "                #'ST_sChannel': glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/ST_s-channel*/*.root'),\n",
    "                'ttW/ttZ': glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/ttWJets*Autumn18*/*.root')\n",
    "                    +glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/ttZJets*Autumn18*/*.root'),\n",
    "                'WW/WZ/ZZ': glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/WW*Autumn18*/*.root')\n",
    "                    +glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/WZ*Autumn18*/*.root')\n",
    "                    +glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/ZZTo2L2Nu*Autumn18*/*.root')\n",
    "                    +glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/ZZTo2Q2Nu*Autumn18*/*.root'),\n",
    "                'Data': glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/0p1p24/MET_Run2018*/*.root')\n",
    "                }\n",
    "\n",
    "fileset_WH_merge = {'mC750_l1': glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/WH_had_750_1_nanoAOD/*.root'),\n",
    "                'ZNuNu': glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/ZJetsToNuNu*/*.root')\n",
    "                    + glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/ttZJets*/*.root')\n",
    "                    + glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/WZ*/*.root')\n",
    "                    + glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/ZZTo2L2Nu*/*.root')\n",
    "                    + glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/ZZTo2Q2Nu*/*.root'),\n",
    "                'QCD': glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/QCD_HT*/*.root'),\n",
    "                'LL': glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/W*JetsToLNu_Tune*/*.root')\n",
    "                    + glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/TTJets*/*.root')\n",
    "                    + glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/ST*/*.root')\n",
    "                    + glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/ttWJets*/*.root')\n",
    "                    + glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/WW*/*.root'),\n",
    "                #'Data': glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/0p1p24/MET_Run2018*/*.root')\n",
    "\n",
    "                }\n",
    "\n",
    "#Here, I've separated by data from my background. This lets me change the style of the\n",
    "#signal line and keep the background consistent. \n",
    "\n",
    "output = processor.run_uproot_job(fileset_WH,\n",
    "                                    treename='Events',\n",
    "                                    processor_instance=WHhadProcessor(),\n",
    "                                    executor=processor.futures_executor,\n",
    "                                    executor_args={'workers': 12, 'function_args': {'flatten': False}},\n",
    "                                    chunksize=500000,\n",
    "                                 )\n",
    "\n",
    "#Here, we have the ability to change the 'workers' and 'chunksize', but to be honest,\n",
    "#it does not make that much of a difference unless you want to see your progress bar \n",
    "#get updates more or less often. Totally a person choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineopts = {\n",
    "    'color': 'r'}\n",
    "\n",
    "data_err_opts = {\n",
    "    'linestyle': 'none',\n",
    "    'marker': '_',\n",
    "    'markersize': 10.,\n",
    "    'color': 'r',\n",
    "    'elinewidth': 1}\n",
    "\n",
    "data_err_opts_rat = {\n",
    "    'linestyle': 'none',\n",
    "    'marker': '.',\n",
    "    'markersize': 10.,\n",
    "    'color': 'k',\n",
    "    'elinewidth': 1}\n",
    "\n",
    "lineopts2 = {\n",
    "    'color': [('#8EA604'), ('#F5BB00') ,('#466365')],#, ('#A33B20'), ('#680E4B'), ('#F6AE2D'),('#45503B')],\n",
    "}\n",
    "fillopts = {\n",
    "    'edgecolor': (0,0,0,0.3),\n",
    "    'facecolor': [('#1982C4')],#, ('#A33B20'), ('#680E4B'), ('#F6AE2D'),('#45503B')],\n",
    "    #'facecolor': [('#1467cc'), ('#51d673') ,('#f7d969'), ('#af84f0'), ('#4f842e'), ('#1ff4ff'),('#3612ab')],\n",
    "}\n",
    "\n",
    "fillopts1 = {\n",
    "    'edgecolor': (0,0,0,0.3),\n",
    "    'facecolor': [('#8AC926'), ('#FFCA3A') ],#, ('#A33B20'), ('#680E4B'), ('#F6AE2D'),('#45503B')],\n",
    "    #'facecolor': [('#1467cc'), ('#51d673') ,('#f7d969'), ('#af84f0'), ('#4f842e'), ('#1ff4ff'),('#3612ab')],\n",
    "}\n",
    "\n",
    "fillopts2 = {\n",
    "    'edgecolor': (0,0,0,0.3),\n",
    "    'facecolor': [('#1982C4'),('#F76F8E'),('#8AC926'),('#FFCA3A'),('#FF5714'),('#6A0136'),('#989C94')]#,('#613F75')]    \n",
    "}\n",
    "\n",
    "\n",
    "def savefig(hists, outdir, name):\n",
    "    import re\n",
    "    bkgandsig = re.compile('(?!Data)')\n",
    "    bkganddata = re.compile('(?!mC750_l1)')\n",
    "    \n",
    "    background = hists[bkgandsig][bkganddata]\n",
    "    signal = hists['mC750_1l']\n",
    "    data = hists['Data']\n",
    "    \n",
    "    plt.rcParams.update({'font.size': 14,'axes.titlesize': 18,'axes.labelsize': 18,\n",
    "                         'xtick.labelsize': 12,'ytick.labelsize': 12})\n",
    "    fig, (ax, rax) = plt.subplots(nrows=2,ncols=1, figsize=(7,7),\n",
    "    gridspec_kw={\"height_ratios\": (3, 1)}, sharex=True)\n",
    "    fig.subplots_adjust(hspace=.07)\n",
    "    hist.plot1d(background, overlay=\"dataset\",  ax=ax, clear=False, density=False, stack=True,\n",
    "                fill_opts = fillopts2, overflow = 'over')\n",
    "    #hist.plot1d(signal, overlay=\"dataset\", ax=ax, clear=False,density=False, stack=False, \n",
    "    #            error_opts=data_err_opts, overflow = 'over')\n",
    "    hist.plot1d(data, overlay=\"dataset\", ax=ax, clear=False,density=False, stack=False, \n",
    "                error_opts=data_err_opts_rat, overflow = 'over')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylim(0, 10000)\n",
    "    ax.set_xlabel(None)\n",
    "    leg = ax.legend()\n",
    "    hist.plotratio(num=data.sum('dataset'), denom=background.sum('dataset'), ax=rax,\n",
    "                   error_opts = data_err_opts_rat, denom_fill_opts={}, guide_opts={}, \n",
    "                   unc='num', overflow = 'over')\n",
    "    rax.set_ylabel('Ratio')\n",
    "    rax.set_ylim(0,2)\n",
    "    fig.savefig(os.path.join(outdir, \"{}_log.png\".format(name)))\n",
    "    fig.savefig(os.path.join(outdir, \"{}_log.pdf\".format(name)))\n",
    "    fig.clear()\n",
    "\n",
    "def savefigshape(hists, outdir, name):\n",
    "    import re\n",
    "    bkgandsig = re.compile('(?!Data)')\n",
    "    bkganddata = re.compile('(?!mC750_l1)')\n",
    "    allbutLL = re.compile('(?!LL)')\n",
    "    \n",
    "    background = hists[bkgandsig][bkganddata]\n",
    "    otherbackgrounds = hists[bkgandsig][bkganddata][allbutLL]\n",
    "    lostLep = hists['LL']\n",
    "    signal = hists['mC750_1l']\n",
    "    data = hists['Data']\n",
    "    \n",
    "    plt.rcParams.update({'font.size': 14,'axes.titlesize': 18,'axes.labelsize': 18,\n",
    "                         'xtick.labelsize': 12,'ytick.labelsize': 12})\n",
    "    fig, (ax, rax) = plt.subplots(nrows=2,ncols=1, figsize=(7,7),\n",
    "    gridspec_kw={\"height_ratios\": (3, 1)}, sharex=True)\n",
    "    fig.subplots_adjust(hspace=.07)\n",
    "    hist.plot1d(background, overlay=\"dataset\",  ax=ax, clear=False, density=True, \n",
    "                stack=False,line_opts = lineopts2, overflow = 'over')\n",
    "    hist.plot1d(signal, overlay=\"dataset\", ax=ax, clear = False, density=True, stack=False, \n",
    "                error_opts=data_err_opts, overflow = 'over')\n",
    "    hist.plot1d(data, overlay=\"dataset\", ax=ax, clear = False, density=True, stack=False, \n",
    "                error_opts=data_err_opts_rat, overflow = 'over')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylim(0, 10000)\n",
    "    ax.set_xlabel(None)\n",
    "    leg = ax.legend()\n",
    "    hist.plotratio(num=data.sum('dataset'), denom=background.sum('dataset'), ax=rax,\n",
    "                   error_opts = data_err_opts_rat, denom_fill_opts={}, guide_opts={}, \n",
    "                   unc='num', overflow = 'over')\n",
    "    rax.set_ylabel('Ratio')\n",
    "    rax.set_ylim(0,2)\n",
    "    ax.figure.savefig(os.path.join(outdir, \"{}_shape_log.png\".format(name)))\n",
    "    ax.figure.savefig(os.path.join(outdir, \"{}_shape_log.pdf\".format(name)))\n",
    "    ax.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's remind ourselves of the histograms we created so we can loop through them \n",
    "#and create an array to loop through when we rebin. \n",
    "histograms = [\"h_pt_met200_CR\",\n",
    "              \"h_pt_met400_CR\",\n",
    "              \"h_pt_met600_CR\",\n",
    "              \"fj_pt_met200_CR\",\n",
    "              \"fj_pt_met400_CR\",\n",
    "              \"fj_pt_met600_CR\",\n",
    "              \"h_mass_met200_CR\",\n",
    "              \"h_mass_met400_CR\",\n",
    "              \"h_mass_met600_CR\",\n",
    "              \"met_noHiggs\",\n",
    "              \"met_oneHiggs\",\n",
    "              \"met_oneW\",\n",
    "              \"met_inHiggs\",\n",
    "              \"met_outHiggs\",\n",
    "              \"met_Higgs_W_CR\",\n",
    "              \"met_Higgs_CR\",\n",
    "              \"met_W_CR\",\n",
    "              \"met_CR\"\n",
    "             ]\n",
    "\n",
    "#Make sure this points to a directory you can print to!\n",
    "outdir = \"/home/users/ksalyer/CMSSW_10_2_9/src/tW_scattering/tutorialPlots/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_pt_met200_CR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/ksalyer/CMSSW_10_2_9/src/tW_scattering/coffeaEnv/lib/python3.6/site-packages/coffea/hist/plot.py:44: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  warnings.warn(\"All sumw are zero!  Cannot compute meaningful error bars\", RuntimeWarning)\n",
      "/cvmfs/cms.cern.ch/slc6_amd64_gcc700/external/py2-ipykernel/4.8.2-gnimlf2/lib/python3.6/site-packages/ipykernel_launcher.py:60: UserWarning: Attempted to set non-positive bottom ylim on a log-scaled axis.\n",
      "Invalid limit will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_pt_met400_CR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/ksalyer/CMSSW_10_2_9/src/tW_scattering/coffeaEnv/lib/python3.6/site-packages/coffea/hist/plot.py:44: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  warnings.warn(\"All sumw are zero!  Cannot compute meaningful error bars\", RuntimeWarning)\n",
      "/cvmfs/cms.cern.ch/slc6_amd64_gcc700/external/py2-ipykernel/4.8.2-gnimlf2/lib/python3.6/site-packages/ipykernel_launcher.py:60: UserWarning: Attempted to set non-positive bottom ylim on a log-scaled axis.\n",
      "Invalid limit will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_pt_met600_CR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/ksalyer/CMSSW_10_2_9/src/tW_scattering/coffeaEnv/lib/python3.6/site-packages/coffea/hist/plot.py:44: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  warnings.warn(\"All sumw are zero!  Cannot compute meaningful error bars\", RuntimeWarning)\n",
      "/cvmfs/cms.cern.ch/slc6_amd64_gcc700/external/py2-ipykernel/4.8.2-gnimlf2/lib/python3.6/site-packages/ipykernel_launcher.py:60: UserWarning: Attempted to set non-positive bottom ylim on a log-scaled axis.\n",
      "Invalid limit will be ignored.\n",
      "/home/users/ksalyer/CMSSW_10_2_9/src/tW_scattering/coffeaEnv/lib/python3.6/site-packages/numpy/core/_asarray.py:83: UserWarning: Warning: converting a masked element to nan.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fj_pt_met200_CR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/ksalyer/CMSSW_10_2_9/src/tW_scattering/coffeaEnv/lib/python3.6/site-packages/coffea/hist/plot.py:44: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  warnings.warn(\"All sumw are zero!  Cannot compute meaningful error bars\", RuntimeWarning)\n",
      "/cvmfs/cms.cern.ch/slc6_amd64_gcc700/external/py2-ipykernel/4.8.2-gnimlf2/lib/python3.6/site-packages/ipykernel_launcher.py:60: UserWarning: Attempted to set non-positive bottom ylim on a log-scaled axis.\n",
      "Invalid limit will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fj_pt_met400_CR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/ksalyer/CMSSW_10_2_9/src/tW_scattering/coffeaEnv/lib/python3.6/site-packages/coffea/hist/plot.py:44: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  warnings.warn(\"All sumw are zero!  Cannot compute meaningful error bars\", RuntimeWarning)\n",
      "/cvmfs/cms.cern.ch/slc6_amd64_gcc700/external/py2-ipykernel/4.8.2-gnimlf2/lib/python3.6/site-packages/ipykernel_launcher.py:60: UserWarning: Attempted to set non-positive bottom ylim on a log-scaled axis.\n",
      "Invalid limit will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fj_pt_met600_CR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/ksalyer/CMSSW_10_2_9/src/tW_scattering/coffeaEnv/lib/python3.6/site-packages/coffea/hist/plot.py:44: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  warnings.warn(\"All sumw are zero!  Cannot compute meaningful error bars\", RuntimeWarning)\n",
      "/cvmfs/cms.cern.ch/slc6_amd64_gcc700/external/py2-ipykernel/4.8.2-gnimlf2/lib/python3.6/site-packages/ipykernel_launcher.py:60: UserWarning: Attempted to set non-positive bottom ylim on a log-scaled axis.\n",
      "Invalid limit will be ignored.\n",
      "/home/users/ksalyer/CMSSW_10_2_9/src/tW_scattering/coffeaEnv/lib/python3.6/site-packages/numpy/core/_asarray.py:83: UserWarning: Warning: converting a masked element to nan.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_mass_met200_CR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/ksalyer/CMSSW_10_2_9/src/tW_scattering/coffeaEnv/lib/python3.6/site-packages/coffea/hist/plot.py:44: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  warnings.warn(\"All sumw are zero!  Cannot compute meaningful error bars\", RuntimeWarning)\n",
      "/cvmfs/cms.cern.ch/slc6_amd64_gcc700/external/py2-ipykernel/4.8.2-gnimlf2/lib/python3.6/site-packages/ipykernel_launcher.py:60: UserWarning: Attempted to set non-positive bottom ylim on a log-scaled axis.\n",
      "Invalid limit will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_mass_met400_CR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/ksalyer/CMSSW_10_2_9/src/tW_scattering/coffeaEnv/lib/python3.6/site-packages/coffea/hist/plot.py:44: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  warnings.warn(\"All sumw are zero!  Cannot compute meaningful error bars\", RuntimeWarning)\n",
      "/cvmfs/cms.cern.ch/slc6_amd64_gcc700/external/py2-ipykernel/4.8.2-gnimlf2/lib/python3.6/site-packages/ipykernel_launcher.py:60: UserWarning: Attempted to set non-positive bottom ylim on a log-scaled axis.\n",
      "Invalid limit will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_mass_met600_CR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/ksalyer/CMSSW_10_2_9/src/tW_scattering/coffeaEnv/lib/python3.6/site-packages/coffea/hist/plot.py:44: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  warnings.warn(\"All sumw are zero!  Cannot compute meaningful error bars\", RuntimeWarning)\n",
      "/cvmfs/cms.cern.ch/slc6_amd64_gcc700/external/py2-ipykernel/4.8.2-gnimlf2/lib/python3.6/site-packages/ipykernel_launcher.py:60: UserWarning: Attempted to set non-positive bottom ylim on a log-scaled axis.\n",
      "Invalid limit will be ignored.\n",
      "/home/users/ksalyer/CMSSW_10_2_9/src/tW_scattering/coffeaEnv/lib/python3.6/site-packages/numpy/core/_asarray.py:83: UserWarning: Warning: converting a masked element to nan.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "met_noHiggs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/cms.cern.ch/slc6_amd64_gcc700/external/py2-ipykernel/4.8.2-gnimlf2/lib/python3.6/site-packages/ipykernel_launcher.py:60: UserWarning: Attempted to set non-positive bottom ylim on a log-scaled axis.\n",
      "Invalid limit will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "met_oneHiggs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/ksalyer/CMSSW_10_2_9/src/tW_scattering/coffeaEnv/lib/python3.6/site-packages/coffea/hist/plot.py:44: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  warnings.warn(\"All sumw are zero!  Cannot compute meaningful error bars\", RuntimeWarning)\n",
      "/cvmfs/cms.cern.ch/slc6_amd64_gcc700/external/py2-ipykernel/4.8.2-gnimlf2/lib/python3.6/site-packages/ipykernel_launcher.py:60: UserWarning: Attempted to set non-positive bottom ylim on a log-scaled axis.\n",
      "Invalid limit will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "met_oneW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/cms.cern.ch/slc6_amd64_gcc700/external/py2-ipykernel/4.8.2-gnimlf2/lib/python3.6/site-packages/ipykernel_launcher.py:60: UserWarning: Attempted to set non-positive bottom ylim on a log-scaled axis.\n",
      "Invalid limit will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "met_inHiggs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/cms.cern.ch/slc6_amd64_gcc700/external/py2-ipykernel/4.8.2-gnimlf2/lib/python3.6/site-packages/ipykernel_launcher.py:60: UserWarning: Attempted to set non-positive bottom ylim on a log-scaled axis.\n",
      "Invalid limit will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "met_outHiggs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/ksalyer/CMSSW_10_2_9/src/tW_scattering/coffeaEnv/lib/python3.6/site-packages/coffea/hist/plot.py:44: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  warnings.warn(\"All sumw are zero!  Cannot compute meaningful error bars\", RuntimeWarning)\n",
      "/cvmfs/cms.cern.ch/slc6_amd64_gcc700/external/py2-ipykernel/4.8.2-gnimlf2/lib/python3.6/site-packages/ipykernel_launcher.py:60: UserWarning: Attempted to set non-positive bottom ylim on a log-scaled axis.\n",
      "Invalid limit will be ignored.\n",
      "/home/users/ksalyer/CMSSW_10_2_9/src/tW_scattering/coffeaEnv/lib/python3.6/site-packages/numpy/core/_asarray.py:83: UserWarning: Warning: converting a masked element to nan.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "met_Higgs_W_CR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/ksalyer/CMSSW_10_2_9/src/tW_scattering/coffeaEnv/lib/python3.6/site-packages/coffea/hist/plot.py:44: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  warnings.warn(\"All sumw are zero!  Cannot compute meaningful error bars\", RuntimeWarning)\n",
      "/cvmfs/cms.cern.ch/slc6_amd64_gcc700/external/py2-ipykernel/4.8.2-gnimlf2/lib/python3.6/site-packages/ipykernel_launcher.py:60: UserWarning: Attempted to set non-positive bottom ylim on a log-scaled axis.\n",
      "Invalid limit will be ignored.\n",
      "/home/users/ksalyer/CMSSW_10_2_9/src/tW_scattering/coffeaEnv/lib/python3.6/site-packages/numpy/core/_asarray.py:83: UserWarning: Warning: converting a masked element to nan.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "met_Higgs_CR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/ksalyer/CMSSW_10_2_9/src/tW_scattering/coffeaEnv/lib/python3.6/site-packages/coffea/hist/plot.py:44: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  warnings.warn(\"All sumw are zero!  Cannot compute meaningful error bars\", RuntimeWarning)\n",
      "/cvmfs/cms.cern.ch/slc6_amd64_gcc700/external/py2-ipykernel/4.8.2-gnimlf2/lib/python3.6/site-packages/ipykernel_launcher.py:60: UserWarning: Attempted to set non-positive bottom ylim on a log-scaled axis.\n",
      "Invalid limit will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "met_W_CR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/ksalyer/CMSSW_10_2_9/src/tW_scattering/coffeaEnv/lib/python3.6/site-packages/coffea/hist/plot.py:44: RuntimeWarning: All sumw are zero!  Cannot compute meaningful error bars\n",
      "  warnings.warn(\"All sumw are zero!  Cannot compute meaningful error bars\", RuntimeWarning)\n",
      "/cvmfs/cms.cern.ch/slc6_amd64_gcc700/external/py2-ipykernel/4.8.2-gnimlf2/lib/python3.6/site-packages/ipykernel_launcher.py:60: UserWarning: Attempted to set non-positive bottom ylim on a log-scaled axis.\n",
      "Invalid limit will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "met_CR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/cms.cern.ch/slc6_amd64_gcc700/external/py2-ipykernel/4.8.2-gnimlf2/lib/python3.6/site-packages/ipykernel_launcher.py:60: UserWarning: Attempted to set non-positive bottom ylim on a log-scaled axis.\n",
      "Invalid limit will be ignored.\n"
     ]
    }
   ],
   "source": [
    "for name in histograms:\n",
    "    print (name)\n",
    "    hists = output[name]\n",
    "\n",
    "    if name == \"h_pt_met200_CR\":\n",
    "        new_pt_bins = hist.Bin('pt', r'Lead Higgs pT', 20, 200, 1000)\n",
    "        hists = hists.rebin('pt', new_pt_bins)\n",
    "    \n",
    "    if name == \"h_pt_met400_CR\":\n",
    "        new_pt_bins = hist.Bin('pt', r'Lead Higgs pT', 20, 200, 1000)\n",
    "        hists = hists.rebin('pt', new_pt_bins)\n",
    "    \n",
    "    if name == \"h_pt_met600_CR\":\n",
    "        new_pt_bins = hist.Bin('pt', r'Lead Higgs pT', 20, 200, 1000)\n",
    "        hists = hists.rebin('pt', new_pt_bins)\n",
    "\n",
    "        \n",
    "\n",
    "    if name == \"fj_pt_met200_CR\":\n",
    "        new_pt_bins = hist.Bin('pt', r'Lead FatJet pT', 20, 200, 1000)\n",
    "        hists = hists.rebin('pt', new_pt_bins)\n",
    "    \n",
    "    if name == \"fj_pt_met400_CR\":\n",
    "        new_pt_bins = hist.Bin('pt', r'Lead FatJet pT', 20, 200, 1000)\n",
    "        hists = hists.rebin('pt', new_pt_bins)\n",
    "    \n",
    "    if name == \"fj_pt_met600_CR\":\n",
    "        new_pt_bins = hist.Bin('pt', r'Lead FatJet pT', 20, 200, 1000)\n",
    "        hists = hists.rebin('pt', new_pt_bins)\n",
    "        \n",
    "\n",
    "\n",
    "    if name == \"h_mass_met200_CR\":\n",
    "        new_mass_bins = hist.Bin('mass', r'Lead Higgs mass', 15, 0, 300)\n",
    "        hists = hists.rebin('mass', new_mass_bins)\n",
    "    \n",
    "    if name == \"h_mass_met400_CR\":\n",
    "        new_mass_bins = hist.Bin('mass', r'Lead Higgs mass', 15, 0, 300)\n",
    "        hists = hists.rebin('mass', new_mass_bins)\n",
    "    \n",
    "    if name == \"h_mass_met600_CR\":\n",
    "        new_mass_bins = hist.Bin('mass', r'Lead Higgs mass', 15, 0, 300)\n",
    "        hists = hists.rebin('mass', new_mass_bins)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if name == \"met_noHiggs\":\n",
    "        new_pt_bins = hist.Bin('pt', r'MET', 20, 200, 1000)\n",
    "        hists = hists.rebin('pt', new_pt_bins)\n",
    "    \n",
    "    if name == \"met_oneHiggs\":\n",
    "        new_pt_bins = hist.Bin('pt', r'MET', 20, 200, 1000)\n",
    "        hists = hists.rebin('pt', new_pt_bins)\n",
    "    \n",
    "    if name == \"met_oneW\":\n",
    "        new_pt_bins = hist.Bin('pt', r'MET', 20, 200, 1000)\n",
    "        hists = hists.rebin('pt', new_pt_bins)\n",
    "    \n",
    "    if name == \"met_inHiggs\":\n",
    "        new_pt_bins = hist.Bin('pt', r'MET', 20, 200, 1000)\n",
    "        hists = hists.rebin('pt', new_pt_bins)\n",
    "        \n",
    "    if name == \"met_outHiggs\":\n",
    "        new_pt_bins = hist.Bin('pt', r'MET', 20, 200, 1000)\n",
    "        hists = hists.rebin('pt', new_pt_bins)\n",
    "        \n",
    "        \n",
    "        \n",
    "    if name == \"met_Higgs_W_CR\":\n",
    "        new_pt_bins = hist.Bin('pt', r'MET', 5, 200, 700)\n",
    "        hists = hists.rebin('pt', new_pt_bins)\n",
    "        \n",
    "    if name == \"met_Higgs_CR\":\n",
    "        new_pt_bins = hist.Bin('pt', r'MET', 5, 200, 700)\n",
    "        hists = hists.rebin('pt', new_pt_bins)\n",
    "        \n",
    "    if name == \"met_W_CR\":\n",
    "        new_pt_bins = hist.Bin('pt', r'MET', 5, 200, 700)\n",
    "        hists = hists.rebin('pt', new_pt_bins)\n",
    "        \n",
    "    if name == \"met_CR\":\n",
    "        new_pt_bins = hist.Bin('pt', r'MET', 5, 200, 700)\n",
    "        hists = hists.rebin('pt', new_pt_bins)\n",
    "        \n",
    "    savefig(hists, outdir, name)\n",
    "    #savefigshape(hists, outdir, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_err_opts = {\n",
    "    'linestyle': 'none',\n",
    "    'marker': '_',\n",
    "    'markersize': 10.,\n",
    "    'color': 'r',\n",
    "    'elinewidth': 1}\n",
    "\n",
    "ST_CR_err_opts_rat = {\n",
    "    'linestyle': 'none',\n",
    "    'marker': '.',\n",
    "    'markersize': 10.,\n",
    "    'color':'#1982C4',\n",
    "    'elinewidth': 1}\n",
    "\n",
    "ttbar_CR_err_opts_rat = {\n",
    "    'linestyle': 'none',\n",
    "    'marker': '.',\n",
    "    'markersize': 10.,\n",
    "    'color':'#F76F8E',\n",
    "    'elinewidth': 1}\n",
    "\n",
    "wjets_CR_err_opts_rat = {\n",
    "    'linestyle': 'none',\n",
    "    'marker': '.',\n",
    "    'markersize': 10.,\n",
    "    'color':'#8AC926',\n",
    "    'elinewidth': 1}\n",
    "\n",
    "ttW_CR_err_opts_rat = {\n",
    "    'linestyle': 'none',\n",
    "    'marker': '.',\n",
    "    'markersize': 10.,\n",
    "    'color':'#FFCA3A',\n",
    "    'elinewidth': 1}\n",
    "\n",
    "ST_SR_err_opts_rat = {\n",
    "    'linestyle': 'none',\n",
    "    'marker': '.',\n",
    "    'markersize': 10.,\n",
    "    'color':'#FF5714',\n",
    "    'elinewidth': 1}\n",
    "\n",
    "ttbar_SR_err_opts_rat = {\n",
    "    'linestyle': 'none',\n",
    "    'marker': '.',\n",
    "    'markersize': 10.,\n",
    "    'color':'#6A0136',\n",
    "    'elinewidth': 1}\n",
    "\n",
    "wjets_SR_err_opts_rat = {\n",
    "    'linestyle': 'none',\n",
    "    'marker': '.',\n",
    "    'markersize': 10.,\n",
    "    'color':'#989C94',\n",
    "    'elinewidth': 1}\n",
    "\n",
    "ttW_SR_err_opts_rat = {\n",
    "    'linestyle': 'none',\n",
    "    'marker': '.',\n",
    "    'markersize': 10.,\n",
    "    'color':'#613F75',\n",
    "    'elinewidth': 1}\n",
    "\n",
    "\n",
    "\n",
    "#lineOverlayOpts = {\n",
    "#    'color': [('#1982C4'),('#F76F8E'),('#8AC926'),('#FFCA3A')]#, ('#FF5714'), ('#6A0136') ],\n",
    "#}\n",
    "\n",
    "lineOverlayOpts = {\n",
    "    'color': [('#1982C4')],#, ('#A33B20'), ('#680E4B'), ('#F6AE2D'),('#45503B')],\n",
    "}\n",
    "\n",
    "lineOverlayOpts1 = {\n",
    "    'color': [('#F76F8E')],#, ('#A33B20'), ('#680E4B'), ('#F6AE2D'),('#45503B')],\n",
    "}\n",
    "\n",
    "lineOverlayOpts2 = {\n",
    "    'color': [('#8AC926') ],#, ('#A33B20'), ('#680E4B'), ('#F6AE2D'),('#45503B')],\n",
    "}\n",
    "\n",
    "lineOverlayOpts3 = {\n",
    "    'color': [('#FFCA3A') ],#, ('#A33B20'), ('#680E4B'), ('#F6AE2D'),('#45503B')],\n",
    "}\n",
    "\n",
    "lineOverlayOpts4 = {\n",
    "    'color': [('#FF5714') ],#, ('#A33B20'), ('#680E4B'), ('#F6AE2D'),('#45503B')],\n",
    "}\n",
    "\n",
    "lineOverlayOpts5 = {\n",
    "    'color': [('#6A0136') ],#, ('#A33B20'), ('#680E4B'), ('#F6AE2D'),('#45503B')],\n",
    "}\n",
    "\n",
    "lineOverlayOpts6 = {\n",
    "    'color': [('#989C94') ],#, ('#A33B20'), ('#680E4B'), ('#F6AE2D'),('#45503B')],\n",
    "}\n",
    "\n",
    "lineOverlayOpts7 = {\n",
    "    'color': [('#613F75') ],#, ('#A33B20'), ('#680E4B'), ('#F6AE2D'),('#45503B')],\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "fillOverlayOpts = {\n",
    "    'edgecolor': (0,0,0,0.3),\n",
    "    'facecolor': [('#1982C4')],#, ('#A33B20'), ('#680E4B'), ('#F6AE2D'),('#45503B')],\n",
    "    #'facecolor': [('#1467cc'), ('#51d673') ,('#f7d969'), ('#af84f0'), ('#4f842e'), ('#1ff4ff'),('#3612ab')],\n",
    "}\n",
    "\n",
    "fillOverlayOpts1 = {\n",
    "    'edgecolor': (0,0,0,0.3),\n",
    "    'facecolor': [('#F76F8E')],#, ('#A33B20'), ('#680E4B'), ('#F6AE2D'),('#45503B')],\n",
    "    #'facecolor': [('#1467cc'), ('#51d673') ,('#f7d969'), ('#af84f0'), ('#4f842e'), ('#1ff4ff'),('#3612ab')],\n",
    "}\n",
    "\n",
    "fillOverlayOpts2 = {\n",
    "    'edgecolor': (0,0,0,0.3),\n",
    "    'facecolor': [('#8AC926') ],#, ('#A33B20'), ('#680E4B'), ('#F6AE2D'),('#45503B')],\n",
    "    #'facecolor': [('#1467cc'), ('#51d673') ,('#f7d969'), ('#af84f0'), ('#4f842e'), ('#1ff4ff'),('#3612ab')],\n",
    "}\n",
    "\n",
    "fillOverlayOpts3 = {\n",
    "    'edgecolor': (0,0,0,0.3),\n",
    "    'facecolor': [('#FFCA3A') ],#, ('#A33B20'), ('#680E4B'), ('#F6AE2D'),('#45503B')],\n",
    "    #'facecolor': [('#1467cc'), ('#51d673') ,('#f7d969'), ('#af84f0'), ('#4f842e'), ('#1ff4ff'),('#3612ab')],\n",
    "}\n",
    "\n",
    "fillOverlayOpts4 = {\n",
    "    'edgecolor': (0,0,0,0.3),\n",
    "    'facecolor': [('#FF5714') ],#, ('#A33B20'), ('#680E4B'), ('#F6AE2D'),('#45503B')],\n",
    "    #'facecolor': [('#1467cc'), ('#51d673') ,('#f7d969'), ('#af84f0'), ('#4f842e'), ('#1ff4ff'),('#3612ab')],\n",
    "}\n",
    "\n",
    "fillOverlayOpts5 = {\n",
    "    'edgecolor': (0,0,0,0.3),\n",
    "    'facecolor': [('#6A0136') ],#, ('#A33B20'), ('#680E4B'), ('#F6AE2D'),('#45503B')],\n",
    "    #'facecolor': [('#1467cc'), ('#51d673') ,('#f7d969'), ('#af84f0'), ('#4f842e'), ('#1ff4ff'),('#3612ab')],\n",
    "}\n",
    "\n",
    "\n",
    "outdir = \"/home/users/ksalyer/CMSSW_10_2_9/src/tW_scattering/tutorialPlots/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveoverlay(histsCR, histsSR, outdir, name):\n",
    "    import re\n",
    "    #bkgandsig = re.compile('(?!Data)')\n",
    "    bkgonly = re.compile('(?!mC750_l1)')\n",
    "    allbutLL = re.compile('(?!LL)')\n",
    "    allbutZ = re.compile('(?!ZNuNu)')\n",
    "    \n",
    "    #background = hists[bkgonly]\n",
    "    QCDCR = histsCR['QCD']\n",
    "    QCDSR = histsSR['QCD']\n",
    "    lostLepCR = histsCR['LL']\n",
    "    lostLepSR = histsSR['LL']\n",
    "    ZCR = histsCR['ZNuNu']\n",
    "    ZSR = histsSR['ZNuNu']\n",
    "    #signal = hists['mC750_1l']\n",
    "    #data = hists['Data']\n",
    "    \n",
    "    plt.rcParams.update({'font.size': 14,'axes.titlesize': 18,'axes.labelsize': 18,\n",
    "                         'xtick.labelsize': 12,'ytick.labelsize': 12})\n",
    "    fig, (ax, rax) = plt.subplots(nrows=2,ncols=1, figsize=(7,7),\n",
    "    gridspec_kw={\"height_ratios\": (3, 1)}, sharex=True)\n",
    "    fig.subplots_adjust(hspace=.07)\n",
    "    hist.plot1d(lostLepCR, overlay=\"dataset\",  ax=ax, clear=False, density=False, stack=True,\n",
    "                fill_opts = fillOverlayOpts, overflow = 'over')\n",
    "    hist.plot1d(lostLepSR, overlay=\"dataset\",  ax=ax, clear=False, density=False, stack=True,\n",
    "                fill_opts = fillOverlayOpts1, overflow = 'over')\n",
    "    hist.plot1d(ZSR, overlay=\"dataset\",  ax=ax, clear=False, density=False, stack=True,\n",
    "                fill_opts = fillOverlayOpts3, overflow = 'over')\n",
    "    hist.plot1d(ZCR, overlay=\"dataset\",  ax=ax, clear=False, density=False, stack=True,\n",
    "                fill_opts = fillOverlayOpts2, overflow = 'over')\n",
    "    hist.plot1d(QCDSR, overlay=\"dataset\",  ax=ax, clear=False, density=False, stack=True,\n",
    "                fill_opts = fillOverlayOpts5, overflow = 'over')\n",
    "    hist.plot1d(QCDCR, overlay=\"dataset\",  ax=ax, clear=False, density=False, stack=True,\n",
    "                fill_opts = fillOverlayOpts4, overflow = 'over')\n",
    "    #hist.plot1d(signal, overlay=\"dataset\", ax=ax, clear=False,density=False, stack=False, \n",
    "    #            error_opts=data_err_opts, overflow = 'over')\n",
    "    #hist.plot1d(data, overlay=\"dataset\", ax=ax, clear=False,density=False, stack=False, \n",
    "    #            error_opts=data_err_opts_rat, overflow = 'over')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylim(0, 10000)\n",
    "    ax.set_xlabel(None)\n",
    "    leg = ax.legend()\n",
    "    #hist.plotratio(num=data.sum('dataset'), denom=background.sum('dataset'), ax=rax,\n",
    "    #               error_opts = data_err_opts_rat, denom_fill_opts={}, guide_opts={}, \n",
    "    #               unc='num', overflow = 'over')\n",
    "    rax.set_ylabel('Ratio')\n",
    "    rax.set_ylim(0,2)\n",
    "    fig.savefig(os.path.join(outdir, \"{}_log.png\".format(name)))\n",
    "    fig.savefig(os.path.join(outdir, \"{}_log.pdf\".format(name)))\n",
    "    fig.clear()\n",
    "    \n",
    "    \n",
    "def saveoverlayshape(histsCR, histsSR, outdir, name):\n",
    "    import re\n",
    "    #bkgandsig = re.compile('(?!Data)')\n",
    "    bkgonly = re.compile('(?!mC750_l1)')\n",
    "    \n",
    "    ttbarCR = histsCR['TTJets']\n",
    "    ttbarCR_norm = ttbarCR.sum('dataset').values(overflow='over')[()].sum()\n",
    "    ttbarCR.scale({'TTJets':1/ttbarCR_norm}, axis='dataset')\n",
    "    STCR = histsCR['ST']\n",
    "    STCR_norm = STCR.sum('dataset').values(overflow='over')[()].sum()\n",
    "    STCR.scale({'ST':1/STCR_norm}, axis='dataset')\n",
    "    wjetsCR = histsCR['WJets']\n",
    "    wjetsCR_norm = wjetsCR.sum('dataset').values(overflow='over')[()].sum()\n",
    "    wjetsCR.scale({'WJets':1/wjetsCR_norm}, axis='dataset')\n",
    "    ttwCR = histsCR['ttW']\n",
    "    ttwCR_norm = ttwCR.sum('dataset').values(overflow='over')[()].sum()\n",
    "    ttwCR.scale({'ttW':1/ttwCR_norm}, axis='dataset')\n",
    "    \n",
    "    ttbarSR = histsSR['TTJets']\n",
    "    ttbarSR_norm = ttbarSR.sum('dataset').values(overflow='over')[()].sum()\n",
    "    ttbarSR.scale({'TTJets':1/ttbarSR_norm}, axis='dataset')\n",
    "    STSR = histsSR['ST']\n",
    "    STSR_norm = STSR.sum('dataset').values(overflow='over')[()].sum()\n",
    "    STSR.scale({'ST':1/STSR_norm}, axis='dataset')\n",
    "    wjetsSR = histsSR['WJets']\n",
    "    wjetsSR_norm = wjetsSR.sum('dataset').values(overflow='over')[()].sum()\n",
    "    wjetsSR.scale({'WJets':1/wjetsSR_norm}, axis='dataset')\n",
    "    ttwSR = histsSR['ttW']\n",
    "    ttwSR_norm = ttwSR.sum('dataset').values(overflow='over')[()].sum()\n",
    "    ttwSR.scale({'ttW':1/ttwSR_norm}, axis='dataset')\n",
    "    \n",
    "    #signal = hists['mC750_1l']\n",
    "    #data = histsCR['Data']\n",
    "    \n",
    "    plt.rcParams.update({'font.size': 14,'axes.titlesize': 18,'axes.labelsize': 18,\n",
    "                         'xtick.labelsize': 12,'ytick.labelsize': 12})\n",
    "    fig, (ax, rax) = plt.subplots(nrows=2,ncols=1, figsize=(7,7),\n",
    "    gridspec_kw={\"height_ratios\": (3, 1)}, sharex=True)\n",
    "    fig.subplots_adjust(hspace=.07)\n",
    "    hist.plot1d(STCR,overlay=\"dataset\", ax=ax, overflow='over', clear=False, line_opts = lineOverlayOpts)\n",
    "    hist.plot1d(ttbarCR,overlay=\"dataset\", ax=ax, overflow='over', clear=False, line_opts = lineOverlayOpts1)\n",
    "    hist.plot1d(wjetsCR,overlay=\"dataset\", ax=ax, overflow='over', clear=False, line_opts = lineOverlayOpts2)\n",
    "    hist.plot1d(ttwCR,overlay=\"dataset\", ax=ax, overflow='over', clear=False, line_opts = lineOverlayOpts3)\n",
    "    hist.plot1d(STSR,overlay=\"dataset\", ax=ax, overflow='over', clear=False, line_opts = lineOverlayOpts4)\n",
    "    hist.plot1d(ttbarSR,overlay=\"dataset\", ax=ax, overflow='over', clear=False, line_opts = lineOverlayOpts5)\n",
    "    hist.plot1d(wjetsSR,overlay=\"dataset\", ax=ax, overflow='over', clear=False, line_opts = lineOverlayOpts6)\n",
    "    hist.plot1d(ttwSR,overlay=\"dataset\", ax=ax, overflow='over', clear=False, line_opts = lineOverlayOpts7)\n",
    "    #hist.plot1d(background, overlay=\"dataset\",  ax=ax, clear=False, density = True, stack=False,\n",
    "    #            line_opts = lineOverlayOpts, overflow = 'over')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylim(0, 10000)\n",
    "    ax.set_xlabel(None)\n",
    "    leg = ax.legend()\n",
    "    hist.plotratio(num=STCR.sum('dataset'), denom=STSR.sum('dataset'), ax=rax, clear = False,\n",
    "                   error_opts = ST_CR_err_opts_rat, denom_fill_opts={}, guide_opts={},  \n",
    "                   unc='num', overflow = 'over')\n",
    "    hist.plotratio(num=ttbarCR.sum('dataset'), denom=ttbarSR.sum('dataset'), ax=rax, clear = False,\n",
    "                   error_opts = ttbar_CR_err_opts_rat, denom_fill_opts={}, guide_opts={},  \n",
    "                   unc='num', overflow = 'over')\n",
    "    hist.plotratio(num=wjetsCR.sum('dataset'), denom=wjetsSR.sum('dataset'), ax=rax, clear = False,\n",
    "                   error_opts = wjets_CR_err_opts_rat, denom_fill_opts={}, guide_opts={},  \n",
    "                   unc='num', overflow = 'over')\n",
    "    hist.plotratio(num=ttwCR.sum('dataset'), denom=ttwSR.sum('dataset'), ax=rax, clear = False,\n",
    "                   error_opts = ttW_CR_err_opts_rat, denom_fill_opts={}, guide_opts={},  \n",
    "                   unc='num', overflow = 'over')\n",
    "    rax.set_ylabel('Ratio')\n",
    "    rax.set_ylim(0,2)\n",
    "    #fig.savefig(os.path.join(outdir, \"{}_log.png\".format(name)))\n",
    "    fig.savefig(os.path.join(outdir, \"{}_all_log.pdf\".format(name)))\n",
    "    fig.clear()\n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.rcParams.update({'font.size': 14,'axes.titlesize': 18,'axes.labelsize': 18,\n",
    "                         'xtick.labelsize': 12,'ytick.labelsize': 12})\n",
    "    fig, (ax, rax) = plt.subplots(nrows=2,ncols=1, figsize=(7,7),\n",
    "    gridspec_kw={\"height_ratios\": (3, 1)}, sharex=True)\n",
    "    fig.subplots_adjust(hspace=.07)\n",
    "    hist.plot1d(STCR,overlay=\"dataset\", ax=ax, overflow='over', clear=False, line_opts = lineOverlayOpts)\n",
    "    hist.plot1d(STSR,overlay=\"dataset\", ax=ax, overflow='over', clear=False, line_opts = lineOverlayOpts4)\n",
    "    #hist.plot1d(background, overlay=\"dataset\",  ax=ax, clear=False, density = True, stack=False,\n",
    "    #            line_opts = lineOverlayOpts, overflow = 'over')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylim(0, 10000)\n",
    "    ax.set_xlabel(None)\n",
    "    leg = ax.legend()\n",
    "    hist.plotratio(num=STCR.sum('dataset'), denom=STSR.sum('dataset'), ax=rax, clear = False,\n",
    "                   error_opts = ST_CR_err_opts_rat, denom_fill_opts={}, guide_opts={},  \n",
    "                   unc='num', overflow = 'over')\n",
    "    rax.set_ylabel('Ratio')\n",
    "    rax.set_ylim(0,2)\n",
    "    #fig.savefig(os.path.join(outdir, \"{}_log.png\".format(name)))\n",
    "    fig.savefig(os.path.join(outdir, \"{}_ST_log.pdf\".format(name)))\n",
    "    fig.clear()\n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.rcParams.update({'font.size': 14,'axes.titlesize': 18,'axes.labelsize': 18,\n",
    "                         'xtick.labelsize': 12,'ytick.labelsize': 12})\n",
    "    fig, (ax, rax) = plt.subplots(nrows=2,ncols=1, figsize=(7,7),\n",
    "    gridspec_kw={\"height_ratios\": (3, 1)}, sharex=True)\n",
    "    fig.subplots_adjust(hspace=.07)\n",
    "    hist.plot1d(ttbarCR,overlay=\"dataset\", ax=ax, overflow='over', clear = False, line_opts = lineOverlayOpts1)\n",
    "    hist.plot1d(ttbarSR,overlay=\"dataset\", ax=ax, overflow='over', clear = False, line_opts = lineOverlayOpts5)\n",
    "    #hist.plot1d(background, overlay=\"dataset\",  ax=ax, clear=False, density = True, stack=False,\n",
    "    #            line_opts = lineOverlayOpts, overflow = 'over')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylim(0, 10000)\n",
    "    ax.set_xlabel(None)\n",
    "    leg = ax.legend()\n",
    "    hist.plotratio(num=ttbarCR.sum('dataset'), denom=ttbarSR.sum('dataset'), ax=rax, clear = False,\n",
    "                   error_opts = ttbar_CR_err_opts_rat, denom_fill_opts={}, guide_opts={}, \n",
    "                   unc='num', overflow = 'over')\n",
    "    rax.set_ylabel('Ratio')\n",
    "    rax.set_ylim(0,2)\n",
    "    #fig.savefig(os.path.join(outdir, \"{}_log.png\".format(name)))\n",
    "    fig.savefig(os.path.join(outdir, \"{}_ttbar_log.pdf\".format(name)))\n",
    "    fig.clear()\n",
    "    \n",
    "    plt.rcParams.update({'font.size': 14,'axes.titlesize': 18,'axes.labelsize': 18,\n",
    "                         'xtick.labelsize': 12,'ytick.labelsize': 12})\n",
    "    fig, (ax, rax) = plt.subplots(nrows=2,ncols=1, figsize=(7,7),\n",
    "    gridspec_kw={\"height_ratios\": (3, 1)}, sharex=True)\n",
    "    fig.subplots_adjust(hspace=.07)\n",
    "    hist.plot1d(wjetsCR,overlay=\"dataset\", ax=ax, overflow='over', clear = False, line_opts = lineOverlayOpts2)\n",
    "    hist.plot1d(wjetsSR,overlay=\"dataset\", ax=ax, overflow='over', clear = False, line_opts = lineOverlayOpts6)\n",
    "    #hist.plot1d(background, overlay=\"dataset\",  ax=ax, clear=False, density = True, stack=False,\n",
    "    #            line_opts = lineOverlayOpts, overflow = 'over')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylim(0, 10000)\n",
    "    ax.set_xlabel(None)\n",
    "    leg = ax.legend()\n",
    "    hist.plotratio(num=wjetsCR.sum('dataset'), denom=wjetsSR.sum('dataset'), ax=rax, clear = False,\n",
    "                   error_opts = wjets_CR_err_opts_rat, denom_fill_opts={}, guide_opts={}, \n",
    "                   unc='num', overflow = 'over')\n",
    "    rax.set_ylabel('Ratio')\n",
    "    rax.set_ylim(0,2)\n",
    "    #fig.savefig(os.path.join(outdir, \"{}_log.png\".format(name)))\n",
    "    fig.savefig(os.path.join(outdir, \"{}_wjets_log.pdf\".format(name)))\n",
    "    fig.clear()\n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.rcParams.update({'font.size': 14,'axes.titlesize': 18,'axes.labelsize': 18,\n",
    "                         'xtick.labelsize': 12,'ytick.labelsize': 12})\n",
    "    fig, (ax, rax) = plt.subplots(nrows=2,ncols=1, figsize=(7,7),\n",
    "    gridspec_kw={\"height_ratios\": (3, 1)}, sharex=True)\n",
    "    fig.subplots_adjust(hspace=.07)\n",
    "    hist.plot1d(ttwCR,overlay=\"dataset\", ax=ax, overflow='over', clear=False, line_opts = lineOverlayOpts3)\n",
    "    hist.plot1d(ttwSR,overlay=\"dataset\", ax=ax, overflow='over', clear=False, line_opts = lineOverlayOpts7)\n",
    "    #hist.plot1d(background, overlay=\"dataset\",  ax=ax, clear=False, density = True, stack=False,\n",
    "    #            line_opts = lineOverlayOpts, overflow = 'over')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylim(0, 10000)\n",
    "    ax.set_xlabel(None)\n",
    "    leg = ax.legend()\n",
    "    hist.plotratio(num=ttwCR.sum('dataset'), denom=ttwSR.sum('dataset'), ax=rax, clear = False,\n",
    "                   error_opts = ttW_CR_err_opts_rat, denom_fill_opts={}, guide_opts={}, \n",
    "                   unc='num', overflow = 'over')\n",
    "    rax.set_ylabel('Ratio')\n",
    "    rax.set_ylim(0,2)\n",
    "    #fig.savefig(os.path.join(outdir, \"{}_log.png\".format(name)))\n",
    "    fig.savefig(os.path.join(outdir, \"{}_ttw_log.pdf\".format(name)))\n",
    "    fig.clear()\n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.rcParams.update({'font.size': 14,'axes.titlesize': 18,'axes.labelsize': 18,\n",
    "                         'xtick.labelsize': 12,'ytick.labelsize': 12})\n",
    "    fig, (ax, rax) = plt.subplots(nrows=2,ncols=1, figsize=(7,7),\n",
    "    gridspec_kw={\"height_ratios\": (3, 1)}, sharex=True)\n",
    "    fig.subplots_adjust(hspace=.07)\n",
    "    hist.plot1d(STCR,overlay=\"dataset\", ax=ax, overflow='over', clear=False, line_opts = lineOverlayOpts)\n",
    "    hist.plot1d(ttbarCR,overlay=\"dataset\", ax=ax, overflow='over', clear = False, line_opts = lineOverlayOpts1)\n",
    "    hist.plot1d(wjetsCR,overlay=\"dataset\", ax=ax, overflow='over', clear = False, line_opts = lineOverlayOpts2)\n",
    "    hist.plot1d(ttwCR,overlay=\"dataset\", ax=ax, overflow='over', clear=False, line_opts = lineOverlayOpts3)\n",
    "    hist.plot1d(STSR,overlay=\"dataset\", ax=ax, overflow='over', clear=False, line_opts = lineOverlayOpts4)\n",
    "    hist.plot1d(ttbarSR,overlay=\"dataset\", ax=ax, overflow='over', clear = False, line_opts = lineOverlayOpts5)\n",
    "    hist.plot1d(wjetsSR,overlay=\"dataset\", ax=ax, overflow='over', clear = False, line_opts = lineOverlayOpts6)\n",
    "    hist.plot1d(ttwSR,overlay=\"dataset\", ax=ax, overflow='over', clear=False, line_opts = lineOverlayOpts7)\n",
    "    #hist.plot1d(background, overlay=\"dataset\",  ax=ax, clear=False, density = True, stack=False,\n",
    "    #            line_opts = lineOverlayOpts, overflow = 'over')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylim(0, 10000)\n",
    "    ax.set_xlabel(None)\n",
    "    leg = ax.legend()\n",
    "    hist.plotratio(num=STCR.sum('dataset'), denom=STSR.sum('dataset'), ax=rax, clear = False,\n",
    "                   error_opts = ST_CR_err_opts_rat, denom_fill_opts={}, guide_opts={},  \n",
    "                   unc='num', overflow = 'over')\n",
    "    hist.plotratio(num=ttbarCR.sum('dataset'), denom=ttbarSR.sum('dataset'), ax=rax, clear = False,\n",
    "                   error_opts = ttbar_CR_err_opts_rat, denom_fill_opts={}, guide_opts={}, \n",
    "                   unc='num', overflow = 'over')\n",
    "    hist.plotratio(num=wjetsCR.sum('dataset'), denom=wjetsSR.sum('dataset'), ax=rax, clear = False,\n",
    "                   error_opts = wjets_CR_err_opts_rat, denom_fill_opts={}, guide_opts={}, \n",
    "                   unc='num', overflow = 'over')\n",
    "    hist.plotratio(num=ttwCR.sum('dataset'), denom=ttwSR.sum('dataset'), ax=rax, clear = False,\n",
    "                   error_opts = ttW_CR_err_opts_rat, denom_fill_opts={}, guide_opts={}, \n",
    "                   unc='num', overflow = 'over')\n",
    "    rax.set_ylabel('Ratio')\n",
    "    rax.set_ylim(0,2)\n",
    "    #fig.savefig(os.path.join(outdir, \"{}_log.png\".format(name)))\n",
    "    fig.savefig(os.path.join(outdir, \"{}_log.pdf\".format(name)))\n",
    "    fig.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histsCR = output[\"met_CR\"]\n",
    "histsSR = output[\"met_SR\"]\n",
    "#print(type(histsCR))\n",
    "new_pt_bins = hist.Bin('pt',r'MET',5,200,700)\n",
    "histsCR = histsCR.rebin('pt',new_pt_bins)\n",
    "histsSR = histsSR.rebin('pt',new_pt_bins)\n",
    "#saveoverlay(histsCR,histsSR,outdir,\"MET_overlay\")\n",
    "saveoverlayshape(histsCR,histsSR,outdir,\"MET_overlay_shape\")\n",
    "\n",
    "histsCR = output[\"met_Higgs_CR\"]\n",
    "histsSR = output[\"met_Higgs_SR\"]\n",
    "new_pt_bins = hist.Bin('pt',r'MET',5,200,700)\n",
    "histsCR = histsCR.rebin('pt',new_pt_bins)\n",
    "histsSR = histsSR.rebin('pt',new_pt_bins)\n",
    "#saveoverlay(histsCR,histsSR,outdir,\"MET_Higgs_overlay\")\n",
    "saveoverlayshape(histsCR,histsSR,outdir,\"MET_Higgs_overlay_shape\")\n",
    "\n",
    "histsCR = output[\"met_W_CR\"]\n",
    "histsSR = output[\"met_W_SR\"]\n",
    "new_pt_bins = hist.Bin('pt',r'MET',5,200,700)\n",
    "histsCR = histsCR.rebin('pt',new_pt_bins)\n",
    "histsSR = histsSR.rebin('pt',new_pt_bins)\n",
    "#saveoverlay(histsCR,histsSR,outdir,\"MET_W_overlay\")\n",
    "saveoverlayshape(histsCR,histsSR,outdir,\"MET_W_overlay_shape\")\n",
    "\n",
    "histsCR = output[\"met_Higgs_W_CR\"]\n",
    "histsSR = output[\"met_Higgs_W_SR\"]\n",
    "new_pt_bins = hist.Bin('pt',r'MET',5,200,700)\n",
    "histsCR = histsCR.rebin('pt',new_pt_bins)\n",
    "histsSR = histsSR.rebin('pt',new_pt_bins)\n",
    "#saveoverlay(histsCR,histsSR,outdir,\"MET_Higgs_W_overlay\")\n",
    "saveoverlayshape(histsCR,histsSR,outdir,\"MET_Higgs_W_overlay_shape\")\n",
    "\n",
    "histsCR = output[\"met_CR\"]\n",
    "histsSR = output[\"met_Higgs_W_SR\"]\n",
    "new_pt_bins = hist.Bin('pt',r'MET',5,200,700)\n",
    "histsCR = histsCR.rebin('pt',new_pt_bins)\n",
    "histsSR = histsSR.rebin('pt',new_pt_bins)\n",
    "#saveoverlay(histsCR,histsSR,outdir,\"MET_Higgs_W_overlay\")\n",
    "saveoverlayshape(histsCR,histsSR,outdir,\"MET_CR_Higgs_W_overlay_shape\")\n",
    "\n",
    "histsCR = output[\"met_Higgs_CR\"]\n",
    "histsSR = output[\"met_Higgs_W_SR\"]\n",
    "new_pt_bins = hist.Bin('pt',r'MET',5,200,700)\n",
    "histsCR = histsCR.rebin('pt',new_pt_bins)\n",
    "histsSR = histsSR.rebin('pt',new_pt_bins)\n",
    "#saveoverlay(histsCR,histsSR,outdir,\"MET_Higgs_W_overlay\")\n",
    "saveoverlayshape(histsCR,histsSR,outdir,\"MET_Higgs_CR_Higgs_W_overlay_shape\")\n",
    "\n",
    "histsCR = output[\"met_W_CR\"]\n",
    "histsSR = output[\"met_Higgs_W_SR\"]\n",
    "new_pt_bins = hist.Bin('pt',r'MET',5,200,700)\n",
    "histsCR = histsCR.rebin('pt',new_pt_bins)\n",
    "histsSR = histsSR.rebin('pt',new_pt_bins)\n",
    "#saveoverlay(histsCR,histsSR,outdir,\"MET_Higgs_W_overlay\")\n",
    "saveoverlayshape(histsCR,histsSR,outdir,\"MET_W_CR_Higgs_W_overlay_shape\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coffeaEnv",
   "language": "python",
   "name": "coffeaenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

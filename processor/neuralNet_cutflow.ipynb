{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "from klepto.archives import dir_archive\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import coffea.processor as processor\n",
    "from coffea.processor.accumulator import AccumulatorABC\n",
    "from coffea.analysis_objects import JaggedCandidateArray\n",
    "from coffea.btag_tools import BTagScaleFactor\n",
    "from coffea import hist\n",
    "import pandas as pd\n",
    "import uproot_methods\n",
    "import uproot\n",
    "import awkward\n",
    "import copy\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "from Tools.config_helpers import *\n",
    "from Tools.helpers import mergeArray, mt\n",
    "\n",
    "from Tools.objects import Collections\n",
    "from Tools.cutflow import Cutflow\n",
    "\n",
    "# This just tells matplotlib not to open any\n",
    "# interactive windows.\n",
    "matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_and_flatten(val): \n",
    "    try:\n",
    "        return val.pad(1, clip=True).fillna(0.).flatten()#.reshape(-1, 1)\n",
    "    except AttributeError:\n",
    "        return val.flatten()\n",
    "\n",
    "os.environ['KERAS_BACKEND'] = 'theano'\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.setrecursionlimit(10000)\n",
    "print(sys.getrecursionlimit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class analysisProcessor(processor.ProcessorABC):\n",
    "    \"\"\"Processor used for running the analysis\"\"\"\n",
    "    def __init__(self):\n",
    "        \n",
    "        ## load the NN\n",
    "        self.model = load_model('../ML/data/training.h5')\n",
    "        self.stds  = pd.read_json('../ML/data/stds.json').squeeze()\n",
    "        self.means = pd.read_json('../ML/data/means.json').squeeze()\n",
    "        \n",
    "        ## load b-tag SFs\n",
    "        #self.btag_sf = BTagScaleFactor(os.path.expandvars(\"$TWHOME/data/DeepCSV_102XSF_V1.btag.csv.gz\", \"reshape\")\n",
    "        \n",
    "        # we can use a large number of bins and rebin later\n",
    "        dataset_axis        = hist.Cat(\"dataset\",   \"Primary dataset\")\n",
    "        pt_axis             = hist.Bin(\"pt\",        r\"$p_{T}$ (GeV)\", 1000, 0, 1000)\n",
    "        p_axis              = hist.Bin(\"p\",         r\"$p$ (GeV)\", 1000, 0, 2500)\n",
    "        ht_axis             = hist.Bin(\"ht\",        r\"$H_{T}$ (GeV)\", 500, 0, 5000)\n",
    "        mass_axis           = hist.Bin(\"mass\",      r\"M (GeV)\", 1000, 0, 2000)\n",
    "        eta_axis            = hist.Bin(\"eta\",       r\"$\\eta$\", 60, -5.5, 5.5)\n",
    "        delta_axis          = hist.Bin(\"delta\",     r\"$\\delta$\", 100,0,10 )\n",
    "        multiplicity_axis   = hist.Bin(\"multiplicity\",         r\"N\", 20, -0.5, 19.5)\n",
    "        norm_axis           = hist.Bin(\"norm\",         r\"N\", 25, 0, 1)\n",
    "\n",
    "        self._accumulator = processor.dict_accumulator({\n",
    "            \"MET_pt_baseline\" :          hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "            \"HT_baseline\" :              hist.Hist(\"Counts\", dataset_axis, ht_axis),\n",
    "            \"mtb_min_baseline\" :         hist.Hist(\"Counts\", dataset_axis, mass_axis),\n",
    "            \"MET_pt\" :          hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "            \"HT\" :              hist.Hist(\"Counts\", dataset_axis, ht_axis),\n",
    "            \"mtb_min\" :         hist.Hist(\"Counts\", dataset_axis, mass_axis),\n",
    "            \"MET_pt_SR\" :       hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "            \"HT_SR\" :           hist.Hist(\"Counts\", dataset_axis, ht_axis),\n",
    "            \"mtb_min_SR\" :      hist.Hist(\"Counts\", dataset_axis, mass_axis),\n",
    "            \"lead_AK8_pt\" :     hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "            \"W_pt\" :            hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "            \"H_pt\" :            hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "            \"W_eta\" :           hist.Hist(\"Counts\", dataset_axis, eta_axis),\n",
    "            \"H_eta\" :           hist.Hist(\"Counts\", dataset_axis, eta_axis),\n",
    "            \n",
    "            \"N_b\" :             hist.Hist(\"Counts\", dataset_axis, multiplicity_axis),\n",
    "            \"N_AK4\" :           hist.Hist(\"Counts\", dataset_axis, multiplicity_axis),\n",
    "            \"N_AK8\" :           hist.Hist(\"Counts\", dataset_axis, multiplicity_axis),\n",
    "            \"N_H\" :             hist.Hist(\"Counts\", dataset_axis, multiplicity_axis),\n",
    "            \"N_W\" :             hist.Hist(\"Counts\", dataset_axis, multiplicity_axis),\n",
    "            \n",
    "            \"WH_deltaPhi\":      hist.Hist(\"Counts\", dataset_axis, delta_axis),\n",
    "            \"WH_deltaR\":        hist.Hist(\"Counts\", dataset_axis, delta_axis),\n",
    "            \"bb_deltaPhi\":      hist.Hist(\"Counts\", dataset_axis, delta_axis),\n",
    "            \"bb_deltaR\":        hist.Hist(\"Counts\", dataset_axis, delta_axis),\n",
    "            \"min_dphiJetMet4\":  hist.Hist(\"Counts\", dataset_axis, delta_axis),\n",
    "            \"dphiDiJet\":        hist.Hist(\"Counts\", dataset_axis, delta_axis),\n",
    "            \"dphiDiFatJet\":     hist.Hist(\"Counts\", dataset_axis, delta_axis),\n",
    "            \n",
    "            \"neuralNet_score\":  hist.Hist(\"Counts\", dataset_axis, norm_axis),\n",
    "            \n",
    "            'mC750_l1':         processor.defaultdict_accumulator(int),\n",
    "            'WJets':            processor.defaultdict_accumulator(int),\n",
    "            'QCD':              processor.defaultdict_accumulator(int),\n",
    "            'TTJets':           processor.defaultdict_accumulator(int),\n",
    "            'ZNuNu':            processor.defaultdict_accumulator(int),\n",
    "            'ST':               processor.defaultdict_accumulator(int),\n",
    "            'ttW/ttZ':          processor.defaultdict_accumulator(int),\n",
    "            'WW/WZ/ZZ':         processor.defaultdict_accumulator(int),\n",
    "            'LL':               processor.defaultdict_accumulator(int),\n",
    "            'totalEvents':      processor.defaultdict_accumulator(int),\n",
    "            'test1':            processor.defaultdict_accumulator(float),\n",
    "        })\n",
    "\n",
    "    @property\n",
    "    def accumulator(self):\n",
    "        return self._accumulator\n",
    "\n",
    "    def process(self, df):\n",
    "        \"\"\"\n",
    "        Processing function. This is where the actual analysis happens.\n",
    "        \"\"\"\n",
    "        output = self.accumulator.identity()\n",
    "        dataset = df[\"dataset\"]\n",
    "        cfg = loadConfig()\n",
    "        \n",
    "        ## MET -> can switch to puppi MET\n",
    "        met_pt  = df[\"MET_pt\"]\n",
    "        met_phi = df[\"MET_phi\"]\n",
    "        \n",
    "        ## Muons\n",
    "        muon = JaggedCandidateArray.candidatesfromcounts(\n",
    "            df['nMuon'],\n",
    "            pt = df['Muon_pt'].content,\n",
    "            eta = df['Muon_eta'].content,\n",
    "            phi = df['Muon_phi'].content,\n",
    "            mass = df['Muon_mass'].content,\n",
    "            miniPFRelIso_all=df['Muon_miniPFRelIso_all'].content,\n",
    "            looseId =df['Muon_looseId'].content\n",
    "            )\n",
    "        muon = muon[(muon.pt > 10) & (abs(muon.eta) < 2.4) & (muon.looseId) & (muon.miniPFRelIso_all < 0.2)]\n",
    "        #muon = Collections(df, \"Muon\", \"tightTTH\").get() # this needs a fix for DASK\n",
    "        \n",
    "        electrons = JaggedCandidateArray.candidatesfromcounts(\n",
    "            df['nElectron'],\n",
    "            pt=df['Electron_pt'].content, \n",
    "            eta=df['Electron_eta'].content, \n",
    "            phi=df['Electron_phi'].content,\n",
    "            mass=df['Electron_mass'].content,\n",
    "            pdgid=df['Electron_pdgId'].content,\n",
    "            mini_iso=df['Electron_miniPFRelIso_all'].content\n",
    "        )\n",
    "        \n",
    "        ## Electrons\n",
    "        electron = JaggedCandidateArray.candidatesfromcounts(\n",
    "            df['nElectron'],\n",
    "            pt = df['Electron_pt'].content,\n",
    "            eta = df['Electron_eta'].content,\n",
    "            phi = df['Electron_phi'].content,\n",
    "            mass = df['Electron_mass'].content,\n",
    "            miniPFRelIso_all=df['Electron_miniPFRelIso_all'].content,\n",
    "            cutBased=df['Electron_cutBased'].content\n",
    "            )\n",
    "        electron = electron[(electron.pt>10) & (abs(electron.eta) < 2.4) & (electron.miniPFRelIso_all < 0.1) &  (electron.cutBased >= 1)]\n",
    "        #electron = Collections(df, \"Electron\", \"tightTTH\").get() # this needs a fix for DASK\n",
    "        \n",
    "        ## FatJets\n",
    "        fatjet = JaggedCandidateArray.candidatesfromcounts(\n",
    "            df['nFatJet'],\n",
    "            pt = df['FatJet_pt'].content,\n",
    "            eta = df['FatJet_eta'].content,\n",
    "            phi = df['FatJet_phi'].content,\n",
    "            mass = df['FatJet_mass'].content,\n",
    "            msoftdrop = df[\"FatJet_msoftdrop\"].content,  \n",
    "            deepTagMD_HbbvsQCD = df['FatJet_deepTagMD_HbbvsQCD'].content, \n",
    "            deepTagMD_WvsQCD = df['FatJet_deepTagMD_WvsQCD'].content, \n",
    "            deepTag_WvsQCD = df['FatJet_deepTag_WvsQCD'].content\n",
    "            \n",
    "        )\n",
    "        \n",
    "        leadingFatJets = fatjet[:,:2]\n",
    "        difatjet = leadingFatJets.choose(2)\n",
    "        dphiDiFatJet = np.arccos(np.cos(difatjet.i0.phi-difatjet.i1.phi))\n",
    "        \n",
    "        htag = fatjet[((fatjet.pt > 200) & (fatjet.deepTagMD_HbbvsQCD > 0.8365))]\n",
    "        htag_hard = fatjet[((fatjet.pt > 300) & (fatjet.deepTagMD_HbbvsQCD > 0.8365))]\n",
    "        \n",
    "        lead_htag = htag[htag.pt.argmax()]\n",
    "        \n",
    "        wtag = fatjet[((fatjet.pt > 200) & (fatjet.deepTagMD_HbbvsQCD < 0.8365) & (fatjet.deepTag_WvsQCD > 0.918))]\n",
    "        wtag_hard = fatjet[((fatjet.pt > 300) & (fatjet.deepTagMD_HbbvsQCD < 0.8365) & (fatjet.deepTag_WvsQCD > 0.918))]\n",
    "        \n",
    "        lead_wtag = wtag[wtag.pt.argmax()]\n",
    "        \n",
    "        wh = lead_htag.cross(lead_wtag)\n",
    "        wh_deltaPhi = np.arccos(wh.i0.phi - wh.i1.phi)\n",
    "        wh_deltaR = wh.i0.p4.delta_r(wh.i1.p4)\n",
    "        \n",
    "        ## Jets\n",
    "        jet = JaggedCandidateArray.candidatesfromcounts(\n",
    "            df['nJet'],\n",
    "            pt = df['Jet_pt'].content,\n",
    "            eta = df['Jet_eta'].content,\n",
    "            phi = df['Jet_phi'].content,\n",
    "            mass = df['Jet_mass'].content,\n",
    "            jetId = df['Jet_jetId'].content, # https://twiki.cern.ch/twiki/bin/view/CMS/JetID\n",
    "            #puId = df['Jet_puId'].content, # https://twiki.cern.ch/twiki/bin/viewauth/CMS/PileupJetID\n",
    "            btagDeepB = df['Jet_btagDeepB'].content, # https://twiki.cern.ch/twiki/bin/viewauth/CMS/BtagRecommendation102X\n",
    "            #deepJet = df['Jet_'].content # not there yet?\n",
    "        )\n",
    "        \n",
    "        jet       = jet[(jet.pt>30) & (abs(jet.eta)<2.4) & (jet.jetId>0)]\n",
    "        jet       = jet[(jet.pt>30) & (jet.jetId>1) & (abs(jet.eta)<2.4)]\n",
    "        jet       = jet[~jet.match(muon, deltaRCut=0.4)] # remove jets that overlap with muons\n",
    "        jet       = jet[~jet.match(electron, deltaRCut=0.4)] # remove jets that overlap with electrons\n",
    "        jet       = jet[jet.pt.argsort(ascending=False)] # sort the jets\n",
    "        btag      = jet[(jet.btagDeepB>0.4184)]\n",
    "        light     = jet[(jet.btagDeepB<0.4184)]\n",
    "        \n",
    "        ## Get the leading b-jets\n",
    "        high_score_btag = jet[jet.btagDeepB.argsort(ascending=False)][:,:2]\n",
    "        \n",
    "        leadingJets = jet[:,:2]\n",
    "        dijet = leadingJets.choose(2)\n",
    "        dphiDiJet = np.arccos(np.cos(dijet.i0.phi-dijet.i1.phi))\n",
    "        \n",
    "        leading_jet = leadingJets[leadingJets.pt.argmax()]\n",
    "        subleading_jet = leadingJets[leadingJets.pt.argmin()]\n",
    "        leading_b      = btag[btag.pt.argmax()]\n",
    "        \n",
    "        bb = high_score_btag.choose(2)\n",
    "        bb_deltaPhi = np.arccos(np.cos(bb.i0.phi-bb.i1.phi))\n",
    "        bb_deltaR = bb.i0.p4.delta_r(bb.i1.p4)\n",
    "        \n",
    "        mtb = mt(btag.pt, btag.phi, met_pt, met_phi)\n",
    "        \n",
    "        ## other variables\n",
    "        ht = jet.pt.sum()\n",
    "        met_sig = met_pt/np.sqrt(ht)\n",
    "\n",
    "        min_dphiJetMet4 = np.arccos(np.cos(jet[:,:4].phi-met_phi)).min()\n",
    "        #goodjcut = ((jets.pt>30) & (abs(jets.eta)<2.4) & (jets.jetid>0))\n",
    "        #goodjets = jets[goodjcut]\n",
    "        #abs_min_dphi_met_leadjs4 = abs(np.arccos(np.cos(goodjets[:,:4].phi-metphi)).min())\n",
    "        #print(min_dphiJetMet4.shape)\n",
    "        #print(self.means['min_dphi_met_j4'].shape)\n",
    "        \n",
    "    \n",
    "        NN_inputs = np.stack([\n",
    "            # normalize\n",
    "            pad_and_flatten( (met_pt - self.means['met'])/self.stds['met'] ),\n",
    "            pad_and_flatten( (ht - self.means['ht'])/self.stds['ht'] ),\n",
    "            pad_and_flatten( (leading_jet.pt - self.means['lead_jet_pt'])/self.stds['lead_jet_pt'] ),\n",
    "            pad_and_flatten( (subleading_jet.pt - self.means['sublead_jet_pt'])/self.stds['sublead_jet_pt'] ),\n",
    "            pad_and_flatten( (jet.counts - self.means['njets'])/self.stds['njets'] ),\n",
    "            pad_and_flatten( (btag.counts - self.means['bjets'])/self.stds['bjets'] ),\n",
    "            pad_and_flatten( (wtag.counts - self.means['nWs'])/self.stds['nWs'] ),\n",
    "            pad_and_flatten( (htag.counts - self.means['nHs'])/self.stds['nHs'] ),\n",
    "            pad_and_flatten( (fatjet.counts - self.means['nFatJets'])/self.stds['nFatJets'] ),\n",
    "            pad_and_flatten( (met_sig - self.means['met_significance'])/self.stds['met_significance'] ),\n",
    "            pad_and_flatten( (min_dphiJetMet4 - self.means['min_dphi_met_j4'])/self.stds['min_dphi_met_j4'] ),\n",
    "        ])\n",
    "        \n",
    "        NN_inputs = np.moveaxis(NN_inputs, 0, 1)\n",
    "        NN_score = self.model.predict(NN_inputs)\n",
    "        \n",
    "        ## define selections (maybe move to a different file at some point)\n",
    "        \n",
    "        output['totalEvents']['all'] += len(df['weight'])\n",
    "        \n",
    "        # Cutflow\n",
    "        #processes = ['mC750_l1', 'WJets', 'QCD', 'TTJets', 'ZNuNu', 'ST', 'ttW/ttZ', 'WW/WZ/ZZ']\n",
    "        processes = ['mC750_l1', 'LL', 'QCD', 'ZNuNu']\n",
    "        cutflow = Cutflow(output, df, cfg, processes)\n",
    "        \n",
    "        cutflow.addRow( 'electron veto',   (electron.counts==0) )\n",
    "        cutflow.addRow( 'muon veto',   (muon.counts==0) )\n",
    "        cutflow.addRow( 'MET>250',     (met_pt>250) )\n",
    "        cutflow.addRow( 'njet2',       (jet.counts>=2) )\n",
    "        cutflow.addRow( 'jetveto',       (jet.counts<=5) )\n",
    "        cutflow.addRow( 'nbtag',       (btag.counts>=1) )\n",
    "        \n",
    "        baseline = copy.deepcopy(cutflow.selection)\n",
    "        \n",
    "        cutflow.addRow( 'min_dphiJetMet4', (min_dphiJetMet4>0.5))\n",
    "        cutflow.addRow( 'dphiDiJet', (dphiDiJet.min()<2.5) ) # the min doesn't do anything here\n",
    "        cutflow.addRow( 'dphiDiFatJet', (dphiDiFatJet<2.5).all() ) # by using .all() I do not implicitely cut on the number of fat jets\n",
    "        \n",
    "        vetoQCD = copy.deepcopy(cutflow.selection)\n",
    "        \n",
    "        cutflow.addRow( 'HT>400',      (ht>400) )\n",
    "        cutflow.addRow( 'N_fatjet>0',      (fatjet.counts>0) )\n",
    "        cutflow.addRow( 'N_htag>0',     (htag.counts>0))\n",
    "        cutflow.addRow( 'NN_score>0.4',     (NN_score.flatten()>0.4))\n",
    "        cutflow.addRow( 'NN_score>0.5',     (NN_score.flatten()>0.5))\n",
    "        cutflow.addRow( 'NN_score>0.6',     (NN_score.flatten()>0.6))\n",
    "        cutflow.addRow( 'NN_score>0.7',     (NN_score.flatten()>0.7))\n",
    "        cutflow.addRow( 'NN_score>0.8',     (NN_score.flatten()>0.8))\n",
    "        cutflow.addRow( 'NN_score>0.9',     (NN_score.flatten()>0.9))\n",
    "        cutflow.addRow( 'NN_score>0.91',     (NN_score.flatten()>0.91))\n",
    "        cutflow.addRow( 'NN_score>0.92',     (NN_score.flatten()>0.92))\n",
    "        cutflow.addRow( 'NN_score>0.93',     (NN_score.flatten()>0.93))\n",
    "        cutflow.addRow( 'NN_score>0.94',     (NN_score.flatten()>0.94))\n",
    "        cutflow.addRow( 'NN_score>0.95',     (NN_score.flatten()>0.95))\n",
    "        cutflow.addRow( 'NN_score>0.96',     (NN_score.flatten()>0.96))\n",
    "        cutflow.addRow( 'NN_score>0.97',     (NN_score.flatten()>0.97))\n",
    "        cutflow.addRow( 'NN_score>0.98',     (NN_score.flatten()>0.98))\n",
    "        cutflow.addRow( 'NN_score>0.99',     (NN_score.flatten()>0.99))\n",
    "        #cutflow.addRow( 'N_fatjet>1',      (fatjet.counts>1) )\n",
    "        #cutflow.addRow( 'N_wtag>0',     (wtag.counts>0))\n",
    "        \n",
    "        event_selection = copy.deepcopy(cutflow.selection)\n",
    "        \n",
    "        cutflow.addRow( 'N_htag>0 hard',     (htag_hard.counts>0))\n",
    "        cutflow.addRow( 'MET>400',     (met_pt>400) )\n",
    "\n",
    "        # signal enriched selection of events\n",
    "        signal_selection = cutflow.selection\n",
    "        \n",
    "        ### And fill the histograms\n",
    "        output['MET_pt_baseline'].fill(dataset=dataset, pt=met_pt[baseline].flatten(), weight=df['weight'][baseline]*cfg['lumi'])\n",
    "        output['HT_baseline'].fill(dataset=dataset, ht=ht[baseline].flatten(), weight=df['weight'][baseline]*cfg['lumi'])\n",
    "        output['mtb_min_baseline'].fill(dataset=dataset, mass=mtb[baseline].min().flatten(), weight=df['weight'][baseline]*cfg['lumi'])\n",
    "\n",
    "        output['MET_pt'].fill(dataset=dataset, pt=met_pt[vetoQCD].flatten(), weight=df['weight'][vetoQCD]*cfg['lumi'])\n",
    "        output['HT'].fill(dataset=dataset, ht=ht[vetoQCD].flatten(), weight=df['weight'][vetoQCD]*cfg['lumi'])\n",
    "        output['mtb_min'].fill(dataset=dataset, mass=mtb[vetoQCD].min().flatten(), weight=df['weight'][vetoQCD]*cfg['lumi'])\n",
    "        \n",
    "        ## N jet and N b without selections on those\n",
    "        output['N_AK4'].fill(dataset=dataset, multiplicity=jet[baseline].counts, weight=df['weight'][baseline]*cfg['lumi'])\n",
    "        output['N_b'].fill(dataset=dataset, multiplicity=btag[baseline].counts, weight=df['weight'][baseline]*cfg['lumi'])       \n",
    "        output['N_W'].fill(dataset=dataset, multiplicity=htag[baseline].counts, weight=df['weight'][baseline]*cfg['lumi'])       \n",
    "        output['N_H'].fill(dataset=dataset, multiplicity=wtag[baseline].counts, weight=df['weight'][baseline]*cfg['lumi'])       \n",
    "        output['N_AK8'].fill(dataset=dataset, multiplicity=fatjet[baseline].counts, weight=df['weight'][baseline]*cfg['lumi'])       \n",
    "\n",
    "        output['bb_deltaPhi'].fill(dataset=dataset, delta=bb_deltaPhi[baseline].flatten(), weight=df['weight'][baseline]*cfg['lumi'])\n",
    "        output['bb_deltaR'].fill(dataset=dataset, delta=bb_deltaR[baseline].flatten(), weight=df['weight'][baseline]*cfg['lumi'])\n",
    "\n",
    "        output['min_dphiJetMet4'].fill(dataset=dataset, delta=min_dphiJetMet4[baseline].flatten(), weight=df['weight'][baseline]*cfg['lumi'])\n",
    "        output['dphiDiJet'].fill(dataset=dataset, delta=dphiDiJet[baseline].min().flatten(), weight=df['weight'][baseline]*cfg['lumi'])\n",
    "\n",
    "        ## Higgs and W pt\n",
    "        output['lead_AK8_pt'].fill(dataset=dataset, pt=fatjet[(baseline & (fatjet.counts>0))].pt.max().flatten(), weight=df['weight'][(baseline & (fatjet.counts>0))]*cfg['lumi'])\n",
    "        output['dphiDiFatJet'].fill(dataset=dataset, delta=dphiDiFatJet[(baseline & (fatjet.counts>1))].min().flatten(), weight=df['weight'][(baseline & (fatjet.counts>1))]*cfg['lumi'])\n",
    "\n",
    "        output['H_pt'].fill(dataset=dataset, pt=lead_htag[event_selection].pt.flatten(), weight=df['weight'][event_selection]*cfg['lumi'])\n",
    "        output['H_eta'].fill(dataset=dataset, eta=lead_htag[event_selection].eta.flatten(), weight=df['weight'][event_selection]*cfg['lumi'])\n",
    "\n",
    "        #output['W_pt'].fill(dataset=dataset, pt=lead_wtag[event_selection].pt.flatten(), weight=df['weight'][event_selection]*cfg['lumi'])\n",
    "        #output['W_eta'].fill(dataset=dataset, eta=lead_wtag[event_selection].eta.flatten(), weight=df['weight'][event_selection]*cfg['lumi'])\n",
    "\n",
    "        #output['WH_deltaPhi'].fill(dataset=dataset, delta=wh_deltaPhi[event_selection].flatten(), weight=df['weight'][event_selection]*cfg['lumi'])\n",
    "        #output['WH_deltaR'].fill(dataset=dataset, delta=wh_deltaR[event_selection].flatten(), weight=df['weight'][event_selection]*cfg['lumi'])\n",
    "\n",
    "        output['MET_pt_SR'].fill(dataset=dataset, pt=met_pt[event_selection].flatten(), weight=df['weight'][event_selection]*cfg['lumi'])\n",
    "        output['HT_SR'].fill(dataset=dataset, ht=ht[event_selection].flatten(), weight=df['weight'][event_selection]*cfg['lumi'])\n",
    "        output['mtb_min_SR'].fill(dataset=dataset, mass=mtb[event_selection].min().flatten(), weight=df['weight'][event_selection]*cfg['lumi'])\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def postprocess(self, accumulator):\n",
    "        return accumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "runLocal = True\n",
    "\n",
    "\n",
    "if not runLocal:\n",
    "    # Get the scheduler from the dask_cluster notebook\n",
    "    from dask.distributed import Client, progress\n",
    "\n",
    "    c = Client('tcp://169.228.130.5:27879')\n",
    "\n",
    "    ## for dask\n",
    "    exe_args = {\n",
    "        'client': c,\n",
    "        #'savemetrics': True,\n",
    "    }\n",
    "    exe = processor.dask_executor\n",
    "    \n",
    "else:\n",
    "    ## for local\n",
    "    exe_args = {\n",
    "        'workers': 4,\n",
    "        'function_args': {'flatten': False}\n",
    "    }\n",
    "    exe = processor.futures_executor\n",
    "\n",
    "if not runLocal:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "414aac3551764db38c2484c06e35950c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(HTML(value='Processing'), FloatProgress(value=0.0, max=495.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "overwrite = True\n",
    "small = False\n",
    "\n",
    "tag = '0p1p20'\n",
    "#tag = '0p1p16/2018'\n",
    "\n",
    "fileset_WH   = {'mC750_l1': glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/WH_had_750_1_nanoAOD/*.root'),\n",
    "                'WJets': glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/WJetsToLNu*/*.root'),\n",
    "                'QCD': glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/QCD_HT*/*.root'),\n",
    "                'TTJets': glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/TTJets*/*.root'),\n",
    "                'ZNuNu': glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/ZJetsToNuNu*/*.root'),\n",
    "                'ST': glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/ST*/*.root'),\n",
    "                'ttW/ttZ': glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/ttWJets*/*.root')\n",
    "                    +glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/ttZJets*/*.root'),\n",
    "                'WW/WZ/ZZ': glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/WW*/*.root')\n",
    "                    +glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/WZ*/*.root')\n",
    "                    +glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/ZZTo2L2Nu*/*.root')\n",
    "                    +glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/ZZTo2Q2Nu*/*.root')\n",
    "                }\n",
    "\n",
    "fileset_WH_merge = {'mC750_l1': glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/WH_had_750_1_nanoAOD/*.root'),\n",
    "                'LL': glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/WJetsToLNu*/*.root')\n",
    "                    + glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/TTJets*/*.root')\n",
    "                    + glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/ST*/*.root')\n",
    "                    + glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/ttWJets*/*.root')\n",
    "                    + glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/WW*/*.root'),\n",
    "                'QCD': glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/QCD_HT*/*.root'),\n",
    "                'ZNuNu': glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/ZJetsToNuNu*/*.root')\n",
    "                    + glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/ttZJets*/*.root')\n",
    "                    + glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/WZ*/*.root')\n",
    "                    + glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/ZZTo2L2Nu*/*.root')\n",
    "                    + glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/ZZTo2Q2Nu*/*.root')\n",
    "                }\n",
    "\n",
    "\n",
    "# load the config and the cache\n",
    "cfg = loadConfig()\n",
    "\n",
    "cacheName = 'WH_small' if small else 'WH'\n",
    "\n",
    "# histograms\n",
    "histograms = []\n",
    "histograms += ['N_AK4']\n",
    "\n",
    "# initialize cache\n",
    "cache = dir_archive(os.path.join(os.path.expandvars(cfg['caches']['base']), cfg['caches'][cacheName]), serialized=True)\n",
    "if not overwrite:\n",
    "    cache.load()\n",
    "\n",
    "if cfg == cache.get('cfg') and histograms == cache.get('histograms') and cache.get('simple_output'):\n",
    "    output = cache.get('simple_output')\n",
    "\n",
    "else:\n",
    "    # Run the processor\n",
    "    if small:\n",
    "        fileset = {\n",
    "                    'mC750_l1': glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/WH_had_750_1_nanoAOD/*.root'),\n",
    "                    'LL': glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/ttWJets*/*.root')[:2],\n",
    "                    'QCD': glob.glob('/hadoop/cms/store/user/ksalyer/allHadTest/'+tag+'/QCD_HT*/*.root')[:2]}\n",
    "        workers = 4\n",
    "    else:\n",
    "        fileset = fileset_WH_merge\n",
    "        workers = 16\n",
    "    \n",
    "        \n",
    "    output = processor.run_uproot_job(fileset,\n",
    "                                      treename='Events',\n",
    "                                      processor_instance=analysisProcessor(),\n",
    "                                      executor=exe,\n",
    "                                      executor_args=exe_args,\n",
    "                                      #chunksize=250000,\n",
    "                                      chunksize=100000,\n",
    "                                     )\n",
    "    cache['fileset']        = fileset\n",
    "    cache['cfg']            = cfg\n",
    "    cache['histograms']     = histograms\n",
    "    cache['simple_output']  = output\n",
    "    cache.dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mC750_l1</th>\n",
       "      <th>LL</th>\n",
       "      <th>QCD</th>\n",
       "      <th>ZNuNu</th>\n",
       "      <th>S/B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>entry</th>\n",
       "      <td>298.0 +/- 1.4</td>\n",
       "      <td>7743000.0 +/- 18000.0</td>\n",
       "      <td>3910000.0 +/- 28000.0</td>\n",
       "      <td>1808000.0 +/- 1000.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>electron veto</th>\n",
       "      <td>296.1 +/- 1.4</td>\n",
       "      <td>5988000.0 +/- 16000.0</td>\n",
       "      <td>3893000.0 +/- 28000.0</td>\n",
       "      <td>1792000.0 +/- 1000.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>muon veto</th>\n",
       "      <td>293.1 +/- 1.4</td>\n",
       "      <td>3909000.0 +/- 13000.0</td>\n",
       "      <td>3133000.0 +/- 16000.0</td>\n",
       "      <td>1773000.0 +/- 1000.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MET&gt;250</th>\n",
       "      <td>267.4 +/- 1.3</td>\n",
       "      <td>1556000.0 +/- 8000.0</td>\n",
       "      <td>907900.0 +/- 6300.0</td>\n",
       "      <td>813100.0 +/- 500.0</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>njet2</th>\n",
       "      <td>266.7 +/- 1.3</td>\n",
       "      <td>1479000.0 +/- 8000.0</td>\n",
       "      <td>896100.0 +/- 5800.0</td>\n",
       "      <td>756600.0 +/- 500.0</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jetveto</th>\n",
       "      <td>239.2 +/- 1.3</td>\n",
       "      <td>1392000.0 +/- 8000.0</td>\n",
       "      <td>827200.0 +/- 5700.0</td>\n",
       "      <td>743400.0 +/- 500.0</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nbtag</th>\n",
       "      <td>197.1 +/- 1.2</td>\n",
       "      <td>260800.0 +/- 2700.0</td>\n",
       "      <td>187100.0 +/- 2900.0</td>\n",
       "      <td>79900.0 +/- 160.0</td>\n",
       "      <td>0.0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_dphiJetMet4</th>\n",
       "      <td>173.0 +/- 1.1</td>\n",
       "      <td>127700.0 +/- 1900.0</td>\n",
       "      <td>3504.0 +/- 1180.0</td>\n",
       "      <td>65640.0 +/- 150.0</td>\n",
       "      <td>0.0009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dphiDiJet</th>\n",
       "      <td>153.5 +/- 1.0</td>\n",
       "      <td>109000.0 +/- 1700.0</td>\n",
       "      <td>1469.0 +/- 257.0</td>\n",
       "      <td>59840.0 +/- 140.0</td>\n",
       "      <td>0.0009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dphiDiFatJet</th>\n",
       "      <td>150.8 +/- 1.0</td>\n",
       "      <td>107600.0 +/- 1700.0</td>\n",
       "      <td>1324.0 +/- 253.0</td>\n",
       "      <td>59550.0 +/- 140.0</td>\n",
       "      <td>0.0009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HT&gt;400</th>\n",
       "      <td>142.9 +/- 1.0</td>\n",
       "      <td>48970.0 +/- 1130.0</td>\n",
       "      <td>896.0 +/- 187.1</td>\n",
       "      <td>23770.0 +/- 60.0</td>\n",
       "      <td>0.0019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N_fatjet&gt;0</th>\n",
       "      <td>142.5 +/- 1.0</td>\n",
       "      <td>47670.0 +/- 1120.0</td>\n",
       "      <td>896.0 +/- 187.1</td>\n",
       "      <td>23520.0 +/- 60.0</td>\n",
       "      <td>0.0020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N_htag&gt;0</th>\n",
       "      <td>66.8 +/- 0.67</td>\n",
       "      <td>4780.0 +/- 312.0</td>\n",
       "      <td>127.8 +/- 78.1</td>\n",
       "      <td>2207.0 +/- 18.0</td>\n",
       "      <td>0.0094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN_score&gt;0.4</th>\n",
       "      <td>62.94 +/- 0.65</td>\n",
       "      <td>1341.0 +/- 180.0</td>\n",
       "      <td>91.46 +/- 75.35</td>\n",
       "      <td>934.9 +/- 10.6</td>\n",
       "      <td>0.0266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN_score&gt;0.5</th>\n",
       "      <td>61.17 +/- 0.64</td>\n",
       "      <td>983.1 +/- 147.5</td>\n",
       "      <td>87.43 +/- 75.32</td>\n",
       "      <td>741.6 +/- 9.3</td>\n",
       "      <td>0.0338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN_score&gt;0.6</th>\n",
       "      <td>58.89 +/- 0.63</td>\n",
       "      <td>767.2 +/- 147.0</td>\n",
       "      <td>86.18 +/- 75.31</td>\n",
       "      <td>575.7 +/- 8.0</td>\n",
       "      <td>0.0412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN_score&gt;0.7</th>\n",
       "      <td>55.19 +/- 0.61</td>\n",
       "      <td>480.1 +/- 104.3</td>\n",
       "      <td>84.94 +/- 75.3</td>\n",
       "      <td>423.8 +/- 6.8</td>\n",
       "      <td>0.0558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN_score&gt;0.8</th>\n",
       "      <td>48.95 +/- 0.58</td>\n",
       "      <td>215.7 +/- 12.6</td>\n",
       "      <td>75.17 +/- 74.67</td>\n",
       "      <td>273.5 +/- 5.3</td>\n",
       "      <td>0.0867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN_score&gt;0.9</th>\n",
       "      <td>34.99 +/- 0.49</td>\n",
       "      <td>66.7 +/- 6.93</td>\n",
       "      <td>0.508 +/- 0.508</td>\n",
       "      <td>112.7 +/- 3.4</td>\n",
       "      <td>0.1944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN_score&gt;0.91</th>\n",
       "      <td>33.15 +/- 0.47</td>\n",
       "      <td>59.54 +/- 6.82</td>\n",
       "      <td>0.508 +/- 0.508</td>\n",
       "      <td>97.23 +/- 3.02</td>\n",
       "      <td>0.2108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN_score&gt;0.92</th>\n",
       "      <td>31.07 +/- 0.46</td>\n",
       "      <td>47.93 +/- 5.74</td>\n",
       "      <td>0.508 +/- 0.508</td>\n",
       "      <td>80.79 +/- 2.78</td>\n",
       "      <td>0.2404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN_score&gt;0.93</th>\n",
       "      <td>28.67 +/- 0.44</td>\n",
       "      <td>41.79 +/- 5.64</td>\n",
       "      <td>0.508 +/- 0.508</td>\n",
       "      <td>63.79 +/- 2.49</td>\n",
       "      <td>0.2702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN_score&gt;0.94</th>\n",
       "      <td>26.26 +/- 0.42</td>\n",
       "      <td>31.56 +/- 4.29</td>\n",
       "      <td>0.508 +/- 0.508</td>\n",
       "      <td>48.87 +/- 2.22</td>\n",
       "      <td>0.3245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN_score&gt;0.95</th>\n",
       "      <td>23.69 +/- 0.4</td>\n",
       "      <td>22.96 +/- 4.01</td>\n",
       "      <td>0.508 +/- 0.508</td>\n",
       "      <td>34.03 +/- 1.68</td>\n",
       "      <td>0.4121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN_score&gt;0.96</th>\n",
       "      <td>20.88 +/- 0.38</td>\n",
       "      <td>15.52 +/- 2.91</td>\n",
       "      <td>0.508 +/- 0.508</td>\n",
       "      <td>22.08 +/- 1.34</td>\n",
       "      <td>0.5479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN_score&gt;0.97</th>\n",
       "      <td>17.86 +/- 0.35</td>\n",
       "      <td>9.967 +/- 2.683</td>\n",
       "      <td>0 +/- 0.0</td>\n",
       "      <td>11.45 +/- 0.93</td>\n",
       "      <td>0.8340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN_score&gt;0.98</th>\n",
       "      <td>13.97 +/- 0.31</td>\n",
       "      <td>7.046 +/- 2.558</td>\n",
       "      <td>0 +/- 0.0</td>\n",
       "      <td>4.993 +/- 0.607</td>\n",
       "      <td>1.1603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN_score&gt;0.99</th>\n",
       "      <td>7.326 +/- 0.222</td>\n",
       "      <td>1.039 +/- 0.446</td>\n",
       "      <td>0 +/- 0.0</td>\n",
       "      <td>0.948 +/- 0.255</td>\n",
       "      <td>3.6870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        mC750_l1                     LL  \\\n",
       "entry              298.0 +/- 1.4  7743000.0 +/- 18000.0   \n",
       "electron veto      296.1 +/- 1.4  5988000.0 +/- 16000.0   \n",
       "muon veto          293.1 +/- 1.4  3909000.0 +/- 13000.0   \n",
       "MET>250            267.4 +/- 1.3   1556000.0 +/- 8000.0   \n",
       "njet2              266.7 +/- 1.3   1479000.0 +/- 8000.0   \n",
       "jetveto            239.2 +/- 1.3   1392000.0 +/- 8000.0   \n",
       "nbtag              197.1 +/- 1.2    260800.0 +/- 2700.0   \n",
       "min_dphiJetMet4    173.0 +/- 1.1    127700.0 +/- 1900.0   \n",
       "dphiDiJet          153.5 +/- 1.0    109000.0 +/- 1700.0   \n",
       "dphiDiFatJet       150.8 +/- 1.0    107600.0 +/- 1700.0   \n",
       "HT>400             142.9 +/- 1.0     48970.0 +/- 1130.0   \n",
       "N_fatjet>0         142.5 +/- 1.0     47670.0 +/- 1120.0   \n",
       "N_htag>0           66.8 +/- 0.67       4780.0 +/- 312.0   \n",
       "NN_score>0.4      62.94 +/- 0.65       1341.0 +/- 180.0   \n",
       "NN_score>0.5      61.17 +/- 0.64        983.1 +/- 147.5   \n",
       "NN_score>0.6      58.89 +/- 0.63        767.2 +/- 147.0   \n",
       "NN_score>0.7      55.19 +/- 0.61        480.1 +/- 104.3   \n",
       "NN_score>0.8      48.95 +/- 0.58         215.7 +/- 12.6   \n",
       "NN_score>0.9      34.99 +/- 0.49          66.7 +/- 6.93   \n",
       "NN_score>0.91     33.15 +/- 0.47         59.54 +/- 6.82   \n",
       "NN_score>0.92     31.07 +/- 0.46         47.93 +/- 5.74   \n",
       "NN_score>0.93     28.67 +/- 0.44         41.79 +/- 5.64   \n",
       "NN_score>0.94     26.26 +/- 0.42         31.56 +/- 4.29   \n",
       "NN_score>0.95      23.69 +/- 0.4         22.96 +/- 4.01   \n",
       "NN_score>0.96     20.88 +/- 0.38         15.52 +/- 2.91   \n",
       "NN_score>0.97     17.86 +/- 0.35        9.967 +/- 2.683   \n",
       "NN_score>0.98     13.97 +/- 0.31        7.046 +/- 2.558   \n",
       "NN_score>0.99    7.326 +/- 0.222        1.039 +/- 0.446   \n",
       "\n",
       "                                   QCD                 ZNuNu     S/B  \n",
       "entry            3910000.0 +/- 28000.0  1808000.0 +/- 1000.0  0.0000  \n",
       "electron veto    3893000.0 +/- 28000.0  1792000.0 +/- 1000.0  0.0000  \n",
       "muon veto        3133000.0 +/- 16000.0  1773000.0 +/- 1000.0  0.0000  \n",
       "MET>250            907900.0 +/- 6300.0    813100.0 +/- 500.0  0.0001  \n",
       "njet2              896100.0 +/- 5800.0    756600.0 +/- 500.0  0.0001  \n",
       "jetveto            827200.0 +/- 5700.0    743400.0 +/- 500.0  0.0001  \n",
       "nbtag              187100.0 +/- 2900.0     79900.0 +/- 160.0  0.0004  \n",
       "min_dphiJetMet4      3504.0 +/- 1180.0     65640.0 +/- 150.0  0.0009  \n",
       "dphiDiJet             1469.0 +/- 257.0     59840.0 +/- 140.0  0.0009  \n",
       "dphiDiFatJet          1324.0 +/- 253.0     59550.0 +/- 140.0  0.0009  \n",
       "HT>400                 896.0 +/- 187.1      23770.0 +/- 60.0  0.0019  \n",
       "N_fatjet>0             896.0 +/- 187.1      23520.0 +/- 60.0  0.0020  \n",
       "N_htag>0                127.8 +/- 78.1       2207.0 +/- 18.0  0.0094  \n",
       "NN_score>0.4           91.46 +/- 75.35        934.9 +/- 10.6  0.0266  \n",
       "NN_score>0.5           87.43 +/- 75.32         741.6 +/- 9.3  0.0338  \n",
       "NN_score>0.6           86.18 +/- 75.31         575.7 +/- 8.0  0.0412  \n",
       "NN_score>0.7            84.94 +/- 75.3         423.8 +/- 6.8  0.0558  \n",
       "NN_score>0.8           75.17 +/- 74.67         273.5 +/- 5.3  0.0867  \n",
       "NN_score>0.9           0.508 +/- 0.508         112.7 +/- 3.4  0.1944  \n",
       "NN_score>0.91          0.508 +/- 0.508        97.23 +/- 3.02  0.2108  \n",
       "NN_score>0.92          0.508 +/- 0.508        80.79 +/- 2.78  0.2404  \n",
       "NN_score>0.93          0.508 +/- 0.508        63.79 +/- 2.49  0.2702  \n",
       "NN_score>0.94          0.508 +/- 0.508        48.87 +/- 2.22  0.3245  \n",
       "NN_score>0.95          0.508 +/- 0.508        34.03 +/- 1.68  0.4121  \n",
       "NN_score>0.96          0.508 +/- 0.508        22.08 +/- 1.34  0.5479  \n",
       "NN_score>0.97                0 +/- 0.0        11.45 +/- 0.93  0.8340  \n",
       "NN_score>0.98                0 +/- 0.0       4.993 +/- 0.607  1.1603  \n",
       "NN_score>0.99                0 +/- 0.0       0.948 +/- 0.255  3.6870  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cutflow\n",
    "from Tools.helpers import getCutFlowTable\n",
    "\n",
    "#processes = ['mC750_l1', 'WJets', 'QCD', 'TTJets', 'ZNuNu', 'ST', 'ttW/ttZ', 'WW/WZ/ZZ']\n",
    "processes = ['mC750_l1', 'LL', 'QCD', 'ZNuNu']\n",
    "lines     = ['entry']\n",
    "lines    += ['electron veto', 'muon veto',  'MET>250', 'njet2', 'jetveto', 'nbtag', 'min_dphiJetMet4', 'dphiDiJet', 'dphiDiFatJet',  'HT>400', 'N_fatjet>0', 'N_htag>0',  'NN_score>0.4',  'NN_score>0.5',  'NN_score>0.6',  'NN_score>0.7',  'NN_score>0.8',  'NN_score>0.9',  'NN_score>0.91',  'NN_score>0.92',  'NN_score>0.93',  'NN_score>0.94',  'NN_score>0.95',  'NN_score>0.96',  'NN_score>0.97',  'NN_score>0.98',  'NN_score>0.99']#'N_fatjet>1', 'N_wtag>0', 'N_htag>0 hard',  'MET>400']\n",
    "df        = getCutFlowTable(output, processes=processes, lines=lines, significantFigures=4, signal='mC750_l1')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mC750_l1</th>\n",
       "      <th>LL</th>\n",
       "      <th>QCD</th>\n",
       "      <th>ZNuNu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>entry</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>electron veto</th>\n",
       "      <td>0.994</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>muon veto</th>\n",
       "      <td>0.990</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MET&gt;250</th>\n",
       "      <td>0.913</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>njet2</th>\n",
       "      <td>0.997</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jetveto</th>\n",
       "      <td>0.897</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nbtag</th>\n",
       "      <td>0.824</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_dphiJetMet4</th>\n",
       "      <td>0.877</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dphiDiJet</th>\n",
       "      <td>0.888</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dphiDiFatJet</th>\n",
       "      <td>0.982</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HT&gt;400</th>\n",
       "      <td>0.948</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N_fatjet&gt;0</th>\n",
       "      <td>0.997</td>\n",
       "      <td>0.973</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N_htag&gt;0</th>\n",
       "      <td>0.469</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN_score&gt;0.4</th>\n",
       "      <td>0.942</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN_score&gt;0.5</th>\n",
       "      <td>0.972</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN_score&gt;0.6</th>\n",
       "      <td>0.963</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN_score&gt;0.7</th>\n",
       "      <td>0.937</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN_score&gt;0.8</th>\n",
       "      <td>0.887</td>\n",
       "      <td>0.449</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN_score&gt;0.9</th>\n",
       "      <td>0.715</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN_score&gt;0.91</th>\n",
       "      <td>0.947</td>\n",
       "      <td>0.893</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN_score&gt;0.92</th>\n",
       "      <td>0.937</td>\n",
       "      <td>0.805</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN_score&gt;0.93</th>\n",
       "      <td>0.923</td>\n",
       "      <td>0.872</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN_score&gt;0.94</th>\n",
       "      <td>0.916</td>\n",
       "      <td>0.755</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN_score&gt;0.95</th>\n",
       "      <td>0.902</td>\n",
       "      <td>0.728</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN_score&gt;0.96</th>\n",
       "      <td>0.881</td>\n",
       "      <td>0.676</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN_score&gt;0.97</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN_score&gt;0.98</th>\n",
       "      <td>0.782</td>\n",
       "      <td>0.707</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NN_score&gt;0.99</th>\n",
       "      <td>0.524</td>\n",
       "      <td>0.147</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 mC750_l1     LL    QCD  ZNuNu\n",
       "entry               1.000  1.000  1.000  1.000\n",
       "electron veto       0.994  0.773  0.996  0.991\n",
       "muon veto           0.990  0.653  0.805  0.990\n",
       "MET>250             0.913  0.398  0.290  0.459\n",
       "njet2               0.997  0.950  0.987  0.931\n",
       "jetveto             0.897  0.941  0.923  0.983\n",
       "nbtag               0.824  0.187  0.226  0.107\n",
       "min_dphiJetMet4     0.877  0.490  0.019  0.821\n",
       "dphiDiJet           0.888  0.853  0.419  0.912\n",
       "dphiDiFatJet        0.982  0.987  0.901  0.995\n",
       "HT>400              0.948  0.455  0.677  0.399\n",
       "N_fatjet>0          0.997  0.973  1.000  0.989\n",
       "N_htag>0            0.469  0.100  0.143  0.094\n",
       "NN_score>0.4        0.942  0.281  0.715  0.424\n",
       "NN_score>0.5        0.972  0.733  0.956  0.793\n",
       "NN_score>0.6        0.963  0.780  0.986  0.776\n",
       "NN_score>0.7        0.937  0.626  0.986  0.736\n",
       "NN_score>0.8        0.887  0.449  0.885  0.645\n",
       "NN_score>0.9        0.715  0.309  0.007  0.412\n",
       "NN_score>0.91       0.947  0.893  1.000  0.863\n",
       "NN_score>0.92       0.937  0.805  1.000  0.831\n",
       "NN_score>0.93       0.923  0.872  1.000  0.790\n",
       "NN_score>0.94       0.916  0.755  1.000  0.766\n",
       "NN_score>0.95       0.902  0.728  1.000  0.696\n",
       "NN_score>0.96       0.881  0.676  1.000  0.649\n",
       "NN_score>0.97       0.856  0.642  0.000  0.519\n",
       "NN_score>0.98       0.782  0.707  1.000  0.436\n",
       "NN_score>0.99       0.524  0.147  1.000  0.190"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Efficiencies\n",
    "df = getCutFlowTable(output, processes=processes, lines=lines, significantFigures=3, absolute=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram = output['neuralNet_score']\n",
    "ax = hist.plot1d(histogram,overlay=\"dataset\", stack=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's define our processor first. \n",
    "\n",
    "class analysisProcessor(processor.ProcessorABC):\n",
    "    def __init__(self):\n",
    "        \n",
    "        ## load the NN\n",
    "        self.model = load_model('../ML/data/training.h5')\n",
    "        self.stds  = pd.read_json('../ML/data/stds.json').squeeze()\n",
    "        self.means = pd.read_json('../ML/data/means.json').squeeze()\n",
    "        \n",
    "        # we can use a large number of bins and rebin later\n",
    "        dataset_axis        = hist.Cat(\"dataset\",   \"Primary dataset\")\n",
    "        pt_axis             = hist.Bin(\"pt\",        r\"$p_{T}$ (GeV)\", 1000, 0, 1000)\n",
    "        p_axis              = hist.Bin(\"p\",         r\"$p$ (GeV)\", 1000, 0, 2500)\n",
    "        ht_axis             = hist.Bin(\"ht\",        r\"$H_{T}$ (GeV)\", 500, 0, 5000)\n",
    "        mass_axis           = hist.Bin(\"mass\",      r\"M (GeV)\", 1000, 0, 2000)\n",
    "        eta_axis            = hist.Bin(\"eta\",       r\"$\\eta$\", 60, -5.5, 5.5)\n",
    "        delta_axis          = hist.Bin(\"delta\",     r\"$\\delta$\", 100,0,10 )\n",
    "        multiplicity_axis   = hist.Bin(\"multiplicity\",         r\"N\", 20, -0.5, 19.5)\n",
    "        norm_axis           = hist.Bin(\"norm\",         r\"N\", 25, 0, 1)\n",
    "\n",
    "        self._accumulator = processor.dict_accumulator({\n",
    "            \"MET_pt_baseline\" :          hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "            \"HT_baseline\" :              hist.Hist(\"Counts\", dataset_axis, ht_axis),\n",
    "            \"mtb_min_baseline\" :         hist.Hist(\"Counts\", dataset_axis, mass_axis),\n",
    "            \"MET_pt\" :          hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "            \"HT\" :              hist.Hist(\"Counts\", dataset_axis, ht_axis),\n",
    "            \"mtb_min\" :         hist.Hist(\"Counts\", dataset_axis, mass_axis),\n",
    "            \"MET_pt_SR\" :       hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "            \"HT_SR\" :           hist.Hist(\"Counts\", dataset_axis, ht_axis),\n",
    "            \"mtb_min_SR\" :      hist.Hist(\"Counts\", dataset_axis, mass_axis),\n",
    "            \"lead_AK8_pt\" :     hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "            \"W_pt\" :            hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "            \"H_pt\" :            hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "            \"W_eta\" :           hist.Hist(\"Counts\", dataset_axis, eta_axis),\n",
    "            \"H_eta\" :           hist.Hist(\"Counts\", dataset_axis, eta_axis),\n",
    "            \n",
    "            \"N_b\" :             hist.Hist(\"Counts\", dataset_axis, multiplicity_axis),\n",
    "            \"N_AK4\" :           hist.Hist(\"Counts\", dataset_axis, multiplicity_axis),\n",
    "            \"N_AK8\" :           hist.Hist(\"Counts\", dataset_axis, multiplicity_axis),\n",
    "            \"N_H\" :             hist.Hist(\"Counts\", dataset_axis, multiplicity_axis),\n",
    "            \"N_W\" :             hist.Hist(\"Counts\", dataset_axis, multiplicity_axis),\n",
    "            \n",
    "            \"WH_deltaPhi\":      hist.Hist(\"Counts\", dataset_axis, delta_axis),\n",
    "            \"WH_deltaR\":        hist.Hist(\"Counts\", dataset_axis, delta_axis),\n",
    "            \"bb_deltaPhi\":      hist.Hist(\"Counts\", dataset_axis, delta_axis),\n",
    "            \"bb_deltaR\":        hist.Hist(\"Counts\", dataset_axis, delta_axis),\n",
    "            \"min_dphiJetMet4\":  hist.Hist(\"Counts\", dataset_axis, delta_axis),\n",
    "            \"dphiDiJet\":        hist.Hist(\"Counts\", dataset_axis, delta_axis),\n",
    "            \"dphiDiFatJet\":     hist.Hist(\"Counts\", dataset_axis, delta_axis),\n",
    "            \n",
    "            \"neuralNet_score\":  hist.Hist(\"Counts\", dataset_axis, norm_axis),\n",
    "            \n",
    "            'mC750_l1':         processor.defaultdict_accumulator(int),\n",
    "            'WJets':            processor.defaultdict_accumulator(int),\n",
    "            'QCD':              processor.defaultdict_accumulator(int),\n",
    "            'TTJets':           processor.defaultdict_accumulator(int),\n",
    "            'ZNuNu':            processor.defaultdict_accumulator(int),\n",
    "            'ST':               processor.defaultdict_accumulator(int),\n",
    "            'ttW/ttZ':          processor.defaultdict_accumulator(int),\n",
    "            'WW/WZ/ZZ':         processor.defaultdict_accumulator(int),\n",
    "            'LL':               processor.defaultdict_accumulator(int),\n",
    "            'totalEvents':      processor.defaultdict_accumulator(int),\n",
    "            'test1':            processor.defaultdict_accumulator(float),\n",
    "        })\n",
    "    \n",
    "    @property\n",
    "    \n",
    "    #First is this guy. He does important things so always include him. \n",
    "    def accumulator(self):\n",
    "        return self._accumulator\n",
    "\n",
    "    #Now comes the fun part. Here's where we tell our processor exactly what to do with the data.\n",
    "    def process(self, df):\n",
    "     \n",
    "        #Make sure to declare your output, which stores everything you put into the histograms.\n",
    "        output = self.accumulator.identity()\n",
    "        \n",
    "        #Load your data for the dataset axis.\n",
    "        dataset = df['dataset']\n",
    "\n",
    "        #Let's define some variables from our dataset, starting with MET.\n",
    "        metphi = df[\"MET_phi\"]\n",
    "        metpt = df[\"MET_pt\"]\n",
    "        #Here, I'm simply calling those nanoaod branches from the samples\n",
    "        #and storing them under easy to access variable names. \n",
    "        \n",
    "      \n",
    "        \n",
    "        #Let's define some 4 vector objects. For these I can call the branches whatever \n",
    "        #I want. Just make sure to include the .content at the end. Also, by making these\n",
    "        #objects, we can call the branches in a pretty easy way. Shown below.\n",
    "        \n",
    "        #Leptons\n",
    "        electrons = JaggedCandidateArray.candidatesfromcounts(\n",
    "            df['nElectron'],\n",
    "            pt=df['Electron_pt'].content, \n",
    "            eta=df['Electron_eta'].content, \n",
    "            phi=df['Electron_phi'].content,\n",
    "            mass=df['Electron_mass'].content,\n",
    "            pdgid=df['Electron_pdgId'].content,\n",
    "            mini_iso=df['Electron_miniPFRelIso_all'].content\n",
    "            #cutBased=df['Electron_cutBased'].content\n",
    "        )\n",
    "        electrons = electrons[(electrons.pt>10) & (abs(electrons.eta) < 2.4) & (electrons.mini_iso < 0.1)]# &  (electrons.cutBased >= 1)]\n",
    "\n",
    "        muons = JaggedCandidateArray.candidatesfromcounts(\n",
    "            df['nMuon'],\n",
    "            pt=df['Muon_pt'].content, \n",
    "            eta=df['Muon_eta'].content, \n",
    "            phi=df['Muon_phi'].content,\n",
    "            mass=df['Muon_mass'].content,\n",
    "            pdgid=df['Muon_pdgId'].content,\n",
    "            mini_iso=df['Muon_miniPFRelIso_all'].content, \n",
    "            looseid =df['Muon_looseId'].content\n",
    "        )\n",
    "        muons = muons[(muons.pt > 10) & (abs(muons.eta) < 2.4) & (muons.looseid) & (muons.mini_iso < 0.2)]\n",
    "\n",
    "        taus = JaggedCandidateArray.candidatesfromcounts(\n",
    "            df['nTau'],\n",
    "            pt=df['Tau_pt'].content, \n",
    "            eta=df['Tau_eta'].content, \n",
    "            phi=df['Tau_phi'].content,\n",
    "            mass=df['Tau_mass'].content,\n",
    "            decaymode=df['Tau_idDecayMode'].content,\n",
    "            newid=df['Tau_idMVAnewDM2017v2'].content,\n",
    "        )\n",
    "        \n",
    "        #Here, since I don't have enough information to form a 4 vector with isotracks,\n",
    "        #I just use the JaggedArray format. I call branches in the same way as the\n",
    "        #JaggedCandidateArray, but I can't use some of the manipulations that come with the\n",
    "        #JCA format. :(\n",
    "        isotracks = awkward.JaggedArray.zip(\n",
    "            pt=df['IsoTrack_pt'], \n",
    "            eta=df['IsoTrack_eta'], \n",
    "            phi=df['IsoTrack_phi'], \n",
    "            rel_iso=df['IsoTrack_pfRelIso03_all'], \n",
    "        )\n",
    "        \n",
    "        #Jets\n",
    "        jets = JaggedCandidateArray.candidatesfromcounts(\n",
    "            df['nJet'],\n",
    "            pt=df['Jet_pt'].content, \n",
    "            eta=df['Jet_eta'].content, \n",
    "            phi=df['Jet_phi'].content,\n",
    "            btag=df['Jet_btagDeepB'].content, \n",
    "            jetid=df['Jet_jetId'].content, \n",
    "            mass=df['Jet_mass'].content,\n",
    "        )\n",
    "        fatjets = JaggedCandidateArray.candidatesfromcounts(\n",
    "            df['nFatJet'],\n",
    "            pt=df['FatJet_pt'].content, \n",
    "            eta=df['FatJet_eta'].content, \n",
    "            phi=df['FatJet_phi'].content, \n",
    "            mass=df['FatJet_mass'].content, \n",
    "            softdrop=df[\"FatJet_msoftdrop\"].content,  \n",
    "            fromH = df['FatJet_deepTagMD_HbbvsQCD'].content, \n",
    "            fromW_MD = df['FatJet_deepTagMD_WvsQCD'].content, \n",
    "            fromW_MC = df['FatJet_deepTag_WvsQCD'].content\n",
    "        )\n",
    "  \n",
    "        \n",
    "        #Now let's deal with some good ol' ak4's baby. Let's define a \"good jet\".\n",
    "        #First, let's define what a good jet should be. Notice how I'm calling the branches\n",
    "        #of the jets. Super easy, right?\n",
    "        goodjcut = ((jets.pt>30) & (abs(jets.eta)<2.4) & (jets.jetid>0))\n",
    "        #Perfect, now let's apply this selection to the ak4's and create a new object.\n",
    "        goodjets = jets[goodjcut]\n",
    "        #LIT. Okay, now I want the number of good jets. \n",
    "        njets = goodjets.counts\n",
    "        #Bro, you are on fire. Good job. I'm proud of you and really appreciate you.\n",
    "\n",
    "        jetpt_sorted = goodjets.pt.argsort(ascending=False)\n",
    "        leadjet = goodjets[jetpt_sorted==0]\n",
    "        subleadjet = goodjets[jetpt_sorted==1]\n",
    "        leadjet_subleadjet = leadjet.cross(subleadjet)\n",
    "        \n",
    "        lead_jet_pt = leadjet.pt\n",
    "        sublead_jet_pt = subleadjet.pt\n",
    "        #leadjets = goodjets[jetpt_sorted <= 1]\n",
    "        #leadjets3 = goodjets[jetpt_sorted <= 2]\n",
    "        #leadjets4 = goodjets[jetpt_sorted <= 4]\n",
    "      \n",
    "        #ak8's\n",
    "        goodfjcut = ((fatjets.pt > 200))\n",
    "        goodfatjets = fatjets[goodfjcut]\n",
    "        nfatjets = goodfatjets.counts\n",
    "        \n",
    "        htagcut = ((fatjets.pt > 200) & (fatjets.fromH > 0.8365))\n",
    "        htagged = fatjets[htagcut]\n",
    "        \n",
    "        htag_hard = fatjets[((fatjets.pt > 300) & (fatjets.fromH > 0.8365))]\n",
    "        lead_htag = htagged[htagged.pt.argmax()]\n",
    "        \n",
    "        wtagcut_mc = ((fatjets.pt > 200) & (fatjets.fromW_MC > 0.918) & (fatjets.fromH < 0.8365))\n",
    "        wtagcut_md = ((fatjets.pt > 200) & (fatjets.fromW_MD > 0.704) & (fatjets.fromH < 0.8365))\n",
    "        wtagged_mc = fatjets[wtagcut_mc]\n",
    "        wtagged_md = fatjets[wtagcut_md]\n",
    "\n",
    "        wtag_hard = fatjets[((fatjets.pt > 300) & (fatjets.fromH < 0.8365) & (fatjets.fromW_MC > 0.918))]\n",
    "        lead_wtag = wtagged_mc[wtagged_mc.pt.argmax()]\n",
    "        \n",
    "        wh = lead_htag.cross(lead_wtag)\n",
    "        wh_deltaPhi = np.arccos(wh.i0.phi - wh.i1.phi)\n",
    "        wh_deltaR = wh.i0.p4.delta_r(wh.i1.p4)\n",
    "        \n",
    "        fatjet_sorted = goodfatjets.pt.argsort(ascending=False)\n",
    "        leadFatJet    = goodfatjets[fatjet_sorted==0]\n",
    "        subleadFatJet = goodfatjets[fatjet_sorted==1]\n",
    "        lead_sublead_FatJets = leadFatJet.cross(subleadFatJet)\n",
    "        \n",
    "        m_lead_FatJet_softdrop = goodfatjets[goodfatjets.pt.argmax()]\n",
    "    \n",
    "        #Let's make some b-jets and find the number of b-jets.\n",
    "        bjcut = ((jets.pt>30) & (abs(jets.eta)<2.4) & (jets.jetid>0) & (jets.btag>0.4184))\n",
    "        bjets = jets[bjcut]\n",
    "        nbjets = bjets.counts\n",
    "        bjetpt = bjets.pt\n",
    "        bjetpt_sorted = bjetpt.argsort(ascending=False)\n",
    "        leadbjets = bjets[bjetpt_sorted <= 1]\n",
    "\n",
    "        high_score_btag = jets[jets.btag.argsort(ascending=False)][:,:2]\n",
    "                \n",
    "        bb = high_score_btag.choose(2)\n",
    "        bb_deltaPhi = np.arccos(np.cos(bb.i0.phi-bb.i1.phi))\n",
    "        bb_deltaR = bb.i0.p4.delta_r(bb.i1.p4)\n",
    "        \n",
    "        #Let's go for HT now. \n",
    "        ht = goodjets.pt.sum()\n",
    "        met_sig = metpt/np.sqrt(ht)\n",
    "        #Remember to put that () after the sum!\n",
    "        \n",
    "        #MT      \n",
    "        dphi_leadbs_met = abs((leadbjets.phi - metphi + np.pi) % (2 * np.pi) - np.pi)\n",
    "        mt_b_met = np.sqrt(2*leadbjets.pt*metpt*(1-np.cos(dphi_leadbs_met)))\n",
    "\n",
    "        sorted_min_mt_b_met = mt_b_met.argsort(ascending=True)\n",
    "        sorted_max_mt_b_met = mt_b_met.argsort(ascending=False)\n",
    "        min_mt_b_met = mt_b_met[sorted_min_mt_b_met == 0]\n",
    "        max_mt_b_met = mt_b_met[sorted_max_mt_b_met == 0]\n",
    "          \n",
    "        #dphi_met_leadjs3 = abs((leadjets3.phi - metphi + np.pi) % (2 * np.pi) - np.pi)\n",
    "        #sorted_dphi_met_leadjs3 = dphi_met_leadjs3.argsort(ascending=True)\n",
    "        #min_dphi_met_leadjs3 = dphi_met_leadjs3[sorted_dphi_met_leadjs3==0]\n",
    "        #abs_min_dphi_met_leadjs3 = abs(min_dphi_met_leadjs3)\n",
    "       \n",
    "        abs_min_dphi_met_leadjs1 = abs(np.arccos(np.cos(goodjets[:,:1].phi-metphi)).min())\n",
    "        abs_min_dphi_met_leadjs2 = abs(np.arccos(np.cos(goodjets[:,:2].phi-metphi)).min())\n",
    "        abs_min_dphi_met_leadjs3 = abs(np.arccos(np.cos(goodjets[:,:3].phi-metphi)).min())\n",
    "        abs_min_dphi_met_leadjs4 = abs(np.arccos(np.cos(goodjets[:,:4].phi-metphi)).min())\n",
    "\n",
    "        abs_dphi_j1_j2           = abs(leadjet_subleadjet.i0.p4.delta_phi(leadjet_subleadjet.i1.p4))\n",
    "        abs_dphi_fj1_fj2         = abs(lead_sublead_FatJets.i0.p4.delta_phi(lead_sublead_FatJets.i1.p4))\n",
    "\n",
    "        dR_fj1_fj2               = lead_sublead_FatJets.i0.p4.delta_r(lead_sublead_FatJets.i1.p4)\n",
    "\n",
    "        ## evaluate NN\n",
    "        # first, prepare the inputs.\n",
    "        # A .max() can ensure that the flattened array has the full length, but we rather use our pad_and_flatten function        \n",
    "        # sorting in training: ['mll', 'njet', 'nbtag', 'st', 'ht', 'met', 'mjj_max', 'mlb_min', 'mlb_max', 'l0_pt', 'l1_pt', 'deltaR_lj_min', 'j0_pt']\n",
    "        \n",
    "        NN_inputs = np.stack([\n",
    "            # normalize\n",
    "            pad_and_flatten( (metpt - self.means['met'])/self.stds['met'] ),\n",
    "            pad_and_flatten( (ht - self.means['ht'])/self.stds['ht'] ),\n",
    "            pad_and_flatten( (lead_jet_pt - self.means['lead_jet_pt'])/self.stds['lead_jet_pt'] ),\n",
    "            pad_and_flatten( (sublead_jet_pt - self.means['sublead_jet_pt'])/self.stds['sublead_jet_pt'] ),\n",
    "            pad_and_flatten( (njets - self.means['njets'])/self.stds['njets'] ),\n",
    "            pad_and_flatten( (nbjets - self.means['bjets'])/self.stds['bjets'] ),\n",
    "            pad_and_flatten( (wtagged_mc.counts - self.means['nWs'])/self.stds['nWs'] ),\n",
    "            pad_and_flatten( (htagged.counts - self.means['nHs'])/self.stds['nHs'] ),\n",
    "            pad_and_flatten( (nfatjets - self.means['nFatJets'])/self.stds['nFatJets'] ),\n",
    "            pad_and_flatten( (met_sig - self.means['met_significance'])/self.stds['met_significance'] ),\n",
    "            pad_and_flatten( (abs_min_dphi_met_leadjs4 - self.means['min_dphi_met_j4'])/self.stds['min_dphi_met_j4'] ),\n",
    "        ])\n",
    "        \n",
    "        NN_inputs = np.moveaxis(NN_inputs, 0, 1)\n",
    "        NN_score = self.model.predict(NN_inputs)\n",
    "        \n",
    "        ## define selections (maybe move to a different file at some point)\n",
    "        \n",
    "        output['totalEvents']['all'] += len(df['weight'])\n",
    "        \n",
    "        # Cutflow\n",
    "        #processes = ['mC750_l1', 'WJets', 'QCD', 'TTJets', 'ZNuNu', 'ST', 'ttW/ttZ', 'WW/WZ/ZZ']\n",
    "        processes = ['mC750_l1', 'LL', 'QCD', 'ZNuNu']\n",
    "        cutflow = Cutflow(output, df, cfg, processes)\n",
    "        \n",
    "        cutflow.addRow( 'electron veto',   (electrons.counts==0) )\n",
    "        cutflow.addRow( 'muon veto',   (muons.counts==0) )\n",
    "        cutflow.addRow( 'MET>250',     (metpt>250) )\n",
    "        cutflow.addRow( 'njet2',       (goodjets.counts>=2) )\n",
    "        cutflow.addRow( 'jetveto',       (goodjets.counts<=5) )\n",
    "        cutflow.addRow( 'nbtag',       (nbjets>=1) )\n",
    "        \n",
    "        baseline = copy.deepcopy(cutflow.selection)\n",
    "        \n",
    "        cutflow.addRow( 'min_dphiJetMet4', (abs_min_dphi_met_leadjs4>0.5))\n",
    "        cutflow.addRow( 'dphiDiJet', (abs_dphi_j1_j2.min()<2.5) ) # the min doesn't do anything here\n",
    "        cutflow.addRow( 'dphiDiFatJet', (abs_dphi_fj1_fj2<2.5).all() ) # by using .all() I do not implicitely cut on the number of fat jets\n",
    "        \n",
    "        vetoQCD = copy.deepcopy(cutflow.selection)\n",
    "        \n",
    "        cutflow.addRow( 'HT>400',      (ht>400) )\n",
    "        cutflow.addRow( 'N_fatjet>0',      (nfatjets>0) )\n",
    "        cutflow.addRow( 'N_htag>0',     (htagged.counts>0))\n",
    "        cutflow.addRow( 'NN_score>0.4',     (NN_score.flatten()>0.4))\n",
    "        cutflow.addRow( 'NN_score>0.5',     (NN_score.flatten()>0.5))\n",
    "        cutflow.addRow( 'NN_score>0.6',     (NN_score.flatten()>0.6))\n",
    "        cutflow.addRow( 'NN_score>0.7',     (NN_score.flatten()>0.7))\n",
    "        cutflow.addRow( 'NN_score>0.8',     (NN_score.flatten()>0.8))\n",
    "        cutflow.addRow( 'NN_score>0.9',     (NN_score.flatten()>0.9))\n",
    "        cutflow.addRow( 'NN_score>0.91',     (NN_score.flatten()>0.91))\n",
    "        cutflow.addRow( 'NN_score>0.92',     (NN_score.flatten()>0.92))\n",
    "        cutflow.addRow( 'NN_score>0.93',     (NN_score.flatten()>0.93))\n",
    "        cutflow.addRow( 'NN_score>0.94',     (NN_score.flatten()>0.94))\n",
    "        cutflow.addRow( 'NN_score>0.95',     (NN_score.flatten()>0.95))\n",
    "        cutflow.addRow( 'NN_score>0.96',     (NN_score.flatten()>0.96))\n",
    "        cutflow.addRow( 'NN_score>0.97',     (NN_score.flatten()>0.97))\n",
    "        cutflow.addRow( 'NN_score>0.98',     (NN_score.flatten()>0.98))\n",
    "        cutflow.addRow( 'NN_score>0.99',     (NN_score.flatten()>0.99))\n",
    "        #cutflow.addRow( 'N_fatjet>1',      (fatjet.counts>1) )\n",
    "        #cutflow.addRow( 'N_wtag>0',     (wtag.counts>0))\n",
    "        \n",
    "        event_selection = copy.deepcopy(cutflow.selection)\n",
    "        \n",
    "        cutflow.addRow( 'N_htag>0 hard',     (htag_hard.counts>0))\n",
    "        cutflow.addRow( 'MET>400',     (metpt>400) )\n",
    "\n",
    "        # signal enriched selection of events\n",
    "        signal_selection = cutflow.selection\n",
    "        \n",
    "        ### And fill the histograms\n",
    "        output['MET_pt_baseline'].fill(dataset=dataset, pt=metpt[baseline].flatten(), weight=df['weight'][baseline]*cfg['lumi'])\n",
    "        output['HT_baseline'].fill(dataset=dataset, ht=ht[baseline].flatten(), weight=df['weight'][baseline]*cfg['lumi'])\n",
    "        output['mtb_min_baseline'].fill(dataset=dataset, mass=mt_b_met[baseline].min().flatten(), weight=df['weight'][baseline]*cfg['lumi'])\n",
    "\n",
    "        output['MET_pt'].fill(dataset=dataset, pt=metpt[vetoQCD].flatten(), weight=df['weight'][vetoQCD]*cfg['lumi'])\n",
    "        output['HT'].fill(dataset=dataset, ht=ht[vetoQCD].flatten(), weight=df['weight'][vetoQCD]*cfg['lumi'])\n",
    "        output['mtb_min'].fill(dataset=dataset, mass=mt_b_met[vetoQCD].min().flatten(), weight=df['weight'][vetoQCD]*cfg['lumi'])\n",
    "        \n",
    "        ## N jet and N b without selections on those\n",
    "        output['N_AK4'].fill(dataset=dataset, multiplicity=goodjets[baseline].counts, weight=df['weight'][baseline]*cfg['lumi'])\n",
    "        output['N_b'].fill(dataset=dataset, multiplicity=bjets[baseline].counts, weight=df['weight'][baseline]*cfg['lumi'])       \n",
    "        output['N_W'].fill(dataset=dataset, multiplicity=htagged[baseline].counts, weight=df['weight'][baseline]*cfg['lumi'])       \n",
    "        output['N_H'].fill(dataset=dataset, multiplicity=wtagged_mc[baseline].counts, weight=df['weight'][baseline]*cfg['lumi'])       \n",
    "        output['N_AK8'].fill(dataset=dataset, multiplicity=fatjets[baseline].counts, weight=df['weight'][baseline]*cfg['lumi'])       \n",
    "\n",
    "        output['bb_deltaPhi'].fill(dataset=dataset, delta=bb_deltaPhi[baseline].flatten(), weight=df['weight'][baseline]*cfg['lumi'])\n",
    "        output['bb_deltaR'].fill(dataset=dataset, delta=bb_deltaR[baseline].flatten(), weight=df['weight'][baseline]*cfg['lumi'])\n",
    "\n",
    "        output['min_dphiJetMet4'].fill(dataset=dataset, delta=abs_min_dphi_met_leadjs4[baseline].flatten(), weight=df['weight'][baseline]*cfg['lumi'])\n",
    "        output['dphiDiJet'].fill(dataset=dataset, delta=abs_dphi_j1_j2[baseline].min().flatten(), weight=df['weight'][baseline]*cfg['lumi'])\n",
    "\n",
    "        output['neuralNet_score'].fill(dataset=dataset, norm=NN_score[baseline].flatten(), weight=df['weight'][baseline]*cfg['lumi'])\n",
    "\n",
    "        ## Higgs and W pt\n",
    "        output['lead_AK8_pt'].fill(dataset=dataset, pt=fatjets[(baseline & (fatjets.counts>0))].pt.max().flatten(), weight=df['weight'][(baseline & (fatjets.counts>0))]*cfg['lumi'])\n",
    "        output['dphiDiFatJet'].fill(dataset=dataset, delta=abs_dphi_fj1_fj2[(baseline & (fatjets.counts>1))].min().flatten(), weight=df['weight'][(baseline & (fatjets.counts>1))]*cfg['lumi'])\n",
    "\n",
    "        output['H_pt'].fill(dataset=dataset, pt=lead_htag[event_selection].pt.flatten(), weight=df['weight'][event_selection]*cfg['lumi'])\n",
    "        output['H_eta'].fill(dataset=dataset, eta=lead_htag[event_selection].eta.flatten(), weight=df['weight'][event_selection]*cfg['lumi'])\n",
    "\n",
    "        #output['W_pt'].fill(dataset=dataset, pt=lead_wtag[event_selection].pt.flatten(), weight=df['weight'][event_selection]*cfg['lumi'])\n",
    "        #output['W_eta'].fill(dataset=dataset, eta=lead_wtag[event_selection].eta.flatten(), weight=df['weight'][event_selection]*cfg['lumi'])\n",
    "\n",
    "        #output['WH_deltaPhi'].fill(dataset=dataset, delta=wh_deltaPhi[event_selection].flatten(), weight=df['weight'][event_selection]*cfg['lumi'])\n",
    "        #output['WH_deltaR'].fill(dataset=dataset, delta=wh_deltaR[event_selection].flatten(), weight=df['weight'][event_selection]*cfg['lumi'])\n",
    "\n",
    "        output['MET_pt_SR'].fill(dataset=dataset, pt=metpt[event_selection].flatten(), weight=df['weight'][event_selection]*cfg['lumi'])\n",
    "        output['HT_SR'].fill(dataset=dataset, ht=ht[event_selection].flatten(), weight=df['weight'][event_selection]*cfg['lumi'])\n",
    "        output['mtb_min_SR'].fill(dataset=dataset, mass=mt_b_met[event_selection].min().flatten(), weight=df['weight'][event_selection]*cfg['lumi'])\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def postprocess(self, accumulator):\n",
    "        return accumulator"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coffeaEnv",
   "language": "python",
   "name": "coffeaenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

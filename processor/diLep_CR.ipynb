{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "from klepto.archives import dir_archive\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import coffea.processor as processor\n",
    "from coffea.processor.accumulator import AccumulatorABC\n",
    "from coffea.analysis_objects import JaggedCandidateArray\n",
    "from coffea.btag_tools import BTagScaleFactor\n",
    "from coffea import hist\n",
    "import pandas as pd\n",
    "import uproot_methods\n",
    "import uproot\n",
    "import awkward\n",
    "import copy\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "from Tools.config_helpers import *\n",
    "from Tools.helpers import mergeArray, mt, get_scheduler_address\n",
    "\n",
    "from Tools.objects import Collections\n",
    "from Tools.cutflow import Cutflow\n",
    "\n",
    "# This just tells matplotlib not to open any\n",
    "# interactive windows.\n",
    "matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_and_flatten(val): \n",
    "    try:\n",
    "        return val.pad(1, clip=True).fillna(0.).flatten()#.reshape(-1, 1)\n",
    "    except AttributeError:\n",
    "        return val.flatten()\n",
    "\n",
    "#os.environ['KERAS_BACKEND'] = 'theano'\n",
    "#from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.setrecursionlimit(10000)\n",
    "print(sys.getrecursionlimit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Tools.WH_objects import *\n",
    "from Tools.WH_scalefactors import LeptonSF\n",
    "from Tools.WH_deepAK8 import getWTagSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global variables... to avoid making bugs!!!\n",
    "processesList = ['DYJets', 'TTJets', 'ttW', 'ttZ', 'Data']\n",
    "linesList= ['triggers', 'filters',  'dimuon = 1', '70 < dimuon mass < 110']\n",
    "\n",
    "plotDir = '/home/users/mbryson/public_html/dump/WH/dilep2016/'\n",
    "year = 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class analysisProcessor(processor.ProcessorABC):\n",
    "    \"\"\"Processor used for running the analysis\"\"\"\n",
    "    def __init__(self):\n",
    "        \n",
    "        ## load b-tag SFs\n",
    "        #self.btag_sf = BTagScaleFactor(os.path.expandvars(\"$TWHOME/data/DeepCSV_102XSF_V1.btag.csv.gz\", \"reshape\")\n",
    "\n",
    "        ## load the NN\n",
    "        #self.model = load_model('../ML/data/training.h5')\n",
    "        #self.stds  = pd.read_json('../ML/data/stds.json').squeeze()\n",
    "        #self.means = pd.read_json('../ML/data/means.json').squeeze()\n",
    "        \n",
    "        # we can use a large number of bins and rebin later\n",
    "        dataset_axis        = hist.Cat(\"dataset\",   \"Primary dataset\")\n",
    "        pt_axis             = hist.Bin(\"pt\",        r\"$p_{T}$ (GeV)\", 1000, 0, 1000)\n",
    "        p_axis              = hist.Bin(\"p\",         r\"$p$ (GeV)\", 1000, 0, 2500)\n",
    "        ht_axis             = hist.Bin(\"ht\",        r\"$H_{T}$ (GeV)\", 500, 0, 5000)\n",
    "        mass_axis           = hist.Bin(\"mass\",      r\"Mass (GeV)\", 1000, 0, 2000)\n",
    "        eta_axis            = hist.Bin(\"eta\",       r\"$\\eta$\", 60, -5.5, 5.5)\n",
    "        phi_axis            = hist.Bin(\"phi\",       r\"$\\phi$\", 40, -4, 4)\n",
    "        delta_axis          = hist.Bin(\"delta\",     r\"$\\delta$\", 100,0,10 )\n",
    "        multiplicity_axis   = hist.Bin(\"multiplicity\",         r\"N\", 20, -0.5, 19.5)\n",
    "        norm_axis           = hist.Bin(\"norm\",         r\"N\", 25, 0, 1)\n",
    "\n",
    "        self._accumulator = processor.dict_accumulator({\n",
    "            \"met\":                     hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "            \"leadmu_pt\":               hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "            \"leadmu_eta\":              hist.Hist(\"Counts\", dataset_axis, eta_axis),\n",
    "            \"leadmu_phi\":              hist.Hist(\"Counts\", dataset_axis, phi_axis),\n",
    "            \"subleadmu_pt\":            hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "            \"subleadmu_eta\":           hist.Hist(\"Counts\", dataset_axis, eta_axis),\n",
    "            \"subleadmu_phi\":           hist.Hist(\"Counts\", dataset_axis, phi_axis),\n",
    "            \"mm_deltaPhi\":             hist.Hist(\"Counts\", dataset_axis, delta_axis),\n",
    "            \"mm_deltaR\":               hist.Hist(\"Counts\", dataset_axis, delta_axis),\n",
    "            \"mm_mass\":                 hist.Hist(\"Counts\", dataset_axis, mass_axis),\n",
    "            \"mm_pt\":                   hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "            \"mm_eta\":                  hist.Hist(\"Counts\", dataset_axis, eta_axis),\n",
    "            \"mm_phi\":                  hist.Hist(\"Counts\", dataset_axis, phi_axis),\n",
    "            \"N_AK4\" :                  hist.Hist(\"Counts\", dataset_axis, multiplicity_axis),\n",
    "            \"N_AK8\" :                  hist.Hist(\"Counts\", dataset_axis, multiplicity_axis),\n",
    "            \"leadAK4_pt\" :             hist.Hist(\"Counts\", dataset_axis, pt_axis),            \n",
    "            \"leadAK4_eta\" :            hist.Hist(\"Counts\", dataset_axis, eta_axis),\n",
    "            \"leadAK4_phi\" :            hist.Hist(\"Counts\", dataset_axis, phi_axis),\n",
    "            \"subleadAK4_pt\" :          hist.Hist(\"Counts\", dataset_axis, pt_axis),            \n",
    "            \"subleadAK4_eta\" :         hist.Hist(\"Counts\", dataset_axis, eta_axis),\n",
    "            \"subleadAK4_phi\" :         hist.Hist(\"Counts\", dataset_axis, phi_axis),\n",
    "            \"leadAK8_pt\" :             hist.Hist(\"Counts\", dataset_axis, pt_axis),            \n",
    "            \"leadAK8_eta\" :            hist.Hist(\"Counts\", dataset_axis, eta_axis),            \n",
    "            \"leadAK8_phi\" :            hist.Hist(\"Counts\", dataset_axis, phi_axis), \n",
    "            \"subleadAK8_pt\" :          hist.Hist(\"Counts\", dataset_axis, pt_axis),            \n",
    "            \"subleadAK8_eta\" :         hist.Hist(\"Counts\", dataset_axis, eta_axis),            \n",
    "            \"subleadAK8_phi\" :         hist.Hist(\"Counts\", dataset_axis, phi_axis),\n",
    "            #\"MET_pt_baseline\" :          hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "            #\"HT_baseline\" :              hist.Hist(\"Counts\", dataset_axis, ht_axis),\n",
    "            #\"mtb_min_baseline\" :         hist.Hist(\"Counts\", dataset_axis, mass_axis),\n",
    "            #\"MET_pt\" :          hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "            #\"HT\" :              hist.Hist(\"Counts\", dataset_axis, ht_axis),\n",
    "            #\"mtb_min\" :         hist.Hist(\"Counts\", dataset_axis, mass_axis),\n",
    "            #\"MET_pt_CR\" :       hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "            #\"HT_CR\" :           hist.Hist(\"Counts\", dataset_axis, ht_axis),\n",
    "            #\"mtb_min_CR\" :      hist.Hist(\"Counts\", dataset_axis, mass_axis),\n",
    "            #\"lead_AK8_pt\" :     hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "            #\"W_pt\" :            hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "            #\"H_pt\" :            hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "            #\"W_eta\" :           hist.Hist(\"Counts\", dataset_axis, eta_axis),\n",
    "            #\"H_eta\" :           hist.Hist(\"Counts\", dataset_axis, eta_axis),\n",
    "            \n",
    "#             \"met_CR\":           hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "#             \"met_Higgs_CR\":     hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "#             \"met_W_CR\":         hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "#             \"met_Higgs_W_CR\":   hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "            \n",
    "#             \"ht_CR\":            hist.Hist(\"Counts\", dataset_axis, ht_axis),\n",
    "#             \"ht_Higgs_CR\":      hist.Hist(\"Counts\", dataset_axis, ht_axis),\n",
    "#             \"ht_W_CR\":          hist.Hist(\"Counts\", dataset_axis, ht_axis),\n",
    "#             \"ht_Higgs_W_CR\":    hist.Hist(\"Counts\", dataset_axis, ht_axis),\n",
    "            \n",
    "#             \"N_AK8_CR\" :        hist.Hist(\"Counts\", dataset_axis, multiplicity_axis),\n",
    "#             \"W_pt_CR\" :         hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "#             \"H_pt_CR\" :         hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "#             \"W_eta_CR\" :        hist.Hist(\"Counts\", dataset_axis, eta_axis),\n",
    "#             \"H_eta_CR\" :        hist.Hist(\"Counts\", dataset_axis, eta_axis),\n",
    "            \n",
    "#             \"N_AK8_Higgs_CR\" :  hist.Hist(\"Counts\", dataset_axis, multiplicity_axis),\n",
    "#             \"W_pt_Higgs_CR\" :   hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "#             \"H_pt_Higgs_CR\" :   hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "#             \"W_eta_Higgs_CR\" :  hist.Hist(\"Counts\", dataset_axis, eta_axis),\n",
    "#             \"H_eta_Higgs_CR\" :  hist.Hist(\"Counts\", dataset_axis, eta_axis),\n",
    "            \n",
    "#             \"N_AK8_W_CR\" :      hist.Hist(\"Counts\", dataset_axis, multiplicity_axis),\n",
    "#             \"W_pt_W_CR\" :       hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "#             \"H_pt_W_CR\" :       hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "#             \"W_eta_W_CR\" :      hist.Hist(\"Counts\", dataset_axis, eta_axis),\n",
    "#             \"H_eta_W_CR\" :      hist.Hist(\"Counts\", dataset_axis, eta_axis),\n",
    "            \n",
    "#             \"N_AK8_Higgs_W_CR\" :hist.Hist(\"Counts\", dataset_axis, multiplicity_axis),\n",
    "#             \"W_pt_Higgs_W_CR\" : hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "#             \"H_pt_Higgs_W_CR\" : hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "#             \"W_eta_Higgs_W_CR\" :hist.Hist(\"Counts\", dataset_axis, eta_axis),\n",
    "#             \"H_eta_Higgs_W_CR\" :hist.Hist(\"Counts\", dataset_axis, eta_axis),\n",
    "\n",
    "            #\"N_b\" :             hist.Hist(\"Counts\", dataset_axis, multiplicity_axis),\n",
    "\n",
    "            #\"N_H\" :             hist.Hist(\"Counts\", dataset_axis, multiplicity_axis),\n",
    "            #\"N_W\" :             hist.Hist(\"Counts\", dataset_axis, multiplicity_axis),\n",
    "            \n",
    "            #\"WH_deltaPhi\":      hist.Hist(\"Counts\", dataset_axis, delta_axis),\n",
    "            #\"WH_deltaR\":        hist.Hist(\"Counts\", dataset_axis, delta_axis),\n",
    "\n",
    "            #\"min_dphiJetMet4\":  hist.Hist(\"Counts\", dataset_axis, delta_axis),\n",
    "            #\"dphiDiJet\":        hist.Hist(\"Counts\", dataset_axis, delta_axis),\n",
    "            #\"dphiDiFatJet\":     hist.Hist(\"Counts\", dataset_axis, delta_axis),\n",
    "            \n",
    "#             'mC750_l1':         processor.defaultdict_accumulator(int),\n",
    "#             'WJets':            processor.defaultdict_accumulator(int),\n",
    "#             'QCD':              processor.defaultdict_accumulator(int),\n",
    "            'TTJets':           processor.defaultdict_accumulator(int),\n",
    "            'DYJets':           processor.defaultdict_accumulator(int),\n",
    "#             'ZNuNu':            processor.defaultdict_accumulator(int),\n",
    "#             'ST':               processor.defaultdict_accumulator(int),\n",
    "#             'ST_tW':            processor.defaultdict_accumulator(int),\n",
    "#             'ST_tChannel':      processor.defaultdict_accumulator(int),\n",
    "#             'ST_sChannel':      processor.defaultdict_accumulator(int),\n",
    "            'ttW':              processor.defaultdict_accumulator(int),\n",
    "            'ttZ':              processor.defaultdict_accumulator(int),\n",
    "#             'WW':               processor.defaultdict_accumulator(int),\n",
    "#             'WZ/ZZ':            processor.defaultdict_accumulator(int),\n",
    "#             'LL':               processor.defaultdict_accumulator(int),\n",
    "            'Data':             processor.defaultdict_accumulator(int),\n",
    "            'totalEvents':      processor.defaultdict_accumulator(int),\n",
    "#             'test1':            processor.defaultdict_accumulator(float),\n",
    "        })\n",
    "\n",
    "    @property\n",
    "    def accumulator(self):\n",
    "        return self._accumulator\n",
    "\n",
    "    def process(self, df):\n",
    "        \"\"\"\n",
    "        Processing function. This is where the actual analysis happens.\n",
    "        \"\"\"\n",
    "        output = self.accumulator.identity()\n",
    "        dataset = df[\"dataset\"]\n",
    "        cfg = loadConfig()\n",
    "        \n",
    "        ############## MET ##############\n",
    "        met = JaggedCandidateArray.candidatesfromcounts(\n",
    "            (df['MET_pt']>=0)*1,\n",
    "            pt = df[\"MET_pt\"],\n",
    "            eta = df[\"MET_phi\"]*0,\n",
    "            phi = df[\"MET_phi\"],\n",
    "            mass = df[\"MET_phi\"]*0\n",
    "        )\n",
    "        \n",
    "        \n",
    "        ############## LOAD OBJECTS ############## \n",
    "        \n",
    "        muon     = getMuons(df, WP='veto')\n",
    "        electron = getElectrons(df, WP='veto')\n",
    "        tau      = getTaus(df)\n",
    "        isotrack = getIsoTracks(df)\n",
    "        fatjet   = getFatJets(df)\n",
    "        jet      = getJets(df)\n",
    "        \n",
    "        triggers = getDimuonTriggers(df, year=year, dataset=dataset)\n",
    "        filters  = getFilters(df, year=year, dataset=dataset)\n",
    "        \n",
    "#         sf = LeptonSF(year=year)\n",
    "#         leptonSF = sf.get(electron, muon)\n",
    "\n",
    "        ############## LEPTONS ############## \n",
    "    \n",
    "        high_pt_e = electron[electron.pt.argsort(ascending=False)][:,:2]\n",
    "        ee = high_pt_e.choose(2)\n",
    "        \n",
    "        high_pt_m = muon[muon.pt.argsort(ascending=False)][:,:2]\n",
    "        mm = high_pt_m.choose(2)\n",
    "        newmet = mm.cross(met)\n",
    "\n",
    "        \n",
    "        mm_deltaPhi = np.arccos(np.cos(mm.i0.phi-mm.i1.phi))\n",
    "        mm_deltaR = mm.i0.p4.delta_r(mm.i1.p4)\n",
    "        \n",
    "        leadm = high_pt_m[high_pt_m.pt.argmax()]\n",
    "        subleadm = high_pt_m[high_pt_m.pt.argmin()]\n",
    "        \n",
    "        #selection for two muons\n",
    "        dimuonsel = (muon.counts == 2)\n",
    "        \n",
    "        ############## FATJETS ##############\n",
    "\n",
    "        \n",
    "        high_pt_fatjet = fatjet[fatjet.pt.argsort(ascending=False)][:,:2]\n",
    "        leadfatjet = high_pt_fatjet[high_pt_fatjet.pt.argmax()]\n",
    "        subleadfatjet = high_pt_fatjet[high_pt_fatjet.pt.argmin()]\n",
    "        \n",
    "        leadingFatJets = fatjet[:,:2]\n",
    "        difatjet = leadingFatJets.choose(2)\n",
    "        dphiDiFatJet = np.arccos(np.cos(difatjet.i0.phi-difatjet.i1.phi))\n",
    "        \n",
    "        htag = fatjet[((fatjet.pt > 200) & (fatjet.deepTagMD_HbbvsQCD > 0.8365))]\n",
    "        htag_hard = fatjet[((fatjet.pt > 300) & (fatjet.deepTagMD_HbbvsQCD > 0.8365))]\n",
    "        \n",
    "        lead_htag = htag[htag.pt.argmax()]\n",
    "        \n",
    "        wtag = fatjet[((fatjet.pt > 200) & (fatjet.deepTagMD_HbbvsQCD < 0.8365) & (fatjet.deepTag_WvsQCD > 0.918))]\n",
    "        wtag_hard = fatjet[((fatjet.pt > 300) & (fatjet.deepTagMD_HbbvsQCD < 0.8365) & (fatjet.deepTag_WvsQCD > 0.918))]\n",
    "        \n",
    "        lead_wtag = wtag[wtag.pt.argmax()]\n",
    "        \n",
    "        wh = lead_htag.cross(lead_wtag)\n",
    "        wh_deltaPhi = np.arccos(wh.i0.phi - wh.i1.phi)\n",
    "        wh_deltaR = wh.i0.p4.delta_r(wh.i1.p4)\n",
    "        \n",
    "        ############## JETS ##############\n",
    "\n",
    "        skimjet   = jet[(jet.pt>30) & (abs(jet.eta)<2.4)]\n",
    "        jet       = jet[(jet.pt>30) & (jet.jetId>1) & (abs(jet.eta)<2.4)]\n",
    "        jet       = jet[~jet.match(muon, deltaRCut=0.4)] # remove jets that overlap with muons\n",
    "        jet       = jet[~jet.match(electron, deltaRCut=0.4)] # remove jets that overlap with electrons\n",
    "        jet       = jet[~jet.match(fatjet, deltaRCut=1.2)] # remove AK4 jets that overlap with AK8 jets\n",
    "        jet       = jet[jet.pt.argsort(ascending=False)] # sort the jets\n",
    "        btag      = jet[(jet.btagDeepB>0.4184)]\n",
    "        light     = jet[(jet.btagDeepB<0.4184)]\n",
    "        extrajet  = jet[~jet.match(fatjet, deltaRCut=0.8)] \n",
    "        \n",
    "        ## Get leading jets\n",
    "        \n",
    "        high_pt_jet = jet[jet.pt.argsort(ascending=False)][:,:2]\n",
    "        leadjet = high_pt_jet[high_pt_jet.pt.argmax()]\n",
    "        subleadjet = high_pt_jet[high_pt_jet.pt.argmin()]\n",
    "        \n",
    "        ## Get the leading b-jets\n",
    "        high_score_btag = jet[jet.btagDeepB.argsort(ascending=False)][:,:2]\n",
    "        \n",
    "        leading_jet    = jet[jet.pt.argmax()]\n",
    "        leading_b      = btag[btag.pt.argmax()]\n",
    "        \n",
    "        bb = high_score_btag.choose(2)\n",
    "        bb_deltaPhi = np.arccos(np.cos(bb.i0.phi-bb.i1.phi))\n",
    "        bb_deltaR = bb.i0.p4.delta_r(bb.i1.p4)\n",
    "#        print(met[dimuonsel].pt)# + btag[dimuonsel].pt)\n",
    "\n",
    "\n",
    "        mtb = mt(btag[dimuonsel].pt, btag[dimuonsel].phi, newmet[dimuonsel].pt.flatten(), newmet[dimuonsel].phi.flatten())\n",
    "        min_mtb = mtb.min()\n",
    "        mth = mt(htag[dimuonsel].pt, htag[dimuonsel].phi, newmet[dimuonsel].pt.flatten(), newmet[dimuonsel].phi.flatten())\n",
    "\n",
    "        ############## OTHER VARIABLES ##############\n",
    "        \n",
    "        ht = jet.pt.sum()\n",
    "        \n",
    "        min_dphiJetMet4 = np.arccos(np.cos(jet[dimuonsel][:,:4].phi-newmet[dimuonsel].phi.flatten())).min()\n",
    "        \n",
    "        leadingJets = jet[:,:2]\n",
    "        dijet = leadingJets.choose(2)\n",
    "        dphiDiJet = np.arccos(np.cos(dijet.i0.phi-dijet.i1.phi))\n",
    "        \n",
    "        min_dphiFatJetMet4 = np.arccos(np.cos(fatjet[dimuonsel][:,:4].phi-newmet[dimuonsel].phi.flatten())).min()\n",
    "       \n",
    "        ############## SELECTIONS ##############\n",
    "        \n",
    "        dilep_sel = ((electron.counts+muon.counts)==2)\n",
    "        dilep_sf_sel = dilep_sel & ((electron.counts ==2 )|(muon.counts == 2))\n",
    "        dilep_of_sel = dilep_sel & ((electron.counts ==1 )|(muon.counts == 1))\n",
    "        \n",
    "        dimuon_sel = dilep_sel & (muon.counts == 2)\n",
    "        \n",
    "        ak4_sel = (jet.counts > 1)\n",
    "        ak8_sel = (fatjet.counts > 0)\n",
    "        \n",
    "        dimuonmass_sel = (abs(mm.mass-90) < 20).any()\n",
    "        dimuonpt_sel = (mm.pt > 200).any()\n",
    "        leadmuon_sel = (leadm.pt >= 20).any()\n",
    "\n",
    "        ############## CUTFLOW ##############\n",
    "        \n",
    "        output['totalEvents']['all'] += len(df['weight'])\n",
    "        processes = processesList\n",
    "        weight = np.ones(len(df['weight'])) if dataset=='Data' else df['weight']\n",
    "        lumi = 1 if dataset=='Data' else 36\n",
    "        fullweight = weight * lumi\n",
    "        \n",
    "        cutflow = Cutflow(output, df, cfg, processes, weight=fullweight)\n",
    "        \n",
    "        cutflow.addRow( 'triggers',   (triggers) )         \n",
    "        cutflow.addRow( 'filters',   (filters) ) \n",
    "        cutflow.addRow('dimuon = 1', (dimuon_sel))\n",
    "        cutflow.addRow('70 < dimuon mass < 110', (dimuonmass_sel))\n",
    "#        cutflow.addRow( 'MET>250',     (newmet.pt>250).any() )\n",
    "#         cutflow.addRow( 'N_fatjet>1',      (fatjet.counts>1) )\n",
    "#         cutflow.addRow( 'min_dphiFatJetMet4', (min_dphiFatJetMet4>0.5).any())\n",
    "#         cutflow.addRow( 'dphiDiFatJet', (dphiDiFatJet<2.5).any() ) \n",
    "#         cutflow.addRow( 'htag > 0',   (htag_sel) )\n",
    "#         cutflow.addRow( 'minmth>200',   (mth.min()>200).any() )\n",
    "#         cutflow.addRow( '90 < h sd mass > 150',   (htag_sel) )\n",
    "#         cutflow.addRow( 'njet veto',     (extrajet.counts<2))\n",
    "\n",
    "#         cutflow.addRow('lead muon pt >= 20', (leadmuon_sel))\n",
    "#        cutflow.addRow('dimuon pt > 200', (dimuonpt_sel))       \n",
    "#         cutflow.addRow( 'stitch',   (stitchVar ==1) )\n",
    "#         cutflow.addRow( 'skim',   ((met_pt>200) & (skimjet.counts>1)) )\n",
    "#         cutflow.addRow( 'Exactly 1 e or mu',   ((electron.counts+muon.counts)==1) )\n",
    "# \n",
    "        \n",
    "        baseline = copy.deepcopy(cutflow.selection)\n",
    "        \n",
    "\n",
    "#         cutflow.addRow( 'min_dphiFatJetMet4', (min_dphiFatJetMet4>0.5))\n",
    "#         cutflow.addRow( 'dphiDiFatJet', (dphiDiFatJet<2.5).all() ) # by using .all() I do not implicitely cut on the number of fat jets\n",
    "\n",
    "#         cutflow.addRow( 'njet veto',     (jet.counts<2))\n",
    "\n",
    "#         vetoQCD = copy.deepcopy(cutflow.selection)\n",
    "        \n",
    "#         cutflow.addRow( 'N_wtag>0',     (wtag_sel), cumulative=False)\n",
    "        \n",
    "#         wtag_selection = copy.deepcopy(cutflow.selection)\n",
    "        \n",
    "#         cutflow.addRow( 'N_htag>0',     (htag_sel), cumulative=False)\n",
    "\n",
    "#         htag_selection = copy.deepcopy(cutflow.selection)\n",
    "        \n",
    "#         cutflow.addRow( 'N_htag>0, N_wtag>0',     (htag_sel & wtag_sel))\n",
    "\n",
    "#         signal_selection = cutflow.selection\n",
    "        \n",
    "        ############## HISTOGRAMS ##############\n",
    "        output['met'].fill(dataset=dataset,pt=newmet[baseline].pt.flatten(),weight=fullweight[baseline])\n",
    "        output['mm_mass'].fill(dataset=dataset,mass=mm[baseline].mass.flatten(),weight=fullweight[baseline])\n",
    "        output['mm_pt'].fill(dataset=dataset,pt=mm[baseline].pt.flatten(),weight=fullweight[baseline])\n",
    "        output['mm_eta'].fill(dataset=dataset,eta=mm[baseline].eta.flatten(),weight=fullweight[baseline])\n",
    "        output['mm_phi'].fill(dataset=dataset,phi=mm[baseline].phi.flatten(),weight=fullweight[baseline])\n",
    "        output['leadmu_pt'].fill(dataset=dataset,pt=leadm[baseline].pt.flatten(),weight=fullweight[baseline])\n",
    "        output['leadmu_eta'].fill(dataset=dataset,eta=leadm[baseline].eta.flatten(),weight=fullweight[baseline])\n",
    "        output['leadmu_phi'].fill(dataset=dataset,phi=leadm[baseline].phi.flatten(),weight=fullweight[baseline])\n",
    "        output['subleadmu_pt'].fill(dataset=dataset,pt=subleadm[baseline].pt.flatten(),weight=fullweight[baseline])\n",
    "        output['subleadmu_eta'].fill(dataset=dataset,eta=subleadm[baseline].eta.flatten(),weight=fullweight[baseline])\n",
    "        output['subleadmu_phi'].fill(dataset=dataset,phi=subleadm[baseline].phi.flatten(),weight=fullweight[baseline])\n",
    "        output['mm_deltaPhi'].fill(dataset=dataset, delta=mm_deltaPhi[baseline].flatten(), weight=fullweight[baseline])\n",
    "        output['mm_deltaR'].fill(dataset=dataset, delta=mm_deltaR[baseline].flatten(), weight=fullweight[baseline])\n",
    "        output['N_AK4'].fill(dataset=dataset, multiplicity=jet[baseline].counts, weight=fullweight[baseline])\n",
    "        output['N_AK8'].fill(dataset=dataset, multiplicity=fatjet[baseline].counts, weight=fullweight[baseline])       \n",
    "        output['leadAK4_pt'].fill(dataset=dataset, pt=leadjet[baseline & ak4_sel].pt.flatten(), weight=fullweight[baseline & ak4_sel])\n",
    "        output['leadAK4_eta'].fill(dataset=dataset, eta=leadjet[baseline & ak4_sel].eta.flatten(), weight=fullweight[baseline & ak4_sel])\n",
    "        output['leadAK4_phi'].fill(dataset=dataset, phi=leadjet[baseline & ak4_sel].phi.flatten(), weight=fullweight[baseline & ak4_sel])\n",
    "        output['subleadAK4_pt'].fill(dataset=dataset, pt=subleadjet[baseline & ak4_sel].pt.flatten(), weight=fullweight[baseline & ak4_sel])\n",
    "        output['subleadAK4_eta'].fill(dataset=dataset, eta=subleadjet[baseline & ak4_sel].eta.flatten(), weight=fullweight[baseline & ak4_sel])\n",
    "        output['subleadAK4_phi'].fill(dataset=dataset, phi=subleadjet[baseline & ak4_sel].phi.flatten(), weight=fullweight[baseline & ak4_sel])\n",
    "        output['leadAK8_pt'].fill(dataset=dataset, pt=leadfatjet[baseline & ak8_sel].pt.flatten(), weight=fullweight[baseline & ak8_sel])       \n",
    "        output['leadAK8_eta'].fill(dataset=dataset, eta=leadfatjet[baseline & ak8_sel].eta.flatten(), weight=fullweight[baseline & ak8_sel])       \n",
    "        output['leadAK8_phi'].fill(dataset=dataset, phi=leadfatjet[baseline & ak8_sel].phi.flatten(), weight=fullweight[baseline & ak8_sel])       \n",
    "        output['subleadAK8_pt'].fill(dataset=dataset, pt=subleadfatjet[baseline & ak8_sel].pt.flatten(), weight=fullweight[baseline & ak8_sel])       \n",
    "        output['subleadAK8_eta'].fill(dataset=dataset, eta=subleadfatjet[baseline & ak8_sel].eta.flatten(), weight=fullweight[baseline & ak8_sel])       \n",
    "        output['subleadAK8_phi'].fill(dataset=dataset, phi=subleadfatjet[baseline & ak8_sel].phi.flatten(), weight=fullweight[baseline & ak8_sel])       \n",
    "\n",
    "        \n",
    "        #         output['met_CR'].fill(dataset=dataset, pt=met_pt[vetoQCD].flatten(), weight=fullweight[vetoQCD])\n",
    "#         output['met_W_CR'].fill(dataset=dataset, pt=met_pt[vetoQCD & wtag_sel].flatten(), weight=fullweight[vetoQCD & wtag_sel])\n",
    "#         output['met_Higgs_CR'].fill(dataset=dataset, pt=met_pt[vetoQCD & htag_sel].flatten(), weight=fullweight[vetoQCD & htag_sel])\n",
    "#         output['met_Higgs_W_CR'].fill(dataset=dataset, pt=met_pt[signal_selection].flatten(), weight=fullweight[signal_selection])\n",
    "\n",
    "#         output['ht_CR'].fill(dataset=dataset, ht=ht[vetoQCD].flatten(), weight=fullweight[vetoQCD])\n",
    "#         output['ht_W_CR'].fill(dataset=dataset, ht=ht[vetoQCD & wtag_sel].flatten(), weight=fullweight[vetoQCD & wtag_sel])\n",
    "#         output['ht_Higgs_CR'].fill(dataset=dataset, ht=ht[vetoQCD & htag_sel].flatten(), weight=fullweight[vetoQCD & htag_sel])\n",
    "#         output['ht_Higgs_W_CR'].fill(dataset=dataset, ht=ht[signal_selection].flatten(), weight=fullweight[signal_selection])\n",
    "        \n",
    "#         output['N_AK8_CR'].fill(dataset=dataset, multiplicity=fatjet[vetoQCD].counts, weight=fullweight[vetoQCD])\n",
    "#         #output['W_pt_CR'].fill(dataset=dataset, pt=lead_wtag[vetoQCD].pt.flatten(), weight=fullweight[vetoQCD])\n",
    "        #output['H_pt_CR'].fill(dataset=dataset, pt=lead_htag[vetoQCD].pt.flatten(), weight=fullweight[vetoQCD])\n",
    "        #output['W_eta_CR'].fill(dataset=dataset, eta=lead_wtag[vetoQCD].eta.flatten(), weight=fullweight[vetoQCD])\n",
    "        #output['H_eta_CR'].fill(dataset=dataset, eta=lead_htag[vetoQCD].eta.flatten(), weight=fullweight[vetoQCD])\n",
    "\n",
    "#         output['N_AK8_W_CR'].fill(dataset=dataset, multiplicity=fatjet[vetoQCD & wtag_sel].counts, weight=fullweight[vetoQCD & wtag_sel])\n",
    "#         output['W_pt_W_CR'].fill(dataset=dataset, pt=lead_wtag[vetoQCD & wtag_sel].pt.flatten(), weight=fullweight[vetoQCD & wtag_sel])\n",
    "#         #output['H_pt_W_CR'].fill(dataset=dataset, pt=lead_htag[vetoQCD & wtag_sel].pt.flatten(), weight=fullweight[vetoQCD & wtag_sel])\n",
    "        #output['W_eta_W_CR'].fill(dataset=dataset, eta=lead_wtag[vetoQCD & wtag_sel].eta.flatten(), weight=fullweight[vetoQCD & wtag_sel])\n",
    "        #output['H_eta_W_CR'].fill(dataset=dataset, eta=lead_htag[vetoQCD & wtag_sel].eta.flatten(), weight=fullweight[vetoQCD & wtag_sel])\n",
    "\n",
    "        #output['N_AK8_Higgs_CR'].fill(dataset=dataset, multiplicity=fatjet[vetoQCD & htag_sel].counts, weight=fullweight[vetoQCD & htag_sel])\n",
    "        #output['W_pt_Higgs_CR'].fill(dataset=dataset, pt=lead_wtag[vetoQCD & htag_sel].pt.flatten(), weight=fullweight[vetoQCD & htag_sel])\n",
    "        #output['H_pt_Higgs_CR'].fill(dataset=dataset, pt=lead_htag[vetoQCD & htag_sel].pt.flatten(), weight=fullweight[vetoQCD & htag_sel])\n",
    "        #output['W_eta_Higgs_CR'].fill(dataset=dataset, eta=lead_wtag[vetoQCD & htag_sel].eta.flatten(), weight=fullweight[vetoQCD & htag_sel])\n",
    "        #output['H_eta_Higgs_CR'].fill(dataset=dataset, eta=lead_htag[vetoQCD & htag_sel].eta.flatten(), weight=fullweight[vetoQCD & htag_sel])\n",
    "\n",
    "#         output['N_AK8_Higgs_W_CR'].fill(dataset=dataset, multiplicity=fatjet[signal_selection].counts, weight=fullweight[signal_selection])\n",
    "#         output['W_pt_Higgs_W_CR'].fill(dataset=dataset, pt=lead_wtag[signal_selection].pt.flatten(), weight=fullweight[signal_selection])\n",
    "#         output['H_pt_Higgs_W_CR'].fill(dataset=dataset, pt=lead_htag[signal_selection].pt.flatten(), weight=fullweight[signal_selection])\n",
    "#         output['W_eta_Higgs_W_CR'].fill(dataset=dataset, eta=lead_wtag[signal_selection].eta.flatten(), weight=fullweight[signal_selection])\n",
    "#         output['H_eta_Higgs_W_CR'].fill(dataset=dataset, eta=lead_htag[signal_selection].eta.flatten(), weight=fullweight[signal_selection])\n",
    "\n",
    "                \n",
    "#         output['MET_pt_baseline'].fill(dataset=dataset, pt=met_pt[baseline].flatten(), weight=df['weight'][baseline]*cfg['lumi'])\n",
    "#         output['HT_baseline'].fill(dataset=dataset, ht=ht[baseline].flatten(), weight=df['weight'][baseline]*cfg['lumi'])\n",
    "#         output['mtb_min_baseline'].fill(dataset=dataset, mass=mtb[baseline].min().flatten(), weight=df['weight'][baseline]*cfg['lumi'])\n",
    "\n",
    "#         output['MET_pt'].fill(dataset=dataset, pt=met_pt[vetoQCD].flatten(), weight=df['weight'][vetoQCD]*cfg['lumi'])\n",
    "#         output['HT'].fill(dataset=dataset, ht=ht[vetoQCD].flatten(), weight=df['weight'][vetoQCD]*cfg['lumi'])\n",
    "#         output['mtb_min'].fill(dataset=dataset, mass=mtb[vetoQCD].min().flatten(), weight=df['weight'][vetoQCD]*cfg['lumi'])\n",
    "        \n",
    "\n",
    "\n",
    "#         output['min_dphiJetMet4'].fill(dataset=dataset, delta=min_dphiJetMet4[baseline].flatten(), weight=df['weight'][baseline]*cfg['lumi'])\n",
    "#         output['dphiDiJet'].fill(dataset=dataset, delta=dphiDiJet[baseline].min().flatten(), weight=df['weight'][baseline]*cfg['lumi'])\n",
    "\n",
    "#         ## Higgs and W pt\n",
    "#         output['lead_AK8_pt'].fill(dataset=dataset, pt=fatjet[(baseline & (fatjet.counts>0))].pt.max().flatten(), weight=df['weight'][(baseline & (fatjet.counts>0))]*cfg['lumi'])\n",
    "#         output['dphiDiFatJet'].fill(dataset=dataset, delta=dphiDiFatJet[(baseline & (fatjet.counts>1))].min().flatten(), weight=df['weight'][(baseline & (fatjet.counts>1))]*cfg['lumi'])\n",
    "\n",
    "#         output['H_pt'].fill(dataset=dataset, pt=lead_htag[event_selection].pt.flatten(), weight=df['weight'][event_selection]*cfg['lumi'])\n",
    "#         output['H_eta'].fill(dataset=dataset, eta=lead_htag[event_selection].eta.flatten(), weight=df['weight'][event_selection]*cfg['lumi'])\n",
    "\n",
    "#         output['W_pt'].fill(dataset=dataset, pt=lead_wtag[event_selection].pt.flatten(), weight=df['weight'][event_selection]*cfg['lumi'])\n",
    "#         output['W_eta'].fill(dataset=dataset, eta=lead_wtag[event_selection].eta.flatten(), weight=df['weight'][event_selection]*cfg['lumi'])\n",
    "\n",
    "#         output['WH_deltaPhi'].fill(dataset=dataset, delta=wh_deltaPhi[event_selection].flatten(), weight=df['weight'][event_selection]*cfg['lumi'])\n",
    "#         output['WH_deltaR'].fill(dataset=dataset, delta=wh_deltaR[event_selection].flatten(), weight=df['weight'][event_selection]*cfg['lumi'])\n",
    "\n",
    "#         output['MET_pt_CR'].fill(dataset=dataset, pt=met_pt[event_selection].flatten(), weight=df['weight'][event_selection]*cfg['lumi'])\n",
    "#         output['HT_CR'].fill(dataset=dataset, ht=ht[event_selection].flatten(), weight=df['weight'][event_selection]*cfg['lumi'])\n",
    "#         output['mtb_min_CR'].fill(dataset=dataset, mass=mtb[event_selection].min().flatten(), weight=df['weight'][event_selection]*cfg['lumi'])\n",
    "\n",
    "        return output\n",
    "\n",
    "    def postprocess(self, accumulator):\n",
    "        return accumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "runLocal = True\n",
    "\n",
    "if not runLocal:\n",
    "    # Get the scheduler from the dask_cluster notebook\n",
    "    from dask.distributed import Client, progress\n",
    "\n",
    "    c = Client('tcp://169.228.130.5:27879')\n",
    "\n",
    "    ## for dask\n",
    "    exe_args = {\n",
    "        'client': c,\n",
    "        #'savemetrics': True,\n",
    "    }\n",
    "    exe = processor.dask_executor\n",
    "    \n",
    "else:\n",
    "    ## for local\n",
    "    exe_args = {\n",
    "        'workers': 16,\n",
    "        'function_args': {'flatten': False}\n",
    "    }\n",
    "    exe = processor.futures_executor\n",
    "\n",
    "if not runLocal:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dilep_2016_small\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3472198b00d40f3a0d46024750a4ded",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(HTML(value='Processing'), FloatProgress(value=0.0, max=80.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/mbryson/CMSSW_10_2_9/src/tW_scattering/coffeaEnv/lib/python3.6/site-packages/awkward/array/jagged.py:1043: RuntimeWarning: invalid value encountered in arccos\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/users/mbryson/CMSSW_10_2_9/src/tW_scattering/coffeaEnv/lib/python3.6/site-packages/awkward/array/jagged.py:1043: RuntimeWarning: invalid value encountered in arccos\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/users/mbryson/CMSSW_10_2_9/src/tW_scattering/coffeaEnv/lib/python3.6/site-packages/awkward/array/jagged.py:1043: RuntimeWarning: invalid value encountered in arccos\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/users/mbryson/CMSSW_10_2_9/src/tW_scattering/coffeaEnv/lib/python3.6/site-packages/awkward/array/jagged.py:1043: RuntimeWarning: invalid value encountered in arccos\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "overwrite = True\n",
    "small = True\n",
    "\n",
    "tag = 'v0.2.4'\n",
    "\n",
    "from Tools.dilep_samples import * #fileset_2016, fileset_2016_small\n",
    "\n",
    "if year == 2016:\n",
    "    fileset_year = fileset_dilep_2016\n",
    "    fileset_year_small = fileset_dilep_2016_small\n",
    "elif year == 2017:\n",
    "    fileset_year = fileset_2017\n",
    "    fileset_year_small = fileset_dilep_2017_small\n",
    "elif year == 2018:\n",
    "    fileset_year = fileset_2018\n",
    "    fileset_year_small = fileset_dilep_2018_small\n",
    "\n",
    "\n",
    "fileset_dilep = {\n",
    "    'DYJets': fileset_year['DY_HT'],\n",
    "    'TTJets': fileset_year['TTJets'] + fileset_year['TTJets_ext'],\n",
    "    'ttW': fileset_year['TTW'],\n",
    "    'ttZ': fileset_year['TTZ'],\n",
    "    'Data': fileset_year['DoubleMuon'],\n",
    "}\n",
    "\n",
    "\n",
    "fileset_dilep_small = {\n",
    "    'DYJets': fileset_dilep['DYJets'][:2],\n",
    "    'TTJets': fileset_dilep['TTJets'][:2],\n",
    "    'ttW': fileset_dilep['ttW'][:2],\n",
    "    'ttZ': fileset_dilep['ttZ'][:2],\n",
    "    'Data': fileset_dilep['Data'][:2],\n",
    "}\n",
    "\n",
    "# load the config and the cache\n",
    "cfg = loadConfig()\n",
    "\n",
    "cacheName = 'Dilep_%s_small'%year if small else 'DiLep_%s'%year\n",
    "print(cacheName)\n",
    "\n",
    "# histograms\n",
    "histograms = []\n",
    "\n",
    "# initialize cache\n",
    "cache = dir_archive(os.path.join(os.path.expandvars(cfg['caches']['base']), cacheName), serialized=True)\n",
    "if not overwrite:\n",
    "    cache.load()\n",
    "\n",
    "if cfg == cache.get('cfg') and histograms == cache.get('histograms') and cache.get('simple_output'):\n",
    "    output = cache.get('simple_output')\n",
    "\n",
    "else:\n",
    "    # Run the processor\n",
    "    if small:\n",
    "        fileset = fileset_dilep_small\n",
    "        exe_args['workers'] = 4\n",
    "    else:\n",
    "        fileset = fileset_dilep\n",
    "        exe_args['workers'] = 16\n",
    "    \n",
    "        \n",
    "    output = processor.run_uproot_job(fileset,\n",
    "                                      treename='Events',\n",
    "                                      processor_instance=analysisProcessor(),\n",
    "                                      executor=exe,\n",
    "                                      executor_args=exe_args,\n",
    "                                      #chunksize=250000,\n",
    "                                      chunksize=100000,\n",
    "                                     )\n",
    "    cache['fileset']        = fileset\n",
    "    cache['cfg']            = cfg\n",
    "    cache['histograms']     = histograms\n",
    "    cache['simple_output']  = output\n",
    "    cache.dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DYJets</th>\n",
       "      <th>TTJets</th>\n",
       "      <th>ttW</th>\n",
       "      <th>ttZ</th>\n",
       "      <th>Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>entry</th>\n",
       "      <td>1554000.0 +/- 1000.0</td>\n",
       "      <td>390400.0 +/- 200.0</td>\n",
       "      <td>2359.0 +/- 5.0</td>\n",
       "      <td>2586.0 +/- 4.0</td>\n",
       "      <td>269400.0 +/- 500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filters</th>\n",
       "      <td>1552000.0 +/- 1000.0</td>\n",
       "      <td>390000.0 +/- 200.0</td>\n",
       "      <td>2353.0 +/- 5.0</td>\n",
       "      <td>2580.0 +/- 4.0</td>\n",
       "      <td>234800.0 +/- 500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>triggers</th>\n",
       "      <td>1554000.0 +/- 1000.0</td>\n",
       "      <td>390400.0 +/- 200.0</td>\n",
       "      <td>2359.0 +/- 5.0</td>\n",
       "      <td>2586.0 +/- 4.0</td>\n",
       "      <td>235300.0 +/- 500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dimuon = 1</th>\n",
       "      <td>770900.0 +/- 800.0</td>\n",
       "      <td>92420.0 +/- 110.0</td>\n",
       "      <td>407.4 +/- 1.9</td>\n",
       "      <td>490.9 +/- 1.9</td>\n",
       "      <td>229100.0 +/- 500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70 &lt; dimuon mass &lt; 110</th>\n",
       "      <td>714800.0 +/- 800.0</td>\n",
       "      <td>24090.0 +/- 60.0</td>\n",
       "      <td>96.82 +/- 0.92</td>\n",
       "      <td>343.1 +/- 1.6</td>\n",
       "      <td>185700.0 +/- 400.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      DYJets              TTJets  \\\n",
       "entry                   1554000.0 +/- 1000.0  390400.0 +/- 200.0   \n",
       "filters                 1552000.0 +/- 1000.0  390000.0 +/- 200.0   \n",
       "triggers                1554000.0 +/- 1000.0  390400.0 +/- 200.0   \n",
       "dimuon = 1                770900.0 +/- 800.0   92420.0 +/- 110.0   \n",
       "70 < dimuon mass < 110    714800.0 +/- 800.0    24090.0 +/- 60.0   \n",
       "\n",
       "                                   ttW             ttZ                Data  \n",
       "entry                   2359.0 +/- 5.0  2586.0 +/- 4.0  269400.0 +/- 500.0  \n",
       "filters                 2353.0 +/- 5.0  2580.0 +/- 4.0  234800.0 +/- 500.0  \n",
       "triggers                2359.0 +/- 5.0  2586.0 +/- 4.0  235300.0 +/- 500.0  \n",
       "dimuon = 1               407.4 +/- 1.9   490.9 +/- 1.9  229100.0 +/- 500.0  \n",
       "70 < dimuon mass < 110  96.82 +/- 0.92   343.1 +/- 1.6  185700.0 +/- 400.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cutflow\n",
    "from Tools.helpers import getCutFlowTable\n",
    "\n",
    "processes = processesList\n",
    "lines     = ['entry']\n",
    "lines    += linesList\n",
    "df        = getCutFlowTable(output, processes=processes, lines=lines, significantFigures=4)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DYJets</th>\n",
       "      <th>TTJets</th>\n",
       "      <th>ttW</th>\n",
       "      <th>ttZ</th>\n",
       "      <th>Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>entry</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filters</th>\n",
       "      <td>0.999</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>triggers</th>\n",
       "      <td>0.486</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dimuon = 1</th>\n",
       "      <td>0.971</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70 &lt; dimuon mass &lt; 110</th>\n",
       "      <td>0.930</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        DYJets  TTJets    ttW    ttZ   Data\n",
       "entry                    1.000   1.000  1.000  1.000  1.000\n",
       "filters                  0.999   0.999  0.998  0.998  0.998\n",
       "triggers                 0.486   0.429  0.419  0.374  0.873\n",
       "dimuon = 1               0.971   0.514  0.384  0.481  0.976\n",
       "70 < dimuon mass < 110   0.930   0.264  0.240  0.712  0.811"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Efficiencies\n",
    "df = getCutFlowTable(output, processes=processes, lines=lines, significantFigures=3, absolute=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plots.helpers import *\n",
    "bins = {\n",
    "    'mm_mass_axis':        {'axis':'mass',   'overflow': 'over', 'bins': hist.Bin(\"mass\",  r\"Dimuon mass (GeV)\", 25, 50, 150)},\n",
    "    'mm_pt_axis':          {'axis':'pt',   'overflow': 'over', 'bins': hist.Bin(\"pt\",  r\"Dimuon $p_{T}$ (GeV)\", 25, 0, 300)},\n",
    "    'mm_eta_axis':         {'axis':'eta',   'overflow': 'over', 'bins': hist.Bin(\"eta\",       r\"Dimuon $\\eta$\", 30, -5.5, 5.5)},\n",
    "    'mm_phi_axis':         {'axis':'phi',   'overflow': 'over', 'bins': hist.Bin(\"phi\",       r\"Dimuon $\\phi$\", 20, -4, 4)},\n",
    "    'leadmu_pt_axis':      {'axis':'pt',   'overflow': 'over', 'bins': hist.Bin(\"pt\",  r\" Lead Muon $p_{T}$ (GeV)\", 25, 0, 250)},\n",
    "    'leadmu_eta_axis':     {'axis':'eta',   'overflow': 'over', 'bins': hist.Bin(\"eta\",       r\"Lead Muon $\\eta$\", 30, -5.5, 5.5)},\n",
    "    'leadmu_phi_axis':     {'axis':'phi',   'overflow': 'over', 'bins': hist.Bin(\"phi\",       r\"Lead Muon $\\phi$\", 20, -4, 4)},\n",
    "    'subleadmu_pt_axis':   {'axis':'pt',   'overflow': 'over', 'bins': hist.Bin(\"pt\",  r\" Sublead Muon $p_{T}$ (GeV)\", 25, 0, 150)},\n",
    "    'subleadmu_eta_axis':  {'axis':'eta',   'overflow': 'over', 'bins': hist.Bin(\"eta\",       r\"Sublead Muon $\\eta$\", 30, -5.5, 5.5)},\n",
    "    'subleadmu_phi_axis':  {'axis':'phi',   'overflow': 'over', 'bins': hist.Bin(\"phi\",       r\"Sublead Muon $\\phi$\", 20, -4, 4)},\n",
    "    'leadAK4_pt_axis':     {'axis':'pt',   'overflow': 'over', 'bins': hist.Bin(\"pt\",  r\" Lead AK4 $p_{T}$ (GeV)\", 25, 0, 300)},\n",
    "    'leadAK4_eta_axis':    {'axis':'eta',   'overflow': 'over', 'bins': hist.Bin(\"eta\",       r\"Lead AK4 $\\eta$\", 30, -5.5, 5.5)},\n",
    "    'leadAK4_phi_axis':    {'axis':'phi',   'overflow': 'over', 'bins': hist.Bin(\"phi\",       r\"Lead AK4 $\\phi$\", 20, -4, 4)},\n",
    "    'subleadAK4_pt_axis':  {'axis':'pt',   'overflow': 'over', 'bins': hist.Bin(\"pt\",  r\" Sublead AK4 $p_{T}$ (GeV)\", 25, 0, 200)},\n",
    "    'subleadAK4_eta_axis': {'axis':'eta',   'overflow': 'over', 'bins': hist.Bin(\"eta\",       r\"Sublead AK4 $\\eta$\", 30, -5.5, 5.5)},\n",
    "    'subleadAK4_phi_axis': {'axis':'phi',   'overflow': 'over', 'bins': hist.Bin(\"phi\",       r\"Sublead AK4 $\\phi$\", 20, -4, 4)},\n",
    "    'leadAK8_pt_axis':     {'axis':'pt',   'overflow': 'over', 'bins': hist.Bin(\"pt\",  r\" Lead AK8 $p_{T}$ (GeV)\", 25, 150, 400)},\n",
    "    'leadAK8_eta_axis':    {'axis':'eta',   'overflow': 'over', 'bins': hist.Bin(\"eta\",       r\"Lead AK8 $\\eta$\", 30, -5.5, 5.5)},\n",
    "    'leadAK8_phi_axis':    {'axis':'phi',   'overflow': 'over', 'bins': hist.Bin(\"phi\",       r\"Lead AK8 $\\phi$\", 20, -4, 4)},\n",
    "    'subleadAK8_pt_axis':  {'axis':'pt',   'overflow': 'over', 'bins': hist.Bin(\"pt\",  r\" Sublead AK8 $p_{T}$ (GeV)\", 25, 150, 350)},\n",
    "    'subleadAK8_eta_axis': {'axis':'eta',   'overflow': 'over', 'bins': hist.Bin(\"eta\",       r\"Sublead AK8 $\\eta$\", 30, -5.5, 5.5)},\n",
    "    'subleadAK8_phi_axis': {'axis':'phi',   'overflow': 'over', 'bins': hist.Bin(\"phi\",       r\"Sublead AK8 $\\phi$\", 20, -4, 4)},\n",
    "    'N_AK4_axis':          {'axis': 'multiplicity',  'overflow':'over',  'bins': hist.Bin('multiplicity', r'$N_{AK4 jet}$', 6, -0.5, 5.5)},\n",
    "    'N_AK8_axis':          {'axis': 'multiplicity',  'overflow':'over',  'bins': hist.Bin('multiplicity', r'$N_{AK8 jet}$', 5, -0.5, 4.5)},\n",
    "    'mm_deltaPhi_axis':    {'axis': 'delta',          'overflow':'over',  'bins': hist.Bin('delta', r'Dimuon $\\Delta \\phi $', 30, 0, 3)},\n",
    "    'mm_deltaR_axis':      {'axis': 'delta',          'overflow':'over',  'bins': hist.Bin('delta', r'Dimuon $\\Delta R $', 10, 0, 5)},\n",
    "   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting aesthetics\n",
    "\n",
    "lineopts = {\n",
    "    'color': 'r',\n",
    "    'linewidth': '3'}\n",
    "\n",
    "data_err_opts = {\n",
    "    'linestyle': 'none',\n",
    "    'marker': '_',\n",
    "    'markersize': 10.,\n",
    "    'color': 'r',\n",
    "    'elinewidth': 1}\n",
    "\n",
    "data_err_opts_rat = {\n",
    "    'linestyle': 'none',\n",
    "    'marker': '.',\n",
    "    'markersize': 10.,\n",
    "    'color': 'k',\n",
    "    'elinewidth': 1}\n",
    "\n",
    "fillopts2 = {\n",
    "    'edgecolor': (0,0,0,0.3),\n",
    "    'facecolor': [('#989C94'),('#6A0136'),('#FF5714'),('#FFCA3A')]  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plots.helpers import *\n",
    "\n",
    "def saveFig( fig, ax, rax, path, name, scale='linear', shape=False, y_max=-1 ):\n",
    "    outdir = os.path.join(path,scale)\n",
    "    finalizePlotDir(outdir)\n",
    "    ax.set_yscale(scale)\n",
    "    ax.set_ylabel('Events')\n",
    "\n",
    "    if scale == 'linear':\n",
    "        if y_max<0: #or True:\n",
    "            pass\n",
    "        else:\n",
    "            ax.set_ylim(0, 1 if shape else 1.2*y_max)\n",
    "    else:\n",
    "        if y_max<0 and not shape:\n",
    "            pass\n",
    "        else:\n",
    "            ax.set_ylim(0.000005 if shape else 0.05, 3 if shape else 300*y_max)\n",
    "\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    new_labels = []\n",
    "    for handle, label in zip(handles, labels):\n",
    "        #print (handle, label)\n",
    "        try:\n",
    "            new_labels.append(my_labels[label])\n",
    "            if not label=='pseudodata':\n",
    "                handle.set_color(colors[label])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    if rax:\n",
    "        plt.subplots_adjust(hspace=0)\n",
    "        rax.set_ylabel('Obs./Pred.')\n",
    "        rax.set_ylim(0,2)\n",
    "\n",
    "    ax.legend(title='',ncol=2,handles=handles, labels=new_labels, frameon=False)\n",
    "\n",
    "    fig.text(0., 0.995, '$\\\\bf{CMS}$', fontsize=20,  horizontalalignment='left', verticalalignment='bottom', transform=ax.transAxes )\n",
    "    fig.text(0.15, 1., '$\\\\it{Simulation}$', fontsize=14, horizontalalignment='left', verticalalignment='bottom', transform=ax.transAxes )\n",
    "    fig.text(0.8, 1., '13 TeV', fontsize=14, horizontalalignment='left', verticalalignment='bottom', transform=ax.transAxes )\n",
    "\n",
    "    fig.savefig(os.path.join(outdir, \"{}.pdf\".format(name)))\n",
    "    fig.savefig(os.path.join(outdir, \"{}.png\".format(name)))\n",
    "    #ax.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Histos I want to save\n",
    "histos = [[\"mm_mass\", \"mm_mass_axis\"],\n",
    "        [\"mm_pt\", \"mm_pt_axis\"],\n",
    "        [\"mm_eta\", \"mm_eta_axis\"],\n",
    "        [\"mm_phi\", \"mm_phi_axis\"],\n",
    "        [\"leadmu_pt\", \"leadmu_pt_axis\"],\n",
    "        [\"leadmu_eta\", \"leadmu_eta_axis\"],\n",
    "        [\"leadmu_phi\", \"leadmu_phi_axis\"],\n",
    "        [\"subleadmu_pt\", \"subleadmu_pt_axis\"],\n",
    "        [\"subleadmu_eta\", \"subleadmu_eta_axis\"],\n",
    "        [\"subleadmu_phi\", \"subleadmu_phi_axis\"],\n",
    "        [\"leadAK4_pt\", \"leadAK4_pt_axis\"],\n",
    "        [\"leadAK4_eta\", \"leadAK4_eta_axis\"],\n",
    "        [\"leadAK4_phi\", \"leadAK4_phi_axis\"],\n",
    "        [\"subleadAK4_pt\", \"subleadAK4_pt_axis\"],\n",
    "        [\"subleadAK4_eta\", \"subleadAK4_eta_axis\"],\n",
    "        [\"subleadAK4_phi\", \"subleadAK4_phi_axis\"],\n",
    "        [\"leadAK8_pt\", \"leadAK8_pt_axis\"],\n",
    "        [\"leadAK8_eta\", \"leadAK8_eta_axis\"],\n",
    "        [\"leadAK8_phi\", \"leadAK8_phi_axis\"],\n",
    "        [\"subleadAK8_pt\", \"subleadAK8_pt_axis\"],\n",
    "        [\"subleadAK8_eta\", \"subleadAK8_eta_axis\"],\n",
    "        [\"subleadAK8_phi\", \"subleadAK8_phi_axis\"],\n",
    "        [\"N_AK4\", \"N_AK4_axis\"],\n",
    "        [\"N_AK8\", \"N_AK8_axis\"],\n",
    "        [\"mm_deltaPhi\", \"mm_deltaPhi_axis\"],\n",
    "        [\"mm_deltaR\", \"mm_deltaR_axis\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some of the plots\n",
    "\n",
    "\n",
    "finalizePlotDir(plotDir)\n",
    "\n",
    "\n",
    "for plot in histos:\n",
    "\n",
    "    name = plot[0]\n",
    "    binName = plot[1]\n",
    "    histogram = output[name]\n",
    "\n",
    "    axis = bins[binName]['axis']\n",
    "    histogram = histogram.rebin(axis, bins[binName]['bins'])\n",
    "\n",
    "    y_max = histogram.sum(\"dataset\").values(overflow='all')[()].max()\n",
    "    y_over = histogram.sum(\"dataset\").values(overflow='all')[()][-1]\n",
    "\n",
    "    import re\n",
    "\n",
    "    bkg = re.compile('(?!Data)')\n",
    "    \n",
    "    background = histogram[bkg]\n",
    "    data = histogram['Data']\n",
    "\n",
    "    #fig, ax = plt.subplots(1,1,figsize=(7,7))\n",
    "    fig, (ax, rax) = plt.subplots(nrows=2,ncols=1, figsize=(7,7),\n",
    "        gridspec_kw={\"height_ratios\": (3, 1)}, sharex=True)\n",
    "    \n",
    "    # get axes\n",
    "    hist.plot1d(background, overlay=\"dataset\", ax=ax, stack=True, \n",
    "                overflow=bins[binName]['overflow'], clear=False, fill_opts=fillopts2, \n",
    "                error_opts=error_opts, order=['DYJets','TTJets', 'ttW', 'ttZ']) #error_opts??\n",
    "    hist.plot1d(data, overlay=\"dataset\", ax=ax, stack=False, \n",
    "                overflow=bins[binName]['overflow'], error_opts=data_err_opts_rat, \n",
    "                clear=False)\n",
    "\n",
    "    hist.plotratio(num=data.sum('dataset'), denom=background.sum('dataset'), ax=rax,\n",
    "                   error_opts = data_err_opts_rat, denom_fill_opts={}, guide_opts={}, \n",
    "                   unc='num', overflow = 'over')\n",
    "\n",
    "    for l in ['log', 'linear']:\n",
    "        saveFig(fig, ax, rax, plotDir, name, scale=l, shape=False, y_max=y_max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = True\n",
    "small = True\n",
    "\n",
    "tag = 'v0.2.4'\n",
    "\n",
    "\n",
    "fileset_all_2016   = {'Data': glob.glob('/hadoop/cms/store/user/dspitzba/WH_hadronic/'+tag+'/DoubleMuon*2016*/*'),\n",
    "                'DYJets':glob.glob('/hadoop/cms/store/user/dspitzba/WH_hadronic/'+tag+'/DYJetsToLL_M-50_Tune*Summer16*/*.root'),\n",
    "                'TTJets': glob.glob('/hadoop/cms/store/user/dspitzba/WH_hadronic/'+tag+'/TTJets_DiLept_Tune*Summer16*/*'),\n",
    "                'ttW':glob.glob('/hadoop/cms/store/user/dspitzba/WH_hadronic/'+tag+'/TTWJets*Summer16*/*'),\n",
    "                'ttZ': glob.glob('/hadoop/cms/store/user/dspitzba/WH_hadronic/'+tag+'/ttZJets*Summer16*/*')\n",
    "                 }\n",
    "\n",
    "fileset_all_2016_sm   = {'Data':glob.glob('/hadoop/cms/store/user/dspitzba/WH_hadronic/'+tag+'/DoubleMuon*2016*/*')[:2],\n",
    "                'DYJets':glob.glob('/hadoop/cms/store/user/dspitzba/WH_hadronic/'+tag+'/DYJetsToLL_M-50_Tune*Summer16*/*')[:2],\n",
    "                'TTJets': glob.glob('/hadoop/cms/store/user/dspitzba/WH_hadronic/'+tag+'/TTJets_DiLept_Tune*Summer16*/*')[:2],\n",
    "                'ttW': glob.glob('/hadoop/cms/store/user/dspitzba/WH_hadronic/'+tag+'/TTWJets*Summer16*/*')[:2],\n",
    "                'ttZ': glob.glob('/hadoop/cms/store/user/dspitzba/WH_hadronic/'+tag+'/ttZJets*Summer16*/*')[:2]\n",
    "                 }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# load the config and the cache\n",
    "cfg = loadConfig()\n",
    "\n",
    "cacheName = 'WH_small' if small else 'WH'\n",
    "\n",
    "# histograms\n",
    "histograms = []\n",
    "histograms += []\n",
    "\n",
    "# initialize cache\n",
    "cache = dir_archive(os.path.join(os.path.expandvars(cfg['caches']['base']), cfg['caches'][cacheName]), serialized=True)\n",
    "if not overwrite:\n",
    "    cache.load()\n",
    "\n",
    "if cfg == cache.get('cfg') and histograms == cache.get('histograms') and cache.get('simple_output'):\n",
    "    output = cache.get('simple_output')\n",
    "\n",
    "else:\n",
    "    # Run the processor\n",
    "\n",
    "    if small:\n",
    "        fileset = fileset_all_2016_sm\n",
    "        workers = 4\n",
    "    else:\n",
    "        fileset = fileset_all_2016\n",
    "        workers = 16\n",
    "    \n",
    "        \n",
    "    output = processor.run_uproot_job(fileset,\n",
    "                                      treename='Events',\n",
    "                                      processor_instance=analysisProcessor(),\n",
    "                                      executor=exe,\n",
    "                                      executor_args=exe_args,\n",
    "                                      chunksize=250000,\n",
    "                                      #chunksize=100000,\n",
    "                                     )\n",
    "    cache['fileset']        = fileset\n",
    "    cache['cfg']            = cfg\n",
    "    cache['histograms']     = histograms\n",
    "    cache['simple_output']  = output\n",
    "    cache.dump()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coffeaEnv",
   "language": "python",
   "name": "coffeaenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
